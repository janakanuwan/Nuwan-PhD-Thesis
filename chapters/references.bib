% MyPublications


@inproceedings{janaka_paracentral_2022,
	address = {New York, NY, USA},
	series = {{CHI} '22},
	title = {Paracentral and near-peripheral visualizations: {Towards} attention-maintaining secondary information presentation on {OHMDs} during in-person social interactions},
	isbn = {978-1-4503-9157-3},
	shorttitle = {Paracentral and near-peripheral visualizations},
	url = {https://dl.acm.org/doi/10.1145/3491102.3502127},
	doi = {10.1145/3491102.3502127},
	abstract = {Optical see-through Head-Mounted Displays (OST HMDs, OHMDs) are known to facilitate situational awareness while accessing secondary information. However, information displayed on OHMDs can cause attention shifts, which distract users from natural social interactions. We hypothesize that information displayed in paracentral and near-peripheral vision can be better perceived while the user is maintaining eye contact during face-to-face conversations. Leveraging this idea, we designed a circular progress bar to provide progress updates in paracentral and near-peripheral vision. We compared it with textual and linear progress bars under two conversation settings: a simulated one with a digital conversation partner and a realistic one with a real partner. Results show that a circular progress bar can effectively reduce notification distractions without losing eye contact and is more preferred by users. Our findings highlight the potential of utilizing the paracentral and near-peripheral vision for secondary information presentation on OHMDs.},
	booktitle = {Proceedings of the 2022 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Janaka, Nuwan and Haigh, Chloe and Kim, Hyeongcheol and Zhang, Shan and Zhao, Shengdong},
	month = apr,
	year = {2022},
	keywords = {circular progress, conversation, HMD, interruption, near-peripheral, paracentral, reminder notification, smart glasses, social interaction},
	pages = {1--14},
}


@inproceedings{ghosh_eyeditor_2020,
	address = {Honolulu HI USA},
	title = {{EYEditor}: {Towards} {On}-the-{Go} {Heads}-{Up} {Text} {Editing} {Using} {Voice} and {Manual} {Input}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {{EYEditor}},
	url = {https://doi.org/10.1145/3313831.3376173},
	doi = {10.1145/3313831.3376173},
	abstract = {On-the-go text-editing is difﬁcult, yet frequently done in everyday lives. Using smartphones for editing text forces users into a heads-down posture which can be undesirable and unsafe. We present EYEditor, a heads-up smartglass-based solution that displays the text on a see-through peripheral display and allows text-editing with voice and manual input. The choices of output modality (visual and/or audio) and content presentation were made after a controlled experiment, which showed that sentence-by-sentence visual-only presentation is best for optimizing users’ editing and path-navigation capabilities. A second experiment formally evaluated EYEditor against the standard smartphone-based solution for tasks with varied editing complexities and navigation difﬁculties. The results showed that EYEditor outperformed smartphones as either the path OR the task became more difﬁcult. Yet, the advantage of EYEditor became less salient when both the editing and navigation was difﬁcult. We discuss trade-offs and insights gained for future heads-up text-editing solutions.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Ghosh, Debjyoti and Foong, Pin Sym and Zhao, Shengdong and Liu, Can and Janaka, Nuwan and Erusu, Vinitha},
	month = apr,
	year = {2020},
	numpages = {13},
    series = {CHI '20},
}


@article{janaka_visual_2022,
	title = {Visual {Behaviors} and {Mobile} {Information} {Acquisition}},
	url = {http://arxiv.org/abs/2202.02748},
	abstract = {It is common for people to engage in information acquisition tasks while on the move. To understand how users' visual behaviors influence microlearning, a form of mobile information acquisition, we conducted a shadowing study with 8 participants and identified three common visual behaviors: 'glance', 'inspect', and 'drift'. We found that 'drift' best supports mobile information acquisition. We also identified four user-related factors that can influence the utilization of mobile information acquisition opportunities: situational awareness, switching costs, ongoing cognitive processes, and awareness of opportunities. We further examined how these user-related factors interplay with device-related factors through a technology probe with 20 participants using mobile phones and optical head-mounted displays (OHMDs). Results indicate that different device platforms significantly influence how mobile information acquisition opportunities are used: OHMDs can better support mobile information acquisition when visual attention is fragmented. OHMDs facilitate shorter visual switch-times between the task and surroundings, which reduces the mental barrier of task transition. Mobile phones, on the other hand, provide a more focused experience in more stable surroundings. Based on these findings, we discuss trade-offs and design implications for supporting information acquisition tasks on the move.},
	journal = {arXiv:2202.02748 [cs]},
	author = {Janaka, Nuwan and Wu, Xinke and Zhang, Shan and Zhao, Shengdong and Slovak, Petr},
	month = feb,
	year = {2022},
    numpages = {35},
}

@inproceedings{janaka_can_2023,
	address = {New York, NY, USA},
	series = {{CHI} '23},
	title = {Can {Icons} {Outperform} {Text}? {Understanding} the {Role} of {Pictograms} in {OHMD} {Notifications}},
	isbn = {978-1-4503-9421-5},
	shorttitle = {Can {Icons} {Outperform} {Text}?},
	url = {https://dl.acm.org/doi/10.1145/3544548.3580891},
	doi = {10.1145/3544548.3580891},
	abstract = {Optical see-through head-mounted displays (OHMDs) can provide just-in-time digital assistance to users while they are engaged in ongoing tasks. However, given users’ limited attentional resources when multitasking, there is a need to concisely and accurately present information in OHMDs. Existing approaches for digital information presentation involve using either text or pictograms. While pictograms have enabled rapid recognition and easier use in warning messages and traffic signs, most studies using pictograms for digital notifications have exhibited unfavorable results. We thus conducted a series of four iterative studies to understand how we can support effective notification presentation on OHMDs during multitasking scenarios. We find that while icon-augmented notifications can outperform text-only notifications, their effectiveness depends on icon familiarity, encoding density, and environmental brightness. We reveal design implications when using icon-augmented notifications in OHMDs and present plausible reasons for the observed disparity in literature.},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Janaka, Nuwan and Zhao, Shengdong and Sapkota, Shardul},
	month = apr,
	year = {2023},
	keywords = {distraction, icon, interruption, notification, OHMD, OST HMD, pictogram, smart glasses},
	pages = {1--23},
}

@inproceedings{janaka_notifade_2023,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '23},
	title = {{NotiFade}: {Minimizing} {OHMD} {Notification} {Distractions} {Using} {Fading}},
	isbn = {978-1-4503-9422-2},
	shorttitle = {{NotiFade}},
	url = {https://dl.acm.org/doi/10.1145/3544549.3585784},
	doi = {10.1145/3544549.3585784},
	abstract = {While animations can minimize attention costs for desktop notifications, their application for Optical see-through Head-Mounted Display (OHMD) notifications is underexplored. To investigate the effectiveness of animation on OHMD notifications in minimizing attention costs, we conducted a study comparing fade-in, blast, and scrolling notification animations. Results showed that fade-in animation minimizes notification interference with the primary task, unlike blast and scrolling animations. Its effectiveness depends on multiple factors, including fade-duration and location of the primary task. Finally, we discuss how fade-in animation can improve OHMD notifications and its associated trade-offs.},
	booktitle = {Extended {Abstracts} of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Janaka, Nuwan and Zhao, Shengdong and Chan, Samantha},
	month = apr,
	year = {2023},
	keywords = {animation, distraction, fade, fading, interruption, notification, OHMD, OST HMD, scroll, smart glasses},
	pages = {1--9},
}

@inproceedings{runze_paraglassmenu_2023,
	address = {New York, NY, USA},
	series = {{CHI} '23},
	title = {{ParaGlassMenu}: {Towards} {Social}-{Friendly} {Subtle} {Interactions} in {Conversations}},
	isbn = {978-1-4503-9421-5},
	shorttitle = {{ParaGlassMenu}},
	url = {https://dl.acm.org/doi/10.1145/3544548.3581065},
	doi = {10.1145/3544548.3581065},
	abstract = {Interactions with digital devices during social settings can reduce social engagement and interrupt conversations. To overcome these drawbacks, we designed ParaGlassMenu, a semi-transparent circular menu that can be displayed around a conversation partner’s face on Optical See-Through Head-Mounted Display (OHMD) and interacted subtly using a ring mouse. We evaluated ParaGlassMenu with several alternative approaches (Smartphone, Voice assistant, and Linear OHMD menus) by manipulating Internet-of-Things (IoT) devices in a simulated conversation setting with a digital partner. Results indicated that the ParaGlassMenu offered the best overall performance in balancing social engagement and digital interaction needs in conversations. To validate these findings, we conducted a second study in a realistic conversation scenario involving commodity IoT devices. Results confirmed the utility and social acceptance of the ParaGlassMenu. Based on the results, we discuss implications for designing attention-maintaining subtle interaction techniques on OHMDs.},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Cai, Runze and Janaka, Nuwan and Zhao, Shengdong and Sun, Minghui},
	month = apr,
	year = {2023},
	keywords = {circular menu, conversation, HMD, Internet-of-Things, IoT manipulation, ring interaction, smart glasses, social interaction},
	pages = {1--21},
}








@misc{epson_tech_2020,
	title = {Tech {Specs} - {Moverio} {BT}-300},
	url = {https://tech.moverio.epson.com/en/bt-300/},
	language = {en},
	urldate = {2020-09-21},
	author = {Epson},
	year = {2020},
}


@article{debernardis_text_2014,
	title = {Text {Readability} in {Head}-{Worn} {Displays}: {Color} and {Style} {Optimization} in {Video} versus {Optical} {See}-{Through} {Devices}},
	volume = {20},
	issn = {1077-2626},
	shorttitle = {Text {Readability} in {Head}-{Worn} {Displays}},
	url = {https://doi.org/10.1109/TVCG.2013.86},
	doi = {10.1109/TVCG.2013.86},
	abstract = {Efficient text visualization in head-worn augmented reality (AR) displays is critical because it is sensitive to display technology, text style and color, ambient illumination and so on. The main problem for the developer is to know the optimal text style for the specific display and for applications where color coding must be strictly followed because it is regulated by laws or internal practices. In this work, we experimented the effects on readability of two head-worn devices (optical and video see-through), two backgrounds (light and dark), five colors (white, black, red, green, and blue), and two text styles (plain text and billboarded text). Font type and size were kept constant. We measured the performance of 15 subjects by collecting about 5,000 measurements using a specific test application and followed by qualitative interviews. Readability turned out to be quicker on the optical see-through device. For the video see-through device, background affects readability only in case of text without billboard. Finally, our tests suggest that a good combination for indoor augmented reality applications, regardless of device and background, could be white text and blue billboard, while a mandatory color should be displayed as billboard with a white text message.},
	language = {en},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Debernardis, Saverio and Fiorentino, Michele and Gattullo, Michele and Monno, Giuseppe and Uva, Antonio Emmanuele},
	month = jan,
	year = {2014},
	pages = {125--139},
}


@article{gabbard_effects_2006,
	title = {The {Effects} of {Text} {Drawing} {Styles}, {Background} {Textures}, and {Natural} {Lighting} on {Text} {Legibility} in {Outdoor} {Augmented} {Reality}},
	volume = {15},
	issn = {1054-7460},
        url = {https://doi.org/10.1162/pres.2006.15.1.16},
	doi = {10.1162/pres.2006.15.1.16},
	abstract = {A challenge in presenting augmenting information in outdoor augmented reality (AR) settings lies in the broad range of uncontrollable environmental conditions that may be present, specifically large-scale fluctuations in natural lighting and wide variations in likely backgrounds or objects in the scene. In this paper, we motivate the need for research on the effects of text drawing styles, outdoor background textures, and natural lighting on user performance in outdoor AR. We present a pilot study and a follow-on user-based study that examined the effects on user performance of outdoor background textures, changing outdoor illuminance values, and text drawing styles in a text identification task using an optical, see-through AR system. We report significant effects for all these variables, and discuss user interface design guidelines and ideas for future work.},
	number = {1},
	journal = {Presence},
	author = {Gabbard, Joseph L. and Swan, J. Edward and Hix, Deborah},
	month = feb,
	year = {2006},
	pages = {16--32},
}




@misc{material_typography_2020,
	title = {Typography {Theming}},
	url = {https://material.io/develop/android/theming/typography},
	abstract = {Build beautiful, usable products faster. Material Design is an adaptable system—backed by open-source code—that helps teams build high quality digital experiences.},
	language = {en},
	urldate = {2021-04-08},
	journal = {Material Design},
	year = {2021},
}

@misc{erik_androidmaterial_2020,
	title = {The {Android}/{Material} {Design} {Font} {Size} {Guidelines} (2021)},
	url = {https://learnui.design/blog/android-material-design-font-size-guidelines.html},
	urldate = {2020-04-08},
	author = {Erik, Kennedy},
	year = {2020},
}

@misc{androidtv_typography_2020,
	title = {Typography - {Style} - {Android} {TV}},
	url = {https://learnui.design/blog/android-material-design-font-size-guidelines.html},
	urldate = {2021-04-08},
	year = {2021},
}


@inproceedings{laramee_visual_2001,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '01},
	title = {Visual interference with a transparent head mounted display},
	isbn = {978-1-58113-340-0},
	url = {http://doi.org/10.1145/634067.634258},
	doi = {10.1145/634067.634258},
	abstract = {Potential perceptual problems that may occur with monocular wearable displays are binocular rivalry and visual interference. We report the results from an experiment with a monocular wearable showing that text becomes increasingly difficult to read as the background becomes more complex. Indeed subjects adopted strategies to avoid the visually complex backgrounds and thereby minimize the interference.},
	booktitle = {{CHI} '01 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Laramee, Robert S. and Ware, Colin},
	month = mar,
	year = {2001},
	keywords = {binocular rivalry, head mounted displays, visual interference, wearable computing},
	pages = {323--324},
}


@inproceedings{hart2006nasa,
  title={NASA-task load index (NASA-TLX); 20 years later},
  author={Hart, Sandra G},
  booktitle={Proceedings of the human factors and ergonomics society annual meeting},
  volume={50},
  number={9},
  pages={904--908},
  year={2006},
  organization={Sage publications Sage CA: Los Angeles, CA}
}


@inproceedings{iqbal_disruption_2007,
	title = {Disruption and {Recovery} of {Computing} {Tasks}: {Field} {Study}, {Analysis}, and {Directions}},
	abstract = {We report on a field study of the multitasking behavior of computer users focused on the suspension and resumption of tasks. Data was collected with a tool that logged users’ interactions with software applications and their associated windows, as well as incoming instant messaging and email alerts. We describe methods, summarize results, and discuss design guidelines suggested by the findings.},
	language = {en},
        url={https://doi.org/10.1145/1240624.1240730},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems},
	author = {Iqbal, Shamsi T and Horvitz, Eric},
	year = {2007},
	pages = {10}
}


@article{mccrickard_establishing_2003,
	title = {Establishing tradeoffs that leverage attention for utility: empirically evaluating information display in notification systems},
	volume = {58},
	issn = {10715819},
	shorttitle = {Establishing tradeoffs that leverage attention for utility},
	url = {https://doi.org/10.1016/S1071-5819(03)00022-3},
	doi = {10.1016/S1071-5819(03)00022-3},
	abstract = {Designing and evaluating notiﬁcation systems represents an emerging challenge in the study of human–computer interaction. Users rely on notiﬁcation systems to present potentially interruptive information in an efﬁcient and effective manner to enable appropriate reaction and comprehension. Little is known about the effects of these systems on ongoing computer tasks. As the research community strives to understand information design suitable for opposing usage goals, few existing efforts lend themselves to extensibility.},
	language = {en},
	number = {5},
	journal = {International Journal of Human-Computer Studies},
	author = {McCrickard, D.Scott and Catrambone, Richard and Chewar, C.M and Stasko, John T},
	month = may,
	year = {2003},
	pages = {547--582},
}


@inproceedings{sahami_shirazi_large_scale_2014,
	address = {Toronto, Ontario, Canada},
	title = {Large-scale assessment of mobile notifications},
	isbn = {978-1-4503-2473-1},
	url = {https://doi.org/10.1145/2556288.2557189},
	doi = {10.1145/2556288.2557189},
	abstract = {Notiﬁcations are a core feature of mobile phones. They inform users about a variety of events. Users may take immediate action or ignore them depending on the importance of a notiﬁcation as well as their current context. The nature of notiﬁcations is manifold, applications use them both sparsely and frequently. In this paper we present the ﬁrst large-scale analysis of mobile notiﬁcations with a focus on users’ subjective perceptions. We derive a holistic picture of notiﬁcations on mobile phones by collecting close to 200 million notiﬁcations from more than 40,000 users. Using a data-driven approach, we break down what users like and dislike about notiﬁcations. Our results reveal differences in importance of notiﬁcations and how users value notiﬁcations from messaging apps as well as notiﬁcations that include information about people and events. Based on these results we derive a number of ﬁndings about the nature of notiﬁcations and guidelines to effectively use them.},
	language = {en},
	booktitle = {Proceedings of the 32nd annual {ACM} conference on {Human} factors in computing systems - {CHI} '14},
	publisher = {ACM Press},
	author = {Sahami Shirazi, Alireza and Henze, Niels and Dingler, Tilman and Pielot, Martin and Weber, Dominik and Schmidt, Albrecht},
	year = {2014},
	pages = {3055--3064},
}


@inproceedings{pielot_situ_2014,
	address = {Toronto, ON, Canada},
	title = {An in-situ study of mobile phone notifications},
	isbn = {978-1-4503-3004-6},
	url = {https://doi.org/10.1145/2628363.2628364},
	doi = {10.1145/2628363.2628364},
	abstract = {Notiﬁcations on mobile phones alert users about new messages, emails, social network updates, and other events. However, little is understood about the nature and effect of such notiﬁcations on the daily lives of mobile users. We report from a one-week, in-situ study involving 15 mobile phones users, where we collected real-world notiﬁcations through a smartphone logging application alongside subjective perceptions of those notiﬁcations through an online diary. We found that our participants had to deal with 63.5 notiﬁcations on average per day, mostly from messengers and email. Whether the phone is in silent mode or not, notiﬁcations were typically viewed within minutes. Social pressure in personal communication was amongst the main reasons given. While an increasing number of notiﬁcations was associated with an increase in negative emotions, receiving more messages and social network updates also made our participants feel more connected with others. Our ﬁndings imply that avoiding interruptions from notiﬁcations may be viable for professional communication, while in personal communication, approaches should focus on managing expectations.},
	language = {en},
	booktitle = {Proceedings of the 16th international conference on {Human}-computer interaction with mobile devices \& services - {MobileHCI} '14},
	publisher = {ACM Press},
	author = {Pielot, Martin and Church, Karen and de Oliveira, Rodrigo},
	year = {2014},
	pages = {233--242},
}



@inproceedings{mustonen_examining_2004,
	address = {Vienna, Austria},
	title = {Examining mobile phone text legibility while walking},
	isbn = {978-1-58113-703-3},
	url = {https://doi.org/10.1145/985921.986034},
	doi = {10.1145/985921.986034},
	abstract = {In this study, alternative methods for studying legibility of text while walking with a mobile phone were examined. Normal reading and pseudo-text search were used as visual tasks in four walking conditions. Visual performance and subjective evaluation of task difficulty were used as measures of text legibility. According to the results, visual performance suffers from increasing walking speed, and the effects are greater on reading velocity for pseudo-text search. Subjects also use more homogenous strategies when reading compared to pseudo-text search, and therefore it is concluded that reading is a more useful measure of legibility. Subjective measures are found to be more sensitive to small variations in legibility than objective measures, and give additional information about task demands. Hence, without both objective and subjective measurements important information about legibility in different conditions and with different tasks will be lost.},
	language = {en},
	booktitle = {Extended abstracts of the 2004 conference on {Human} factors and computing systems  - {CHI} '04},
	publisher = {ACM Press},
	author = {Mustonen, Terhi and Olkkonen, Maria and Hakkinen, Jukka},
	year = {2004},
	pages = {1243},

}


@article{sheedy_performance_2002,
	title = {Performance and {Comfort} on {Near}-{Eye} {Computer} {Displays}},
	volume = {79},
	issn = {1538-9235},
	url = {https://journals.lww.com/optvissci/Fulltext/2002/05000/Performance_and_Comfort_on_Near_Eye_Computer.10.aspx},
	abstract = {Background. 
        Very small high-resolution displays (SVGA, 800 × 600 pixels) worn near the eye and imaged to create a virtual image have potential as alternatives to traditional computer displays.
        Methods. 
        Twenty-two subjects performed text-based tasks on five displays: monocular virtual, binocular head-mounted virtual, hard copy, flat panel, and a small format portable display. Outcome measures included performance speed, symptoms, visual acuity, and heterophoria. In a second experiment, subjects performed a proscribed routine of head and body movements designed to elicit motion-related symptoms.
        Results. 
        Performance speed on monocular virtual was generally comparable with performances on flat panel and hard copy. Overall, performance speeds on the binocular virtual display were about 5\% slower than normalized performances, 6.75\% slower compared with the traditional flat panel and hard copy displays. Symptoms of eyestrain and blurry vision were significantly higher on monocular virtual than on other displays. No significant changes in visual acuity or heterophoria occurred with any of the displays. Motion-related symptoms with the head mounted near-eye display were not significantly different than with other displays tested.
        Conclusions. 
        Performance and comfort on the near-eye displays in this study was more similar to traditional displays than in many previous studies with head mounted displays. This is likely due to lack of task movement, partial instead of full immersion, better display resolution, and concordance of the accommodative and vergence stimuli.},
	language = {en-US},
	number = {5},
	journal = {Optometry and Vision Science},
	author = {Sheedy, James and Bergstrom, Neil},
	month = may,
	year = {2002},
	pages = {306--312},
}

@article{Bouma1980VisualRP,
  title={Visual reading processes and the quality of text displays},
  author={H. Bouma},
  journal={IPO Annual Progress Report},
  year={1980},
  volume={15},
  pages={83-90}
}


@article{santangelo_perceptual_2008,
	title = {Perceptual load affects exogenous spatial orienting while working memory load does not},
	volume = {184},
	issn = {1432-1106},
	url = {https://doi.org/10.1007/s00221-007-1108-8},
	doi = {10.1007/s00221-007-1108-8},
	abstract = {We examined whether or not increasing visual perceptual load or visual working memory (WM) load would affect the exogenous orienting of visuo-spatial attention, in order to assess whether or not exogenous orienting is genuinely automatic. In Experiment 1, we manipulated visual perceptual load by means of a central morphing shape that in some trials morphed into a particular target shape (a rectangle) that participants had to detect. In Experiment 2, the possibility that the presentation of any changing stimulus at fixation would eliminate exogenous orienting was ruled out, by presenting two alternating letters at fixation. In Experiment 3, we manipulated visual WM load by means of arrays consisting of three (low-load) or five (high-load) randomly located coloured squares. The participants had to remember these items in order to judge whether a cued square had been presented in the same or different colour at the end of each trial. In all the experiments, exogenous visuo-spatial attentional orienting was measured by means of an orthogonal spatial cuing task, in which the participants had to discriminate the elevation (up vs. down) of a visual target previously cued by a spatially nonpredictive visual cue. The results showed that increasing the perceptual load of the task eliminated the exogenous orienting of visuo-spatial attention. By contrast, increasing the WM load had no effect on spatial orienting. These results are discussed in terms of the light that they shed on claims regarding the automaticity of visuo-spatial exogenous orienting.},
	language = {en},
	number = {3},
	journal = {Experimental Brain Research},
	author = {Santangelo, Valerio and Finoia, Paola and Raffone, Antonino and Olivetti Belardinelli, Marta and Spence, Charles},
	month = jan,
	year = {2008},
	pages = {371--382},
}

@article{mustonen_visual_2013,
	title = {Visual {Task} {Performance} {Using} a {Monocular} {See}-{Through} {Head}-{Mounted} {Display} ({HMD}) {While} {Walking}},
	abstract = {A monocular see-through head-mounted display (HMD) allows the user to view displayed information while simultaneously interacting with the surrounding environment. This configuration lets people use HMDs while they are moving, such as while walking. However, sharing attention between the display and environment can compromise a person’s performance in any ongoing task, and controlling one’s gait may add further challenges. In this study, the authors investigated how the requirements of HMDadministered visual tasks altered users’ performance while they were walking. Twenty-four university students completed 3 cognitive tasks (high- and low-working memory load, visual vigilance) on an HMD while seated and while simultaneously performing a paced walking task in a controlled environment. The results show that paced walking worsened performance (d=, reaction time) in all HMD-administered tasks, but visual vigilance deteriorated more than memory performance. The HMD-administered tasks also worsened walking performance (speed, path overruns) in a manner that varied according to the overall demands of the task. These results suggest that people’s ability to process information displayed on an HMD may worsen while they are in motion. Furthermore, the use of an HMD can critically alter a person’s natural performance, such as their ability to guide and control their gait. In particular, visual tasks that involve constant monitoring of the HMD should be avoided. These findings highlight the need for careful consideration of the type and difficulty of information that can be presented through HMDs while still letting the user achieve an acceptable overall level of performance in various contexts of use.},
	language = {en},
	author = {Mustonen, Terhi and Berg, Mikko and Kaistinen, Jyrki and Kawai, Takashi and Häkkinen, Jukka},
        url={https://doi.org/10.1037/a0034635},
	year = {2013},
	pages = {12},
}

@article{peirce_psychopy2_2019,
	title = {{PsychoPy2}: {Experiments} in behavior made easy},
	volume = {51},
	issn = {1554-3528},
	shorttitle = {{PsychoPy2}},
	url = {https://doi.org/10.3758/s13428-018-01193-y},
	doi = {10.3758/s13428-018-01193-y},
	abstract = {PsychoPy is an application for the creation of experiments in behavioral science (psychology, neuroscience, linguistics, etc.) with precise spatial control and timing of stimuli. It now provides a choice of interface; users can write scripts in Python if they choose, while those who prefer to construct experiments graphically can use the new Builder interface. Here we describe the features that have been added over the last 10 years of its development. The most notable addition has been that Builder interface, allowing users to create studies with minimal or no programming, while also allowing the insertion of Python code for maximal flexibility. We also present some of the other new features, including further stimulus options, asynchronous time-stamped hardware polling, and better support for open science and reproducibility. Tens of thousands of users now launch PsychoPy every month, and more than 90 people have contributed to the code. We discuss the current state of the project, as well as plans for the future.},
	language = {en},
	number = {1},
	journal = {Behavior Research Methods},
	author = {Peirce, Jonathan and Gray, Jeremy R. and Simpson, Sol and MacAskill, Michael and Höchenberger, Richard and Sogo, Hiroyuki and Kastman, Erik and Lindeløv, Jonas Kristoffer},
	month = feb,
	year = {2019},
	pages = {195--203}
}


@inproceedings{chua_positioning_2016,
	address = {San Jose, USA},
	title = {Positioning {Glass}: {Investigating} {Display} {Positions} of {Monocular} {Optical} {See}-{Through} {Head}-{Mounted} {Display}},
	isbn = {978-1-4503-4760-0},
	shorttitle = {Positioning {Glass}},
	url = {https://doi.org/10.1145/2948708.2948713},
	doi = {10.1145/2948708.2948713},
	language = {en},
	booktitle = {Proceedings of the {Fourth} {International} {Symposium} on {Chinese} {CHI} - {ChineseCHI2016}},
	publisher = {ACM Press},
	author = {Chua, Soon Hau and Perrault, Simon T. and Matthies, Denys J. C. and Zhao, Shengdong},
	year = {2016},
	pages = {1--6},
}


@incollection{ramachandran_vigilance_2002,
	address = {New York},
	title = {Vigilance},
	isbn = {978-0-12-227210-3},
	url = {https://doi.org/10.1016/B0-12-227210-2/00357-5},
	booktitle = {Encyclopedia of the {Human} {Brain}},
	publisher = {Academic Press},
	author = {Sarter, Martin and Bruno, John P.},
	editor = {Ramachandran, V. S.},
	year = {2002},
	doi = {10.1016/B0-12-227210-2/00357-5},
	pages = {687--699},
}

@incollection{hutchison_image_2012,
	address = {Berlin, Heidelberg},
	title = {Image {Abstraction} in {Crossmedia} {Retrieval} for {Text} {Illustration}},
	volume = {7224},
	isbn = {978-3-642-28997-2},
	url = {https://doi.org/10.1007/978-3-642-28997-2_28},
	abstract = {Text illustration is a multimedia retrieval task that consists in ﬁnding suitable images to illustrate text fragments such as blog entries, news reports or children stories. In this paper we describe a crossmedia retrieval system which, given a textual input, selects a short list of candidate images from a large media collection. This approach makes use of a recently proposed method to map metadata and visual features into a common textual representation that can be handled by traditional information retrieval engines. Content-based analysis is enhanced by visual abstraction, namely the Anisotropic Kuwahara Filter, which impacts feature information captured by the Joint Composite and Speeded Up Robust Features visual descriptors. For evaluation purposes, we used the wellestablished MIRFlickr photo collection, with 25,000 photos and user tags collected from Flickr as well as manual annotations provided as image retrieval groundtruth. Results show that image abstraction can improve visual retrieval as well as signiﬁcantly reduce processing and storage requirements, even more when paired with Google’s WebP image format. We conclude that applying a visual rerank after an initial text retrieval step improves the quality of results, and that the adopted text mapping method for visual descriptors provides an eﬀective crossmedia approach for text illustration.},
	language = {en},
	booktitle = {Advances in {Information} {Retrieval}},
	publisher = {Springer Berlin Heidelberg},
	author = {Coelho, Filipe and Ribeiro, Cristina},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Baeza-Yates, Ricardo and de Vries, Arjen P. and Zaragoza, Hugo and Cambazoglu, B. Barla and Murdock, Vanessa and Lempel, Ronny and Silvestri, Fabrizio},
	year = {2012},
	doi = {10.1007/978-3-642-28997-2_28},
	pages = {329--339},
}

@incollection{hutchison_every_2010,
	address = {Berlin, Heidelberg},
	title = {Every {Picture} {Tells} a {Story}: {Generating} {Sentences} from {Images}},
	volume = {6314},
	isbn = {978-3-642-15561-1},
	shorttitle = {Every {Picture} {Tells} a {Story}},
	url = {https://doi.org/10.1007/978-3-642-15561-1_2},
	abstract = {Humans can prepare concise descriptions of pictures, focusing on what they ﬁnd important. We demonstrate that automatic methods can do so too. We describe a system that can compute a score linking an image to a sentence. This score can be used to attach a descriptive sentence to a given image, or to obtain images that illustrate a given sentence. The score is obtained by comparing an estimate of meaning obtained from the image to one obtained from the sentence. Each estimate of meaning comes from a discriminative procedure that is learned using data. We evaluate on a novel dataset consisting of human-annotated images. While our underlying estimate of meaning is impoverished, it is suﬃcient to produce very good quantitative results, evaluated with a novel score that can account for synecdoche.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2010},
	publisher = {Springer Berlin Heidelberg},
	author = {Farhadi, Ali and Hejrati, Mohsen and Sadeghi, Mohammad Amin and Young, Peter and Rashtchian, Cyrus and Hockenmaier, Julia and Forsyth, David},
	editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
	year = {2010},
	doi = {10.1007/978-3-642-15561-1_2},
	pages = {15--29},
}

@article{nasa_tlx_2006,
    author = {Sandra G. Hart},
    title ={Nasa-Task Load Index (NASA-TLX); 20 Years Later},
    journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
    volume = {50},
    number = {9},
    pages = {904-908},
    year = {2006},
    doi = {10.1177/154193120605000909},
    URL = { https://doi.org/10.1177/154193120605000909},
    abstract = { NASA-TLX is a multi-dimensional scale designed to obtain workload estimates from one or more operators while they are performing a task or immediately afterwards. The years of research that preceded subscale selection and the weighted averaging approach resulted in a tool that has proven to be reasonably easy to use and reliably sensitive to experimentally important manipulations over the past 20 years. Its use has spread far beyond its original application (aviation), focus (crew complement), and language (English). This survey of 550 studies in which NASA-TLX was used or reviewed was undertaken to provide a resource for a new generation of users. The goal was to summarize the environments in which it has been applied, the types of activities the raters performed, other variables that were measured that did (or did not) covary, methodological issues, and lessons learned }
}


@article{huberty1992multivariate,
  title={Multivariate analysis versus multiple univariate analyses.},
  author={Huberty, Carl J and Morris, John D},
  year={1992},
  publisher={American Psychological Association}
}

@article{stanislaw_calculation_1999,
	title = {Calculation of signal detection theory measures},
	volume = {31},
	issn = {0743-3808, 1532-5970},
	url = {https://doi.org/10.3758/BF03207704},
	doi = {10.3758/BF03207704},
	language = {en},
	number = {1},
	journal = {Behavior Research Methods, Instruments, \& Computers},
	author = {Stanislaw, Harold and Todorov, Natasha},
	month = mar,
	year = {1999},
	pages = {137--149},
}

@inproceedings{rzayev_effects_2020,
	address = {Tallinn Estonia},
	title = {Effects of {Position} and {Alignment} of {Notifications} on {AR} {Glasses} during {Social} {Interaction}},
	isbn = {978-1-4503-7579-5},
	url = {https://doi.org/10.1145/3419249.3420095},
	doi = {10.1145/3419249.3420095},
	abstract = {Notifications are one of the smartphones’ key features. However, notifications can be disruptive, especially during social interaction. Augmented reality (AR) glasses can embed notifications directly into the user’s field of view and enable reading them while being engaged in a primary task. However, for efficient notification presentation using AR glasses, it is necessary to understand how notifications should be displayed without negatively affecting social interaction. Therefore, we conducted a study with 32 participants (16 pairs) using AR glasses to investigate how to display notifications during face-to-face communication. We compared center and top-right positions for notifications while aligning them relative to the user’s field of view or with the conversation partner. We found significant effects of notification position and alignment on how notifications are perceived using AR glasses during face-to-face communication. Insights from our study inform the design of applications for AR glasses that support displaying digital notifications.},
	language = {en},
	booktitle = {Proceedings of the 11th {Nordic} {Conference} on {Human}-{Computer} {Interaction}: {Shaping} {Experiences}, {Shaping} {Society}},
	publisher = {ACM},
	author = {Rzayev, Rufat and Korbely, Susanne and Maul, Milena and Schark, Alina and Schwind, Valentin and Henze, Niels},
	month = oct,
	year = {2020},
	pages = {1--11},
}


@article{redick_cognitive_2016,
	title = {Cognitive {Predictors} of a {Common} {Multitasking} {Ability}: {Contributions} {From} {Working} {Memory}, {Attention} {Control}, and {Fluid} {Intelligence}},
	volume = {145},
	shorttitle = {Cognitive predictors of a common multitasking ability},
	url = {https://doi.org/10.1037/xge0000219},
	doi = {10.1037/xge0000219},
	abstract = {Previous research has identified several cognitive abilities that are important for multitasking, but few studies have attempted to measure a general multitasking ability using a diverse set of multitasks. In the final dataset, 534 young adult subjects completed measures of working memory (WM), attention control, fluid intelligence, and multitasking. Correlations, hierarchical regression analyses, confirmatory factor analyses, structural equation models, and relative weight analyses revealed several key findings. First, although the complex tasks used to assess multitasking differed greatly in their task characteristics and demands, a coherent construct specific to multitasking ability was identified. Second, the cognitive ability predictors accounted for substantial variance in the general multitasking construct, with WM and fluid intelligence accounting for the most multitasking variance compared to attention control. Third, the magnitude of the relationships among the cognitive abilities and multitasking varied as a function of the complexity and structure of the various multitasks assessed. Finally, structural equation models based on a multifaceted model of WM indicated that attention control and capacity fully mediated the WM and multitasking relationship.},
	language = {en},
	number = {11},
	journal = {Journal of Experimental Psychology. General},
	author = {Redick, Thomas S and Shipstead, Zach and Meier, Matthew E and Montroy, Janelle J and Hicks, Kenny L and Unsworth, Nash and Kane, Michael J and Hambrick, D Zachary and Engle, Randall W},
	month = nov,
	year = {2016},
	keywords = {Adolescent, Adult, Aptitude, Attention, Auditory Perception, Cognition, Female, Humans, Intelligence, Male, Memory, Short-Term, Problem Solving, Psychomotor Performance, Reaction Time, Saccades, Space Perception, Visual Perception, Young Adult},
	pages = {1473--1492},
}


@book{caplin_2001_icon,
  title={Icon design: Graphic icons in computer interface design},
  author={Caplin, Steve},
  year={2001},
  publisher={Watson-Guptill Publications, Inc.}
}


@article{isherwood_icon_2007,
	title = {Icon {Identification} in {Context}: {The} {Changing} {Role} of {Icon} {Characteristics} {With} {User} {Experience}},
	volume = {49},
	issn = {0018-7208, 1547-8181},
	shorttitle = {Icon {Identification} in {Context}},
	url = {https://doi.org/10.1518/001872007X200102},
	doi = {10.1518/001872007X200102},
	language = {en},
	number = {3},
	journal = {Human Factors: The Journal of the Human Factors and Ergonomics Society},
	author = {Isherwood, Sarah J. and McDougall, Siné J. P. and Curry, Martin B.},
	month = jun,
	year = {2007},
	pages = {465--476},
}


@inproceedings{wobbrock_aligned_2011,
	address = {New York, NY, USA},
	series = {{CHI} '11},
	title = {The aligned rank transform for nonparametric factorial analyses using only anova procedures},
	isbn = {978-1-4503-0228-9},
	url = {https://doi.org/10.1145/1978942.1978963},
	doi = {10.1145/1978942.1978963},
	abstract = {Nonparametric data from multi-factor experiments arise often in human-computer interaction (HCI). Examples may include error counts, Likert responses, and preference tallies. But because multiple factors are involved, common nonparametric tests (e.g., Friedman) are inadequate, as they are unable to examine interaction effects. While some statistical techniques exist to handle such data, these techniques are not widely available and are complex. To address these concerns, we present the Aligned Rank Transform (ART) for nonparametric factorial data analysis in HCI. The ART relies on a preprocessing step that "aligns" data before applying averaged ranks, after which point common ANOVA procedures can be used, making the ART accessible to anyone familiar with the F-test. Unlike most articles on the ART, which only address two factors, we generalize the ART to N factors. We also provide ARTool and ARTweb, desktop and Web-based programs for aligning and ranking data. Our re-examination of some published HCI results exhibits advantages of the ART.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Wobbrock, Jacob O. and Findlater, Leah and Gergle, Darren and Higgins, James J.},
	month = may,
	year = {2011},
	keywords = {statistics, analysis of variance, anova, f-test, factorial analysis, nonparametric data},
	pages = {143--146},
}


@article{mccrickard_model_2003,
	title = {A model for notification systems evaluation—assessing user goals for multitasking activity},
	volume = {10},
	issn = {1073-0516, 1557-7325},
	url = {https://doi.org/10.1145/966930.966933},
	doi = {10.1145/966930.966933},
	language = {en},
	number = {4},
	journal = {ACM Transactions on Computer-Human Interaction (TOCHI)},
	author = {McCrickard, D. Scott and Chewar, C. M. and Somervell, Jacob P. and Ndiwalana, Ali},
	month = dec,
	year = {2003},
	keywords = {claims reuse, design model, Peripheral systems, usability},
	pages = {312--338},
}


@article{mccrickard_attuning_2003,
	title = {Attuning notification design to user goals and attention costs},
	volume = {46},
	issn = {00010782},
	url = {https://doi.org/10.1145/636772.636800},
	doi = {10.1145/636772.636800},
	language = {en},
	number = {3},
	journal = {Communications of the ACM},
	author = {McCrickard, D. Scott and Chewar, C. M.},
	month = mar,
	year = {2003},
	pages = {67},
}

@article{sabelman_real_life_2015,
	title = {The real-life dangers of augmented reality},
	volume = {52},
	issn = {0018-9235},
	url = {https://doi.org/10.1109/MSPEC.2015.7131695},
	doi = {10.1109/MSPEC.2015.7131695},
	language = {en},
	number = {7},
	journal = {IEEE Spectrum},
	author = {Sabelman, Eric E. and Lam, Roger},
	month = jul,
	year = {2015},
	pages = {48--53},
}


@article{laramee_rivalry_2002,
	title = {Rivalry and interference with a head-mounted display},
	volume = {9},
	issn = {1073-0516},
	url = {https://doi.org/10.1145/568513.568516},
	doi = {10.1145/568513.568516},
	abstract = {Perceptual factors that affect monocular, transparent (a.k.a "see-thru") head-mounted displays include binocular rivalry, visual interference, and depth of focus. We report the results of an experiment designed to evaluate the effects of these factors on user performance in a table look-up task. Two backgrounds were used. A dynamic moving background was provided by a large screen TV and an untidy bookshelf was used to provide a complex static background. With the TV background large effects were found attributable to both rivalry and visual interference. These two effects were roughly additive. Smaller effects were found with the bookshelf. In conclusion we suggest that monocular transparent HMDs may be unsuitable for use in visually dynamic environments. However when backgrounds are relatively static, having a transparent display may be preferable to having an opaque display.},
	number = {3},
	journal = {ACM Transactions on Computer-Human Interaction},
	author = {Laramee, Robert S. and Ware, Colin},
	month = sep,
	year = {2002},
	keywords = {augmented reality, binocular rivalry, head-mounted display, heads-up display, mobile computing devices, see-thru Display, visual interference, Wearable computing},
	pages = {238--251},
}


@inproceedings{iqbal_notifications_2010,
	address = {Savannah, Georgia, USA},
	title = {Notifications and awareness: a field study of alert usage and preferences},
	isbn = {978-1-60558-795-0},
	shorttitle = {Notifications and awareness},
	url = {https://doi.org/10.1145/1718918.1718926},
	doi = {10.1145/1718918.1718926},
	abstract = {Desktop notifications are designed to provide awareness of information while a user is attending to a primary task. Unfortunately the awareness can come with the price of disruption to the focal task. We review results of a field study on the use and perceived value of email notifications in the workplace. We recorded users’ interactions with software applications for two weeks and studied how notifications or their forced absence influenced users’ quest for awareness of new email arrival, as well as the impact of notifications on their overall task focus. Results showed that users view notifications as a mechanism to provide passive awareness rather than a trigger to switch tasks. Turing off notifications cause some users to self interrupt more to explicitly monitor email arrival, while others appear to be able to better focus on their tasks. Users acknowledge notifications as disruptive, yet opt for them because of their perceived value in providing awareness.},
	language = {en},
	booktitle = {Proceedings of the 2010 {ACM} conference on {Computer} supported cooperative work - {CSCW} '10},
	publisher = {ACM Press},
	author = {Iqbal, Shamsi T. and Horvitz, Eric},
	year = {2010},
	pages = {27},
}

@inproceedings{pielot_productive_2017,
    author = {Pielot, Martin and Rello, Luz},
    title = {Productive, Anxious, Lonely: 24 Hours without Push Notifications},
    year = {2017},
    isbn = {9781450350754},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3098279.3098526},
    doi = {10.1145/3098279.3098526},
    abstract = {We report from the Do Not Disturb Challenge where 30 volunteers disabled notification alerts for 24 hours across all devices. The effect of the absence of notifications on the participants was isolated through an experimental study design: we compared self-reported feedback from the day without notifications against a baseline day. The evidence indicates that notifications have locked us in a dilemma: without notifications, participants felt less distracted and more productive. But, they also felt no longer able to be as responsive as expected, which made some participants anxious. And, they felt less connected with one's social group. In contrast to previous reports, about two third of the participants expressed the intention to change how they manage notifications. Two years later, half of the participants are still following through with their plans.},
    booktitle = {Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services},
    articleno = {11},
    numpages = {11},
    keywords = {notifications, mobile devices, deprivation study},
    location = {Vienna, Austria},
    series = {MobileHCI '17}
}

@article{bailey_effects_2001,
	series = {Human-{Computer} {Interaction} \{{INTERACT}\} '01},
	title = {The {Effects} of {Interruptions} on {Task} {Performance}, {Annoyance}, and {Anxiety} in the {User} {Interface}},
	abstract = {When an automating application needs a user’s input or has feedback or other information for that user, it typically engages the user immediately, interrupting the user’s current task. To empirically validate why unnecessarily interrupting a user’s task should be avoided, we designed an experiment measuring the effects of an interruption on a user’s task performance, annoyance, and anxiety. Fifty subjects participated in the experiment. The results demonstrate that an interruption has a disruptive effect on both a user’s task performance and emotional state, and that the degree of disruption depends on the user’s mental load at the point of interruption. We discuss the implications of these results in terms of building a system to better coordinate interactions between the user and applications competing for that user’s attention.},
	language = {en},
	journal = {International Conference on Human-Computer Interaction},
	author = {Bailey, Brian P and Konstan, Joseph A and Carlis, John V},
	year = {2001},
	pages = {593--601},
}


@inproceedings{cutrell_notification_2001,
	title = {Notification, {Disruption}, and {Memory}: {Effects} of {Messaging} {Interruptions} on {Memory} and {Performance}},
	url = {https://www.microsoft.com/en-us/research/publication/notification-disruption-and-memory-effects-of-messaging-interruptions-on-memory-and-performance/},
	abstract = {We describe a study on the influence of instant messaging (IM) on ongoing computing tasks. The study both replicates and extends earlier work on the cost of sending notifications at different times and the sensitivity of different tasks to interruption. We investigate alternative hypotheses about the nature of disruption for a list evaluation task, an activity identified as being particularly costly to interrupt. Our findings once again show the generally disruptive effects of IM, especially during fast, stimulus-driven search tasks. In addition, we show that interruptions coming early during a search task are more likely to result in the user forgetting the primary task goal than interruptions that arrive later on. These findings have implications for the design of user interfaces and notification policies that minimize the disruptiveness of notifications.},
	booktitle = {{INTERACT} 2001},
	publisher = {IOS Press},
	author = {Cutrell, Ed and Czerwinski, Mary and Horvitz, Eric},
	month = jan,
	year = {2001},
	pages = {263--269},
}


@inproceedings{weber_snooze_2018,
	address = {Barcelona Spain},
	title = {Snooze!: investigating the user-defined deferral of mobile notifications},
	isbn = {978-1-4503-5898-9},
	shorttitle = {Snooze!},
	url = {https://doi.org/10.1145/3229434.3229436},
	doi = {10.1145/3229434.3229436},
	abstract = {Notiﬁcations on mobile devices are a prominent source of interruptions. Previous work suggests using opportune moments to deliver notiﬁcations to reduce negative effects. In this paper, we instead explore the manual deferral of notiﬁcations. We developed an Android app that allows users to “snooze” mobile notiﬁcations for a user-deﬁned amount of time or to a user-deﬁned point in time. Using this app, we conducted a year-long in-the-wild study with 295 active users. To complement the ﬁndings, we recruited 16 further participants who used the app for one week and subsequently interviewed them. In both studies, snoozing was mainly used to defer notiﬁcations related to people and events. The reasons for deferral were manifold, from not being able to attend notiﬁcations immediately to not wanting to. Daily routines played an important role in the deferral of notiﬁcations. Most notiﬁcations were deferred to the same day or next morning, and a deferral of more than two days was an exception. Based on our ﬁndings, we derive design implications that can inform the design of future smart notiﬁcation systems.},
	language = {en},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Weber, Dominik and Voit, Alexandra and Auda, Jonas and Schneegass, Stefan and Henze, Niels},
	month = sep,
	year = {2018},
	pages = {1--13},
}


@inproceedings{ho_using_2005,
	address = {Portland, Oregon, USA},
	title = {Using context-aware computing to reduce the perceived burden of interruptions from mobile devices},
	isbn = {978-1-58113-998-3},
	url = {https://doi.org/10.1145/1054972.1055100},
	doi = {10.1145/1054972.1055100},
	abstract = {The potential for sensor-enabled mobile devices to proactively present information when and where users need it ranks among the greatest promises of ubiquitous computing. Unfortunately, mobile phones, PDAs, and other computing devices that compete for the user’s attention can contribute to interruption irritability and feelings of information overload. Designers of mobile computing interfaces, therefore, require strategies for minimizing the perceived interruption burden of proactively delivered messages. In this work, a contextaware mobile computing device was developed that automatically detects postural and ambulatory activity transitions in real time using wireless accelerometers. This device was used to experimentally measure the receptivity to interruptions delivered at activity transitions relative to those delivered at random times. Messages delivered at activity transitions were found to be better received, thereby suggesting a viable strategy for context-aware message delivery in sensorenabled mobile computing devices.},
	language = {en},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems  - {CHI} '05},
	publisher = {ACM Press},
	author = {Ho, Joyce and Intille, Stephen S.},
	year = {2005},
	pages = {909},
}

@article{mehrotra_intelligent_2018,
	title = {Intelligent {Notification} {Systems}: {A} {Survey} of the {State} of the {Art} and {Research} {Challenges}},
	shorttitle = {Intelligent {Notification} {Systems}},
	url = {http://arxiv.org/abs/1711.10171},
	abstract = {Notifications provide a unique mechanism for increasing the effectiveness of real-time information delivery systems. However, notifications that demand users' attention at inopportune moments are more likely to have adverse effects and might become a cause of potential disruption rather than proving beneficial to users. In order to address these challenges a variety of intelligent notification mechanisms based on monitoring and learning users' behavior have been proposed. The goal of such mechanisms is maximizing users' receptivity to the delivered information by automatically inferring the right time and the right context for sending a certain type of information. This article provides an overview of the current state of the art in the area of intelligent notification mechanisms that relies on the awareness of users' context and preferences. More specifically, we first present a survey of studies focusing on understanding and modeling users' interruptibility and receptivity to notifications from desktops and mobile devices. Then, we discuss the existing challenges and opportunities in developing mechanisms for intelligent notification systems in a variety of application scenarios.},
	language = {en},
	journal = {arXiv:1711.10171 [cs]},
	author = {Mehrotra, Abhinav and Musolesi, Mirco},
	month = jan,
	year = {2018},
}


@inproceedings{luyten_hidden_2016,
	address = {Santa Clara, California, USA},
	title = {Hidden in {Plain} {Sight}: an {Exploration} of a {Visual} {Language} for {Near}-{Eye} {Out}-of-{Focus} {Displays} in the {Peripheral} {View}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {Hidden in {Plain} {Sight}},
	url = {https://doi.org/10.1145/2858036.2858339},
	doi = {10.1145/2858036.2858339},
	abstract = {In this paper, we set out to ﬁnd what encompasses an appropriate visual language for information presented on neareye out-of-focus displays. These displays are positioned in a user’s peripheral view, very near to the user’s eyes, for example on the inside of the temples of a pair of glasses. We explored the usable display area, the role of spatial and retinal variables, and the inﬂuence of motion and interaction for such a language. Our ﬁndings show that a usable visual language can be accomplished by limiting the possible shapes and by making clever use of orientation and meaningful motion. We found that especially motion is very important to improve perception and comprehension of what is being displayed on near-eye out-of-focus displays, and that perception is further improved if direct interaction with the content is allowed.},
	language = {en},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '16},
	publisher = {ACM Press},
	author = {Luyten, Kris and Degraen, Donald and Rovelo Ruiz, Gustavo and Coppers, Sven and Vanacken, Davy},
	year = {2016},
	pages = {487--497},
}

@inproceedings{poppinga_ambiglasses_2012,
	title = {{AmbiGlasses} – {Information} in the {Periphery} of the {Visual} {Field}},
	abstract = {While more and more digital information becomes available, the demand to access information whenever and wherever increases. However, ubiquitous information provision often interferes with the user's primary tasks such as walking, driving, or reading. In this paper we present a mobile device called AmbiGlasses, a pair of glasses with 12 LEDs that illuminate the periphery of the user's field of view. A conducted user study shows that participants are able to locate the correct LED with 71\% accuracy and estimate the rough location of the LED with 92\% accuracy. Participants were further asked to exemplary design visualization configurations for four directions. Consistent results show that different participants encode directions with similar patterns. We argue that the AmbiGlasses can therefore be used to convey clear and intuitive navigation instructions.},
	language = {en},
	booktitle = {Mensch \& {Computer} 2012: interaktiv informiert – allgegenwärtig und allumfassend!?},
	author = {Poppinga, Benjamin and Henze, Niels and Fortmann, Jutta and Heuten, Wilko},
	year = {2012},
	pages = {153--162},
}

@inproceedings{nakuo_smart_2016,
	address = {Heidelberg Germany},
	title = {Smart glasses with a peripheral vision display},
	isbn = {978-1-4503-4462-3},
	url = {https://doi.org/10.1145/2968219.2971393},
	doi = {10.1145/2968219.2971393},
	abstract = {We present a demonstration of an initial peripheral vision glasses prototype. We can display patterns in the peripheral vision of the user. A simple use case is to show notiﬁcations. Up to 8 different notiﬁcation types can be distinguished. We also suggest to use it to modify walking speed of users (depending on the animations people tend to speed up or slow down).},
	language = {en},
	booktitle = {Proceedings of the 2016 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}: {Adjunct}},
	publisher = {ACM},
	author = {Nakuo, Takuro and Kunze, Kai},
	month = sep,
	year = {2016},
	pages = {341--344},
}


@inproceedings{costanza_eye_q_2006,
	address = {Helsinki, Finland},
	title = {eye-q: eyeglass peripheral display for subtle intimate notifications},
	isbn = {978-1-59593-390-4},
	shorttitle = {eye-q},
	url = {https://doi.org/10.1145/1152215.1152261},
	doi = {10.1145/1152215.1152261},
	abstract = {Mobile devices are generally used in public, where the user is surrounded by others not involved in the interaction. Audible notification cues are often a cause of unnecessary disruption and distraction both for co-located people and even for the user to whom they are directed. We present a wearable peripheral display embedded in eyeglasses that delivers subtle, discreet and unobtrusive cues. The display is personal and intimate; it delivers visual cues in the wearers’ periphery without disrupting their immediate environment. A user study conducted to validate the design reveals that the display is effective and subtle in notifying users. Experimental results show, with significance, that the cues can be designed to meet specific levels of visibility and disruption for the wearer, so that some cues are less noticeable when the user is not under high workload, which is highly desirable in many practical circumstances. Hence, peripheral notification displays can provide an effective solution for designing socially acceptable notification displays, unobtrusive to the user and the immediate environment.},
	language = {en},
	booktitle = {Proceedings of the 8th conference on {Human}-computer interaction with mobile devices and services  - {MobileHCI} '06},
	publisher = {ACM Press},
	author = {Costanza, Enrico and Inverso, Samuel A. and Pavlov, Elan and Allen, Rebecca and Maes, Pattie},
	year = {2006},
	pages = {211},
}


@inproceedings{ishiguro_peripheral_2011,
	address = {Tokyo, Japan},
	title = {Peripheral vision annotation: noninterference information presentation method for mobile augmented reality},
	isbn = {978-1-4503-0426-9},
	shorttitle = {Peripheral vision annotation},
	url = {https://doi.org/10.1145/1959826.1959834},
	doi = {10.1145/1959826.1959834},
	abstract = {Augmented-reality (AR) systems present information about a user’s surrounding environment by overlaying it on the user’s real-world view. However, such overlaid information tends to obscure a user’s field of view and thus impedes a user’s realworld activities. This problem is especially critical when a user is wearing a head-mounted display. In this paper, we propose an information presentation mechanism for mobile AR systems by focusing on the user’s gaze information and peripheral vision field. The gaze information is used to control the positions and the level-of-detail of the information overlaid on the user’s field of view. We also propose a method for switching displayed information based on the difference in human visual perception between the peripheral and central visual fields. We develop a mobile AR system to test our proposed method consisting of a gaze-tracking system and a retinal imaging display. The eyetracking system estimates whether the user’s visual focus is on the information display area or not, and changes the information type from simple to detailed information accordingly.},
	language = {en},
	booktitle = {Proceedings of the 2nd {Augmented} {Human} {International} {Conference} on - {AH} '11},
	publisher = {ACM Press},
	author = {Ishiguro, Yoshio and Rekimoto, Jun},
	year = {2011},
	pages = {1--5},
}


@inproceedings{tanveer_rhema_2015,
	address = {Atlanta, Georgia, USA},
	title = {Rhema: {A} {Real}-{Time} {In}-{Situ} {Intelligent} {Interface} to {Help} {People} with {Public} {Speaking}},
	isbn = {978-1-4503-3306-1},
	shorttitle = {Rhema},
	url = {https://doi.org/10.1145/2678025.2701386},
	doi = {10.1145/2678025.2701386},
	abstract = {A large number of people rate public speaking as their top fear. What if these individuals were given an intelligent interface that provides live feedback on their speaking skills? In this paper, we present Rhema, an intelligent user interface for Google Glass to help people with public speaking. The interface automatically detects the speaker’s volume and speaking rate in real time and provides feedback during the actual delivery of speech. While designing the interface, we experimented with two different strategies of information delivery: 1) Continuous streams of information, and 2) Sparse delivery of recommendation. We evaluated our interface with 30 native English speakers. Each participant presented three speeches (avg. duration 3 minutes) with 2 different feedback strategies (continuous, sparse) and a baseline (no feeback) in a random order. The participants were significantly more pleased (p {\textless} 0.05) with their speech while using the sparse feedback strategy over the continuous one and no feedback.},
	language = {en},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Intelligent} {User} {Interfaces} - {IUI} '15},
	publisher = {ACM Press},
	author = {Tanveer, M. Iftekhar and Lin, Emy and Hoque, Mohammed (Ehsan)},
	year = {2015},
	keywords = {augmented-reality, live-feedback, public-speaking},
	pages = {286--295},
}

@inproceedings{damian_augmenting_2015,
	address = {Seoul, Republic of Korea},
	title = {Augmenting {Social} {Interactions}: {Realtime} {Behavioural} {Feedback} using {Social} {Signal} {Processing} {Techniques}},
	isbn = {978-1-4503-3145-6},
	shorttitle = {Augmenting {Social} {Interactions}},
	url = {https://doi.org/10.1145/2702123.2702314},
	doi = {10.1145/2702123.2702314},
	abstract = {Nonverbal and unconscious behaviour is an important component of daily human-human interaction. This is especially true in situations such as public speaking, job interviews or information sensitive conversations, where researchers have shown that an increased awareness of one’s behaviour can improve the outcome of the interaction. With wearable technology, such as Google Glass, we now have the opportunity to augment social interactions and provide realtime feedback on one’s behaviour in an unobtrusive way. In this paper we present Logue, a system that provides realtime feedback on the presenters’ openness, body energy and speech rate during public speaking. The system analyses the user’s nonverbal behaviour using social signal processing techniques and gives visual feedback on a head-mounted display. We conducted two user studies with a staged and a real presentation scenario which yielded that Logue’s feedback was perceived helpful and had a positive impact on the speaker’s performance.},
	language = {en},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '15},
	publisher = {ACM Press},
	author = {Damian, Ionut and Tan, Chiew Seng (Sean) and Baur, Tobias and Schöning, Johannes and Luyten, Kris and André, Elisabeth},
	year = {2015},
	pages = {565--574},
}

@inproceedings{lauber_your_face_2014,
	address = {Toronto, Ontario, Canada},
	title = {In-your-face, yet unseen?: improving head-stabilized warnings to reduce reaction time},
	isbn = {978-1-4503-2473-1},
	shorttitle = {In-your-face, yet unseen?},
	url = {https://doi.org/10.1145/2556288.2557063},
	doi = {10.1145/2556288.2557063},
	abstract = {One unique property of head-mounted displays (HMDs) is that content can easily be displayed at a fixed position within the user’s field of view (head-stabilized). This ensures that critical information (e.g. warnings) is continuously visible and can, in principle, be perceived as quickly as possible. We examined this strategy with a physically and visually distracted driver. We ran two consecutive studies in a driving simulator, comparing different warning visualizations in a head-up display (HUD) and a HMD. In an initial study, we found no significant effects of warning type or display technology on the reaction times. In a second study, after modifying our visualization to include a visual reference marker, we found that with only this minor change, reaction times were significantly lower in the HMD when compared to the HUD. Our insights can help others design better headstabilized notifications.},
	language = {en},
	booktitle = {Proceedings of the 32nd annual {ACM} conference on {Human} factors in computing systems - {CHI} '14},
	publisher = {ACM Press},
	author = {Lauber, Felix and Butz, Andreas},
	year = {2014},
	pages = {3201--3204},
}

@inproceedings{ofek_reducing_2013,
	address = {New York, NY, USA},
	series = {{CHI} '13},
	title = {Reducing disruption from subtle information delivery during a conversation: mode and bandwidth investigation},
	isbn = {978-1-4503-1899-0},
	shorttitle = {Reducing disruption from subtle information delivery during a conversation},
	url = {https://doi.org/10.1145/2470654.2466425},
	doi = {10.1145/2470654.2466425},
	abstract = {With proliferation of mobile devices that provide ubiquitous access to information, the question arises of how distracting processing information in social settings can be, especially during face-to-face conversations. However, relevant information presented at opportune moments may help enhance conversation quality. In this paper, we study how much information users can consume during a conversation and what information delivery mode, via audio or visual aids, helps them effectively conceal the fact that they are receiving information. We observe that users can internalize more information while still disguising this fact the best when information is delivered visually in batches (multiple pieces of information at a time) and perform better on both dimensions if information is delivered while they are not speaking. Interestingly, participants qualitatively did not prefer this mode as being the easiest to use, preferring modes that displayed one piece of information at a time.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Ofek, Eyal and Iqbal, Shamsi T. and Strauss, Karin},
	month = apr,
	year = {2013},
	keywords = {augmented reality, attention, design, human factors},
	pages = {3111--3120},
}

@inproceedings{mcatamney_examination_2006,
	address = {New York, NY, USA},
	series = {{CHI} '06},
	title = {An examination of the effects of a wearable display on informal face-to-face communication},
	isbn = {978-1-59593-372-0},
	url = {https://doi.org/10.1145/1124772.1124780},
	doi = {10.1145/1124772.1124780},
	abstract = {Wearable computers have the potential to support our memory, facilitate our creativity, our communication and augment our physical senses [15] but, like email and cell-phones, they also have the potential to interrupt, displace or downgrade our social interactions. This paper presents the results of a simple laboratory-based study which examines the impact of a xybernaut head-mounted Shimadzu display on conversation between two people. We hypothesized that the wearable, by reducing eye-contact and attention in the wearer would have a detrimental effect. Pairs of friends discussed pre-defined topics under three conditions, no wearable, wearable present but inactive, wearable present and active. Likert scale statements were used to record the wearer's level of attention, concentration, listening, eye contact, naturalness and relaxation, and the impact of the wearable. The presence of the wearable without an active display did not have an effect on the conversation. The quality of the interaction was however impaired in the active wearable condition and eye-contact was effected. This effect may be the result of the nature of the information type, the interface used, the characteristics of its presentation or the novelty of the display to the user. Additional research to identify design implications is discussed.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {McAtamney, Gerard and Parker, Caroline},
	month = apr,
	year = {2006},
	keywords = {attention, conversation, displays, eye-contact, information, social computing, wearables, wearer vs non-wearer},
	pages = {45--54},
}


@inproceedings{lucero_notifeye_2014,
	address = {Funchal, Portugal},
	title = {{NotifEye}: using interactive glasses to deal with notifications while walking in public},
	isbn = {978-1-4503-2945-3},
	shorttitle = {{NotifEye}},
	url = {https://doi.org/10.1145/2663806.2663824},
	doi = {10.1145/2663806.2663824},
	abstract = {In this paper we explore the use of interactive eyewear in public. We introduce NotifEye, an application that allows a person to receive social network notifications on interactive glasses while walking on a busy street. The prototype uses a minimalistic user interface (UI) for interactive glasses to help people focus their attention on their surroundings and supports discreet interaction by using a finger rub pad to take action on incoming notifications. We studied pragmatic and hedonic aspects of the prototype during a pedestrian navigation task in a city center. We found that, despite the potential risk of overwhelming people with information, participants were able to keep track of their surroundings as they dealt with incoming notifications. Participants also positively valued the use of a discreet device to provide input for interactive glasses. Finally, participants reflected on their (evolving) perception of interactive glasses, indicating that glasses should become smaller, more comfortable to wear, and somewhat of a fashion accessory.},
	language = {en},
	booktitle = {Proceedings of the 11th {Conference} on {Advances} in {Computer} {Entertainment} {Technology} - {ACE} '14},
	publisher = {ACM Press},
	author = {Lucero, Andr{\textbackslash}'\{e\}s and Vetek, Akos},
	year = {2014},
	pages = {1--10},
}


@article{orlosky_managing_2014,
	title = {Managing mobile text in head mounted displays: studies on visual preference and text placement},
	volume = {18},
	issn = {1559-1662},
	shorttitle = {Managing mobile text in head mounted displays},
	url = {https://doi.org/10.1145/2636242.2636246},
	doi = {10.1145/2636242.2636246},
	abstract = {In recent years, the development of wearable displays has seen a drastic increase. However, there is still a strong resistance to using wearable technology for fear of decreased visibility and attention to one's surroundings. To address this concern, this paper describes a series of experiments that study user tendencies related to viewing and placing text in head mounted displays (HMDs). From the results of two pilot experiments, we show that awareness is to some extent better for HMDs compared to smartphones, and find that users would prefer to place text in the background rather than the HMD screen. We then consequently build an intelligent system to manage placement of text such as e-mail and messaging using computer vision algorithms.?? Finally, through two experiments comparing automatic and manual text placement, we show that our system can mimic human tendencies with approximately 70\% accuracy.},
	number = {2},
	journal = {ACM SIGMOBILE Mobile Computing and Communications Review},
	author = {Orlosky, Jason and Kiyokawa, Kiyoshi and Takemura, Haruo},
	month = jun,
	year = {2014},
	pages = {20--31},
}


@article{wu_which_2016,
	title = {Which is a {Better} {In}-{Vehicle} {Information} {Display}? {A} {Comparison} of {Google} {Glass} and {Smartphones}},
	issn = {1551-319X, 1558-9323},
	shorttitle = {Which is a {Better} {In}-{Vehicle} {Information} {Display}?},
	url = {https://doi.org/10.1109/JDT.2016.2594263},
	doi = {10.1109/JDT.2016.2594263},
	abstract = {In-vehicle information display is critical for driving safety and has been the focus of transportation and display technology research. Cellphone use, while driving is popular, leads to distraction and impairs driving performance. A new head-mounted display (HMD), Google Glass, has been developed in hope of reducing the visual distractions caused by a head-down display (HDD), such as a smartphone. Alternatively, HMD could induce greater distraction by giving drivers the false impression that they are simultaneously paying attention to both the HMD and the road. We compared driving performance in a simulated tactical lanechanging task while drivers read from either an HMD (e.g., Google Glass) or an HDD (e.g., smartphone). Although both HMD and HDD use impaired driving performance, drivers produced smaller lane variation, had fewer lane excursions, and lower subjective workload when using an HMD than when using an HDD. Wearable display technologies like Google Glass might reduce the impairment caused by looking down at a smartphone.},
	language = {en},
	journal = {Journal of Display Technology},
	author = {Wu, Xiaohui and Ellis, Jake and Choi, William and Wang, Pingfeng and Peng, Kaiping and He, Jibo},
	year = {2016},
}


@inproceedings{chaturvedi_peripheral_2019,
	address = {Marina del Ray, California},
	title = {Peripheral vision: a new killer app for smart glasses},
	isbn = {978-1-4503-6272-6},
	shorttitle = {Peripheral vision},
	url = {https://doi.org/10.1145/3301275.3302263},
	doi = {10.1145/3301275.3302263},
	abstract = {Most smart glasses have a small and limited field of view. The head-mounted display often spreads between the human central and peripheral vision. In this paper, we exploit this characteristic to display information in the peripheral vision of the user. We introduce a mobile peripheral vision model, which can be used on any smart glasses with a head-mounted display without any additional hardware requirement. This model taps into the blocked peripheral vision of a user and simplifies multi-tasking when using smart glasses. To display the potential applications of this model, we implement an application for indoor and outdoor navigation. We conduct an experiment on 20 people on both smartphone and smart glass to evaluate our model on indoor and outdoor conditions. Users report to have spent at least 50\% less time looking at the screen by exploiting their peripheral vision with smart glass. 90\% of the users Agree that using the model for navigation is more practical than standard navigation applications.},
	language = {en},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Intelligent} {User} {Interfaces}  - {IUI} '19},
	publisher = {ACM Press},
	author = {Chaturvedi, Isha and Bijarbooneh, Farshid Hassani and Braud, Tristan and Hui, Pan},
	year = {2019},
	pages = {625--636},
}


@article{tijus_design_2007,
	title = {The {Design}, {Understanding} and {Usage} of {Pictograms}},
	shorttitle = {Chapter 2},
	url = {https://doi.org/10.1163/9789004253254_003},
	doi = {10.1163/9789004253254_003},
	abstract = {Pictograms form part of our daily lives through their use in medication, transport, computers, etc., because they indicate - in iconic form - places, directions, actions or constraints on actions in either the real world (a town, a road, etc.) or virtual space (computer desktop, Internet, etc.). This chapter is essentially a review of research on the pictogram effect, which can be summed up as follows: a pictogram is better than a label, and recognizing an image is easier than reading text (Norman, 1990). This review covers theoretical and experimental studies from linguistics, psychology and cognitive ergonomics on the design and validation, comprehension and usage of pictograms. Among the various methods, an emphasis is placed on classification and the creation of pictogram taxonomies as tools for homogenization and design.},
	language = {en},
	journal = {Written Documents in the Workplace},
	author = {Tijus, Charles and Barcenilla, Javier and Lavalette, Brigitte Cambon de and Meunier, Jean-Guy},
	month = jan,
	year = {2007},
	pages = {17--31},
}


@article{mcdougall_measuring_1999,
	title = {Measuring symbol and icon characteristics: {Norms} for concreteness, complexity, meaningfulness, familiarity, and semantic distance for 239 symbols},
	volume = {31},
	issn = {0743-3808, 1532-5970},
	shorttitle = {Measuring symbol and icon characteristics},
	url = {https://doi.org/10.3758/BF03200730},
	doi = {10.3758/BF03200730},
	language = {en},
	number = {3},
	journal = {Behavior Research Methods, Instruments, \& Computers},
	author = {Mcdougall, Siné J. P. and Curry, Martin B. and de Bruijn, Oscar},
	month = sep,
	year = {1999},
	pages = {487--519},
}


@article{ells_rapid_1979,
	title = {Rapid {Comprehension} of {Verbal} and {Symbolic} {Traffic} {Sign} {Messages}},
	volume = {21},
	issn = {0018-7208},
	url = {https://doi.org/10.1177/001872087902100203},
	doi = {10.1177/001872087902100203},
	abstract = {A “same”-“different” reaction time procedure was used in two experiments to measure the times required to comprehend the meanings of projected slides of traffic signs. The results indicated that signs with symbolic messages could be understood more quickly than those with verbal messages. Visually degrading the signs resulted in a greater decrement in performance for verbal than for symbolic signs. Correlational analyses demonstrated reaction time to correlate significantly with a previously obtained measure of sign legibility taken from a moving motor vehicle on a roadway. The utility of reaction time as an index of traffic sign adequacy is discussed along with some possible practical implications of the research.},
	language = {en},
	number = {2},
	journal = {Human Factors},
	author = {Ells, Jerry G. and Dewar, Robert E.},
	month = apr,
	year = {1979},
	pages = {161--168},
}


@book{paivio_mental_1990,
	title = {Mental Representations: A dual coding approach},
	isbn = {978-0-19-989408-6},
	shorttitle = {Mental Representations},
	url = {https://doi.org/10.1093/acprof:oso/9780195066661.001.0001},
	abstract = {This work presents a systematic analysis of the psychological phenomena associated with the concept of mental representations — also referred to as cognitive or internal representations. A major restatement of a theory the author of this book first developed in his 1971 book (Imagery and Verbal Processes), this book covers phenomena from the earlier period that remain relevant today but emphasizes cognitive problems and paradigms that have since emerged more fully. It proposes that performance in memory and other cognitive tasks is mediated not only by linguistic processes but also by a distinct nonverbal imagery model of thought as well. It discusses the philosophy of science associated with the dual coding approach, emphasizing the advantages of empiricism in the study of cognitive phenomena and shows that the fundamentals of the theory have stood up well to empirical challenges over the years.},
	language = {en},
	publisher = {Oxford University Press},
	author = {Paivio, Allan},
	year = {1990},
}



@inproceedings{warnock_multiple_2013,
	address = {New York, NY, USA},
	series = {{CHI} '13},
	title = {Multiple notification modalities and older users},
	isbn = {978-1-4503-1899-0},
	url = {https://doi.org/10.1145/2470654.2466139},
	doi = {10.1145/2470654.2466139},
	abstract = {Multimodal interaction can make home care reminder systems more accessible to their users, most of whom are older and/or have sensory impairments. Existing research into the properties of different notification modalities have used younger participants rather than members of the older population at which they are aimed. This paper presents the results of a user study with older adults that examined how different notification modalities affected (a) performance in a card matching game and (b) how effective the different modalities were at delivering information. Participants were all aged over 50 and notifications were delivered using textual, pictographic, abstract visual, speech, Earcon, Auditory Icon, tactile and olfactory modalities while playing the game. The results showed that older users were influenced by the same factors as younger users, yet there were subjective differences. The implications for the design of multimodal reminder systems for home care are discussed.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Warnock, David and McGee-Lennon, Marilyn and Brewster, Stephen},
	month = apr,
	year = {2013},
	keywords = {multimodal, notifications, older users, reminders},
	pages = {1091--1094},
}


@incollection{hutchison_role_2011,
	address = {Berlin, Heidelberg},
	title = {The {Role} of {Modality} in {Notification} {Performance}},
	volume = {6947},
	isbn = {978-3-642-23770-6 978-3-642-23771-3},
	url = {https://doi.org/10.1007/978-3-642-23771-3_43},
	abstract = {The primary users of home care technology often have signiﬁcant sensory impairments. Multimodal interaction can make home care technology more accessible and appropriate, yet most research in the ﬁeld of multimodal notiﬁcations is not aimed at the home but at oﬃce or high-pressure environments. This paper presents an experiment that compared the disruptiveness and eﬀectiveness of visual, auditory, tactile and olfactory notiﬁcations. The results showed that disruption in the primary task was the same regardless of the notiﬁcation modality. It was also found that diﬀerences in notiﬁcation eﬀectiveness were due to the inherent traits of a modality, e.g.olfactory notiﬁcations were slowest to deliver. The results of this experiment allow researchers and developers to capitalize on the diﬀerent properties of multimodal techniques, with signiﬁcant implications for home care technology and technology targeted at users with sensory impairments.},
	language = {en},
	booktitle = {Human-{Computer} {Interaction} – {INTERACT} 2011},
	publisher = {Springer Berlin Heidelberg},
	author = {Warnock, David and McGee-Lennon, Marilyn and Brewster, Stephen},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Campos, Pedro and Graham, Nicholas and Jorge, Joaquim and Nunes, Nuno and Palanque, Philippe and Winckler, Marco},
	year = {2011},
	doi = {10.1007/978-3-642-23771-3_43},
	pages = {572--588},
}

@article{somervell_evaluating_2002,
	title = {Evaluating graphical vs. textual secondary displays for information notification},
	abstract = {This paper reports the findings of a humancomputer interaction (HCI) experiment, conducted to determine whether graphical or textual representations of a simulated load monitor are more effective at communicating notification information in a secondary display. We establish guidelines for design tradeoffs based on significant differences in display facilitation of information monitoring, awareness, and introduction of distraction. These findings result from an experiment in which subjects browsed through information pages searching for answers to questions while simultaneously monitoring information in the load monitor. This research is critical in developing a framework for secondary display evaluation that should guide the design and use of visual notification systems requiring a division of user attention.},
	language = {en},
	journal = {Proceedings of the ACM Southeast Conference, Raleigh NC},
	author = {Somervell, Jacob and Chewar, C M and McCrickard, D Scott},
	year = {2002},
	pages = {153--160},
}


@inproceedings{warnock_subjective_2011,
	title = {A subjective evaluation of multimodal notifications},
        url = {https://doi.org/10.4108/icst.pervasivehealth.2011.246001},
	doi = {10.4108/icst.pervasivehealth.2011.246001},
	abstract = {The primary users of home care technology often have significant sensory impairments. Multimodal interaction can make home care technology more accessible and appropriate, but most research in the field of multimodal notifications is aimed at office or high-pressure environments instead of the home. Two experiments were carried out that evaluated the subjective workload of responding to visual, auditory, tactile and olfactory notifications (simulating home care reminders) while carrying out a primary task (a card matching memory game). The subjective measurements and observations revealed that participants were open-minded about the possibilities and applications of these modalities, suggesting that home care technology should embrace a much wider range of interaction methods than are currently used.},
	booktitle = {2011 5th {International} {Conference} on {Pervasive} {Computing} {Technologies} for {Healthcare} ({PervasiveHealth}) and {Workshops}},
	author = {Warnock, David},
	month = may,
	year = {2011},
	keywords = {accessibility and usability, Context, Games, Hardware, Heating, Multimodal interfaces, Olfactory, Speech, technology in healthcare, Visualization},
	pages = {461--468},
}


@inproceedings{lee_hooked_2014,
	address = {New York, NY, USA},
	series = {{CHI} '14},
	title = {Hooked on smartphones: an exploratory study on smartphone overuse among college students},
	isbn = {978-1-4503-2473-1},
	shorttitle = {Hooked on smartphones},
	url = {https://doi.org/10.1145/2556288.2557366},
	doi = {10.1145/2556288.2557366},
	abstract = {The negative aspects of smartphone overuse on young adults, such as sleep deprivation and attention deficits, are being increasingly recognized recently. This emerging issue motivated us to analyze the usage patterns related to smartphone overuse. We investigate smartphone usage for 95 college students using surveys, logged data, and interviews. We first divide the participants into risk and non-risk groups based on self-reported rating scale for smartphone overuse. We then analyze the usage data to identify between-group usage differences, which ranged from the overall usage patterns to app-specific usage patterns. Compared with the non-risk group, our results show that the risk group has longer usage time per day and different diurnal usage patterns. Also, the risk group users are more susceptible to push notifications, and tend to consume more online content. We characterize the overall relationship between usage features and smartphone overuse using analytic modeling and provide detailed illustrations of problematic usage behaviors based on interview data.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Lee, Uichin and Lee, Joonwon and Ko, Minsam and Lee, Changhun and Kim, Yuhwan and Yang, Subin and Yatani, Koji and Gweon, Gahgene and Chung, Kyong-Mee and Song, Junehwa},
	month = apr,
	year = {2014},
	keywords = {measurement, smartphone overuse},
	pages = {2327--2336},
}


@inproceedings{adamczyk_if_2004,
	address = {Vienna, Austria},
	title = {If not now, when?: the effects of interruption at different moments within task execution},
	isbn = {978-1-58113-702-6},
	shorttitle = {If not now, when?},
	url = {https://doi.org/10.1145/985692.985727},
	doi = {10.1145/985692.985727},
	abstract = {User attention is a scarce resource and users are susceptible to interruption overload. Systems do not reason about the costs of interrupting a user during a task sequence. In this study, we measure effects of interrupting a user at different moments within task execution in terms of task performance, emotional state, and social attribution. Task models were developed using event perception techniques, and the resulting models were used to identify interruption timings based on a user’s predicted cognitive load. Our results show that different interruption moments have different impacts on user emotional state and positive social attribution, and suggest that a system could enable a user to maintain a high level of awareness while mitigating the disruptive effects of interruption. We discuss implications of these results for the design of an attention manager.},
	language = {en},
	booktitle = {Proceedings of the 2004 conference on {Human} factors in computing systems  - {CHI} '04},
	publisher = {ACM Press},
	author = {Adamczyk, Piotr D. and Bailey, Brian P.},
	year = {2004},
	keywords = {interruption, attention, affective state, task models},
	pages = {271--278},
}


@inproceedings{chang_investigating_2015,
	address = {Copenhagen, Denmark},
	title = {Investigating {Mobile} {Users}' {Ringer} {Mode} {Usage} and {Attentiveness} and {Responsiveness} to {Communication}},
	isbn = {978-1-4503-3652-9},
	url = {https://doi.org/10.1145/2785830.2785852},
	doi = {10.1145/2785830.2785852},
	abstract = {Smartphones are considered to be “always on, always connected” but mobile users are not always attentive and responsive to incoming communication. We present a mixed methods study investigating how mobile users use ringer modes for managing interruption by and awareness of incoming communication, and how these practices and locales affect their attentiveness and responsiveness. We show that mobile users have diverse ringer mode usage, but they switch ringer modes mainly for three purposes: avoiding interruption, preventing the phone from disrupting the environment, and noticing important notifications. In addition, without signals of notifications, users are less likely to immediately attend to notifications, but they are not less responsive to those they have attended. Finally, ringer mode switches, attentiveness, and responsiveness are all correlated with certain locales. We discuss implications from these findings, and suggest how future CMC tools and notification services take different purposes for using ringer modes and locales into consideration.},
	language = {en},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services} - {MobileHCI} '15},
	publisher = {ACM Press},
	author = {Chang, Yung-Ju and Tang, John C.},
	year = {2015},
	pages = {6--15},
}

@inproceedings{beauvisage_computer_2009,
    author = {Beauvisage, Thomas},
    title = {Computer Usage in Daily Life},
    year = {2009},
    isbn = {9781605582467},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1518701.1518791},
    doi = {10.1145/1518701.1518791},
    abstract = {In this paper we explore the use of computer at home. This work is based on the automatic recording of application focus data in natural situation from a wide representative panel of 661 households with 1,434 users at home over 19 months. To process these large-scale data, we build a two-level classification of PC applications describing the whole PC use. At the household level, we worked on computer usage temporality: we observed two strategies of PC usage reflecting a tension between synchronous and asynchronous usage profiles. At the individual level, we found out that software preferences and usage intensity are rather independent; therefore, we distinguished five specific profiles of users reflecting strong routine behaviors of computer usage at home. These observations tend to show the strength of routine behaviors in computer usage.},
    booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
    pages = {575–584},
    numpages = {10},
    keywords = {representative panel, computer usage, user generated events, user profiles},
    location = {Boston, MA, USA},
    series = {CHI '09}
}


@article{wang_comprehensive_2016,
	title = {A comprehensive survey of augmented reality assembly research},
	volume = {4},
	issn = {2195-3597},
	url = {https://doi.org/10.1007/s40436-015-0131-4},
	doi = {10.1007/s40436-015-0131-4},
	abstract = {In the past two decades, augmented reality (AR) has received a growing amount of attention by researchers in the manufacturing technology community, because AR can be applied to address a wide range of problems throughout the assembly phase in the lifecycle of a product, e.g., planning, design, ergonomics assessment, operation guidance and training. However, to the best of authors’ knowledge, there has not been any comprehensive review of AR-based assembly systems. This paper aims to provide a concise overview of the technical features, characteristics and broad range of applications of AR-based assembly systems published between 1990 and 2015. Among these selected articles, two thirds of them were published between 2005 and 2015, and they are considered as recent pertinent works which will be discussed in detail. In addition, the current limitation factors and future trends in the development will also be discussed.},
	language = {en},
	number = {1},
	journal = {Advances in Manufacturing},
	author = {Wang, X. and Ong, S. K. and Nee, A. Y. C.},
	month = mar,
	year = {2016},
	pages = {1--22},
}


@article{mitrasinovic_clinical_2015,
	title = {Clinical and surgical applications of smart glasses},
	volume = {23},
	issn = {0928-7329},
	url = {https://doi.org/10.3233/THC-150910},
	doi = {10.3233/THC-150910},
	abstract = {BACKGROUND: With the increased efforts to adopt health information technology in the healthcare field, many innovative devices have emerged to improve patient care, increase efficiency, and decrease healthcare costs. A recent addition is smart glass},
	language = {en},
	number = {4},
	journal = {Technology and Health Care},
	author = {Mitrasinovic, Stefan and Camacho, Elvis and Trivedi, Nirali and Logan, Julia and Campbell, Colson and Zilinyi, Robert and Lieber, Bryan and Bruce, Eliza and Taylor, Blake and Martineau, David and Dumont, Emmanuel L. P. and Appelboom, Geoff and Connolly Jr., E. Sander},
	month = jan,
	year = {2015},
	keywords = {augmented reality, Confidentiality, Documentation, Electronic Health Records, epson moverio, Eyeglasses, google glass, heads-up-display, Humans, Internet, Meta-Pro spaceglasses, Point-of-Care Systems, Smart glasses, telemedicine, Telemedicine, User-Computer Interface},
	pages = {381--401},
}


@article{braun_using_2006,
	title = {Using thematic analysis in psychology},
	volume = {3},
	issn = {1478-0887},
	url = {https://doi.org/10.1191/1478088706qp063oa},
	doi = {10.1191/1478088706qp063oa},
	abstract = {Thematic analysis is a poorly demarcated, rarely acknowledged, yet widely used qualitative analytic method within psychology. In this paper, we argue that it offers an accessible and theoretically flexible approach to analysing qualitative data. We outline what thematic analysis is, locating it in relation to other qualitative analytic methods that search for themes or patterns, and in relation to different epistemological and ontological positions. We then provide clear guidelines to those wanting to start thematic analysis, or conduct it in a more deliberate and rigorous way, and consider potential pitfalls in conducting thematic analysis. Finally, we outline the disadvantages and advantages of thematic analysis. We conclude by advocating thematic analysis as a useful and flexible method for qualitative research in and beyond psychology.},
	number = {2},
	journal = {Qualitative Research in Psychology},
	author = {Braun, Virginia and Clarke, Victoria},
	month = jan,
	year = {2006},
	keywords = {epistemology, flexibility, patterns, qualitative psychology, thematic analysis},
	pages = {77--101},
}


@article{yeh_target_1999,
	title = {Target {Cuing} in {Visual} {Search}: {The} {Effects} of {Conformality} and {Display} {Location} on the {Allocation} of {Visual} {Attention}},
	volume = {41},
	issn = {0018-7208},
	shorttitle = {Target {Cuing} in {Visual} {Search}},
	url = {https://doi.org/10.1518/001872099779656752},
	doi = {10.1518/001872099779656752},
	abstract = {Two experiments were performed to examine how frame of reference (world referenced vs. screen-referenced) and target expectancy can modulate the effects of target cuing in directing attention for see-through helmet-mounted displays (HMDs). In the first experiment, the degree of world referencing was varied by the spatial accuracy of the cue; in the second, the degree of world referencing was varied more radically between a world-referenced HMD and a hand-held display. Participants were asked to detect, identify, and give azimuth information for targets hidden in terrain presented in the far domain (i.e., the world) while performing a monitoring task in the near domain (i.e., the display). The results of both experiments revealed a cost-benefit trade-off for cuing such that the presence of cuing aided the target detection task for expected targets but drew attention away from the presence of unexpected targets in the environment. Analyses support the observation that this effect can be mediated by the display: The world-referenced display reduced the cost of cognitive tunneling relative to the screen-referenced display in Experiment 1; this cost was further reduced in Experiment 2 when participants were using a hand-held display. Potential applications of this research include important design guidelines and specifications for automated target recognition systems as well as any terrain-and-targeting display system in which superimposed symbology is included, specifically in assessing the costs and benefits of attentional cuing and the means by which this information is displayed.},
	language = {en},
	number = {4},
	journal = {Human Factors},
	author = {Yeh, Michelle and Wickens, Christopher D. and Seagull, F. Jacob},
	month = dec,
	year = {1999},
	keywords = {Attention, Cognition, Female, Humans, Male, Reaction Time, User-Computer Interface, Aerospace Medicine, Analysis of Variance, Aviation, Clothing, Computer Graphics, Cues, Data Display, Head Movements, Military Medicine, Reference Values, Task Performance and Analysis, United States, Visual Fields},
	pages = {524--542},
}


@inproceedings{salvucci_toward_2009,
	address = {New York, NY, USA},
	series = {{CHI} '09},
	title = {Toward a unified theory of the multitasking continuum: from concurrent performance to task switching, interruption, and resumption},
	isbn = {978-1-60558-246-7},
	shorttitle = {Toward a unified theory of the multitasking continuum},
	url = {https://doi.org/10.1145/1518701.1518981},
	doi = {10.1145/1518701.1518981},
	abstract = {Multitasking in user behavior can be represented along a continuum in terms of the time spent on one task before switching to another. In this paper, we present a theory of behavior along the multitasking continuum, from concurrent tasks with rapid switching to sequential tasks with longer time between switching. Our theory unifies several theoretical effects - the ACT-R cognitive architecture, the threaded cognition theory of concurrent multitasking, and the memory-for-goals theory of interruption and resumption - to better understand and predict multitasking behavior. We outline the theory and discuss how it accounts for numerous phenomena in the recent empirical literature.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Salvucci, Dario D. and Taatgen, Niels A. and Borst, Jelmer P.},
	month = apr,
	year = {2009},
	keywords = {interruption, attention, cognitive architecture, multitasking},
	pages = {1819--1828},
}



@article{salvucci_threaded_2008,
	title = {Threaded cognition: an integrated theory of concurrent multitasking},
	volume = {115},
	issn = {0033-295X},
	shorttitle = {Threaded cognition},
        url = {https://doi.org/10.1037/0033-295X.115.1.101},
	doi = {10.1037/0033-295X.115.1.101},
	abstract = {The authors propose the idea of threaded cognition, an integrated theory of concurrent multitasking--that is, performing 2 or more tasks at once. Threaded cognition posits that streams of thought can be represented as threads of processing coordinated by a serial procedural resource and executed across other available resources (e.g., perceptual and motor resources). The theory specifies a parsimonious mechanism that allows for concurrent execution, resource acquisition, and resolution of resource conflicts, without the need for specialized executive processes. By instantiating this mechanism as a computational model, threaded cognition provides explicit predictions of how multitasking behavior can result in interference, or lack thereof, for a given set of tasks. The authors illustrate the theory in model simulations of several representative domains ranging from simple laboratory tasks such as dual-choice tasks to complex real-world domains such as driving and driver distraction.},
	language = {eng},
	number = {1},
	journal = {Psychological Review},
	author = {Salvucci, Dario D. and Taatgen, Niels A.},
	month = jan,
	year = {2008},
	pmid = {18211187},
	keywords = {Automobile Driving, Cognition, Humans, Psychological Theory, Psychomotor Performance},
	pages = {101--130},
}


@inproceedings{kushlev_silence_2016,
	address = {San Jose California USA},
	title = {"{Silence} {Your} {Phones}": {Smartphone} {Notifications} {Increase} {Inattention} and {Hyperactivity} {Symptoms}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {"{Silence} {Your} {Phones}"},
	url = {https://doi.org/10.1145/2858036.2858359},
	doi = {10.1145/2858036.2858359},
	abstract = {As smartphones increasingly pervade our daily lives, people are ever more interrupted by alerts and notifications. Using both correlational and experimental methods, we explored whether such interruptions might be causing inattention and hyperactivity—symptoms associated with Attention Deficit Hyperactivity Disorder (ADHD)—even in people not clinically diagnosed with ADHD. We recruited a sample of 221 participants from the general population. For one week, participants were assigned to maximize phone interruptions by keeping notification alerts on and their phones within their reach/sight. During another week, participants were assigned to minimize phone interruptions by keeping alerts off and their phones away. Participants reported higher levels of inattention and hyperactivity when alerts were on than when alerts were off. Higher levels of inattention in turn predicted lower productivity and psychological wellbeing. These findings highlight some of the costs of ubiquitous connectivity and suggest how people can reduce these costs simply by adjusting existing phone settings.},
	language = {en},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Kushlev, Kostadin and Proulx, Jason and Dunn, Elizabeth W.},
	month = may,
	year = {2016},
	pages = {1011--1020},
}


@article{streefkerk_designing_2006,
    title = {Designing personal attentive user interfaces in the mobile public safety domain},
    journal = {Computers in Human Behavior},
    volume = {22},
    number = {4},
    pages = {749-770},
    year = {2006},
    issn = {0747-5632},
    doi = {https://doi.org/10.1016/j.chb.2005.12.006},
    url = {https://www.sciencedirect.com/science/article/pii/S0747563205001147},
    author = {Jan Willem Streefkerk and Myra P. {van Esch-Bussemakers} and Mark A. Neerincx},
    keywords = {Mobile computing, Attention, Context-aware computing, Personalization, User-centered design, Police},
    abstract = {In the mobile computing environment, there is a need to adapt the information and service provision to the momentary attentive state of the user, operational requirements and usage context. This paper proposes to design personal attentive user interfaces (PAUI) for which the content and style of information presentation is based on models of relevant cognitive, task, context and user aspects. Using the police work environment as the application domain, relevant attributes of these aspects are identified based on literature and domain analyses. We present a user-centered design (UCD) method for the iterative development and validation of the proposed PAUI. Application of this approach provided requirements for (1) adaptation to users’ attentive state, (2) notification, (3) information processing and task switching support and (4) user modeling. We aim at refining and validating the models and requirements through continuing empirical evaluation.}
}


@inproceedings{klose_text_2019,
	address = {Osaka, Japan},
	title = {Text {Presentation} for {Augmented} {Reality} {Applications} in {Dual}-{Task} {Situations}},
	isbn = {978-1-72811-377-7},
	url = {https://doi.org/10.1109/VR.2019.8797992},
	doi = {10.1109/VR.2019.8797992},
	abstract = {We investigate how reading text in augmented reality (AR) glasses and the simultaneous execution of three real-world tasks interfere with each other. The three tasks are a visual stimulusresponse task (VSRT), a simple walking task and a walking obstacle course. Also, we investigate the effects of different AR text positions on primary task and reading performance as well as subjective preference. We propose a novel out of sight bodylocked text placement for AR text presentation to be used in dualtask situations and compare it to head-locked text placement, each in two heights. AR reading affected performance in all tasks and reading speed was affected in all dual-task conditions. Participants subjectively preferred the body-locked text presentation, while objective measures do not reflect that preference. Differences between the tasks and several interaction effects between task and AR text placement demonstrate the necessity to carefully consider the context of use when designing AR reading UIs. The presented study with 12 participants provides insights into the effects of AR glasses usage in dual-task situations and several design recommendations are derived from the results.},
	language = {en},
	booktitle = {2019 {IEEE} {Conference} on {Virtual} {Reality} and {3D} {User} {Interfaces} ({VR})},
	publisher = {IEEE},
	author = {Klose, Elisa Maria and Mack, Nils Adrian and Hegenberg, Jens and Schmidt, Ludger},
	month = mar,
	year = {2019},
	pages = {636--644},
}


@article{stothart_attentional_2015,
	title = {The attentional cost of receiving a cell phone notification.},
	volume = {41},
	issn = {1939-1277, 0096-1523},
	url = {https://doi.org/10.1037/xhp0000100},
	doi = {10.1037/xhp0000100},
	abstract = {It is well documented that interacting with a mobile phone is associated with poorer performance on concurrently performed tasks because limited attentional resources must be shared between tasks. However, mobile phones generate auditory or tactile notifications to alert users of incoming calls and messages. Although these notifications are generally short in duration, they can prompt task-irrelevant thoughts, or mind wandering, which has been shown to damage task performance. We found that cellular phone notifications alone significantly disrupted performance on an attention-demanding task, even when participants did not directly interact with a mobile device during the task. The magnitude of observed distraction effects was comparable in magnitude to those seen when users actively used a mobile phone, either for voice calls or text messaging.},
	language = {en},
	number = {4},
	journal = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Stothart, Cary and Mitchum, Ainsley and Yehnert, Courtney},
	month = aug,
	year = {2015},
	pages = {893--897},
}


@misc{broni_emoji_2020,
	title = {Emoji {Trends} {That} {Defined} 2020},
	url = {https://blog.emojipedia.org/emoji-trends-that-defined-2020/},
	abstract = {Emoji use continues to rise with over one in five tweets now containing at least one emoji. While more emojis are being used now than ever, the rate of growth has slowed in 2020.  In the middle of a year where the �� Microbe emoji saw a giant increase, a certain},
	language = {en},
	urldate = {2021-05-08},
	journal = {Emojipedia},
	author = {Broni, Keith},
	month = dec,
	year = {2020},
}


@inproceedings{norrie_impact_2015,
	address = {Copenhagen, Denmark},
	title = {Impact of {Smartphone} {Notification} {Display} {Choice} in a {Typing} {Task}},
	isbn = {978-1-4503-3653-6},
	url = {https://doi.org/10.1145/2786567.2794335},
	doi = {10.1145/2786567.2794335},
	abstract = {External displays have the potential to make smartphone notiﬁcations less obtrusive when a user has committed their attention to a primary task. We compare six notiﬁcation displays, and evaluate the impact that negotiating smartphone interruptions has on a typing task when the number of notiﬁcations to ignore and act on are equal. A lab experiment with 30 participants is conducted, and initial results show that desktop pop-ups are preferred signiﬁcantly more, where they require the fewest actions to read. Managing notiﬁcations via the notiﬁcation bar is least preferred, despite requiring fewer actions to respond. This work is a well-controlled pre-cursor to the application of notiﬁcation displays in social scenarios. The results motivate the use of external displays to manage attention around smartphone interruptions.},
	language = {en},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services} {Adjunct} - {MobileHCI} '15},
	publisher = {ACM Press},
	author = {Norrie, Lauren and Murray-Smith, Roderick},
	year = {2015},
	pages = {1094--1099},
}

@InProceedings{patel_farther_2006,
    author="Patel, Shwetak N.
    and Kientz, Julie A.
    and Hayes, Gillian R.
    and Bhat, Sooraj
    and Abowd, Gregory D.",
    editor="Dourish, Paul
    and Friday, Adrian",
    title="Farther Than You May Think: An Empirical Investigation of the Proximity of Users to Their Mobile Phones",
    booktitle="UbiComp 2006: Ubiquitous Computing",
    year="2006",
    publisher="Springer Berlin Heidelberg",
    address="Berlin, Heidelberg",
    pages="123--140",
    abstract="Implicit in much research and application development for mobile phones is the assumption that the mobile phone is a suitable proxy for its owner's location. We report an in-depth empirical investigation of this assumption in which we measured proximity of the phone to its owner over several weeks of continual observation. Our findings, summarizing results over 16 different subjects of a variety of ages and occupations, establish baseline statistics for the proximity relationship in a typical US metropolitan market. Supplemental interviews help us to establish reasons why the phone and owner are separated, leading to guidelines for developing mobile phone applications that can be smart with respect to the proximity assumption. We show it is possible to predict the proximity relationship with 86{\%} confidence using simple parameters of the phone, such as current cell ID, current date and time, signal status, charger status and ring/vibrate mode.",
    isbn="978-3-540-39635-2",
    url = {https://doi.org/10.1007/11853565_8},
}


@book{proctor_human_2017,
	address = {USA},
	edition = {3rd},
	title = {Human {Factors} in {Simple} and {Complex} {Systems}},
	isbn = {978-1-4822-2956-1},
	abstract = {Recently, there have been a number of advances in technology, including in mobile devices, globalization of companies, display technologies and healthcare, all of which require significant input and evaluation from human factors specialists. Accordingly, this textbook has been completely updated, with some chapters folded into other chapters and new chapters added where needed. The text continues to fill the need for a textbook that bridges the gap between the conceptual and empirical foundations of the field.},
	publisher = {CRC Press, Inc.},
	author = {Proctor, Robert W. and Zandt, Trisha Van},
	year = {2017},
}


@book{wickens_engineering_2015,
	edition = {4th},
	title = {Engineering psychology and human performance},
	isbn = {978-0-205-02198-7},
	language = {en},
	publisher = {Pearson Education},
	author = {Wickens, Christopher D. and Hollands, Justin G. and Banbury, Simon and Parasuraman, Raja},
	year = {2015},
	keywords = {Human engineering, Human-machine systems, Psychology, Industrial},
}


@article{camacho_icons_1990,
    author = {Monica J. Camacho and Bruce A. Steiner and Barry L. Berson},
    title ={Icons vs. Alphanumerics in Pilot-Vehicle Interfaces},
    journal = {Proceedings of the Human Factors Society Annual Meeting},
    volume = {34},
    number = {1},
    pages = {11-15},
    year = {1990},
    doi = {10.1177/154193129003400104},
    URL = {https://doi.org/10.1177/154193129003400104},
    abstract = { The effects on performance from the use of icons and alphanumerics in pilot-vehicle interfaces were investigated in an experiment. Varying numbers of single status display indicators were presented in both iconic and alphanumeric formats in fixed and random display positions across three levels of difficulty. Subjects' ability to maintain a tracking task while concurrently searching and selecting appropriate display indicators was tested. Results indicated that for all numbers of indicators presented, icons produced faster search and selection reaction times. Significant interactions were also found for format type and difficulty level. Questionnaire assessment revealed that subjects preferred the iconic to the alphanumeric formats. Implications for the design of aircraft interfaces and further research suggestions are discussed. }
}


@article{perry_dealing_2001,
	title = {Dealing with mobility: understanding access anytime, anywhere},
	volume = {8},
	issn = {1073-0516},
	shorttitle = {Dealing with mobility},
	url = {https://doi.org/10.1145/504704.504707},
	doi = {10.1145/504704.504707},
	abstract = {The rapid and accelerating move towards use of mobile technologies has increasingly provided people and organizations with the ability to work away from the office and on the move. The new ways of working afforded by these technologies are often characterized in terms of access to information and people anytime, anywhere. This article presents a study of mobile workers that highlights different facets of access to remote people and information, and different facets of anytime, anywhere. Four key factors in mobile work are identified: the role of planning, working in "dead time," accessing remote technological and informational resources, and monitoring the activities of remote colleagues. By reflecting on these issues, we can better understand the role of technology and artifacts in mobile work and identify the opportunities for the development of appropriate technological solutions to support mobile workers.},
	number = {4},
	journal = {ACM Transactions on Computer-Human Interaction},
	author = {Perry, Mark and O'hara, Kenton and Sellen, Abigail and Brown, Barry and Harper, Richard},
	month = dec,
	year = {2001},
	keywords = {Awareness, context, dead time, diary study, distributed collaboration, interviews, mobile communication, mobile technology, mobile workers, personal computing},
	pages = {323--347},
}


@article{appel_smartphone_2019,
	title = {Smartphone zombies! {Pedestrians}' distracted walking as a function of their fear of missing out},
	volume = {63},
	issn = {0272-4944},
	url = {https://doi.org/10.1016/j.jenvp.2019.04.003},
	doi = {10.1016/j.jenvp.2019.04.003},
	abstract = {Smartphone use while walking (i.e., being a smartphone zombie) has become a prevalent phenomenon in many cities worldwide. Previous research shows that many pedestrians choose to interact with their phones as they walk around in cities, despite being aware that their behavior might be dangerous. To investigate potential reasons for the prevalence of distracted walking, the current study explores the construct Fear of Missing Out (FoMO) as a potential antecedent of pedestrians' smartphone use while walking. Hierarchical OLS and logistic regression analyses show that FoMO predicts distracted walking, the tendency to engage in virtual social interactions while walking, and dangerous traffic incidents—irrespective of participants’ age and gender. Virtual communication might serve as a compensation for real-world company, thus sidelining the need to traverse safely.},
	language = {en},
	journal = {Journal of Environmental Psychology},
	author = {Appel, Markus and Krisch, Nina and Stein, Jan-Philipp and Weber, Silvana},
	month = jun,
	year = {2019},
	keywords = {Distracted walking, Fear of Missing Out, Pedestrians, Smartphone},
	pages = {130--133},
}


@article{shin_effects_2014,
	title = {Effects of {Cervical} {Flexion} on the {Flexion}-relaxation {Ratio} during {Smartphone} {Use}},
	volume = {26},
    url = {https://doi.org/10.1589/jpts.26.1899},
	doi = {10.1589/jpts.26.1899},
	abstract = {[Purpose] The purpose of this study was to measure the cervical flexion-relaxation ratio          (FRR) and intensity of neck pain and identify the differences according to postures          adopted while using smartphones. [Subjects] Fifteen healthy adults with no neck pain,          spinal trauma, or history cervical surgery participated in this study. [Methods] The          activity of the cervical erector spinae muscle was recorded while performing a          standardized cervical flexion-extension movement in three phases (flexion, sustained full          flexion, extension). And neck pain intensity was recorded using a visual analog scale          (VAS) with values between 0 and 10. Postures held while using a smartphone are          distinguished between desk postures and lap postures. The FRR was calculated by dividing          the maximal muscle activation during the extension phase by average activation during the          complete flexion phase. [Results] No significant differences were found in the FRR between          desk posture, lap posture, and baseline, though the intensity of the neck pain increased          in the lap posture. [Conclusion] The FRR could be a significant criterion of neuromuscular          impairment in chronic neck pain or lumbar pain patients, but it is impossible to          distinguish neck pain that is caused by performing task for a short time. Prolonged lap          posture might cause neck pain, so the use of smartphones for a long time in this posture          should be avoided.},
	number = {12},
	journal = {Journal of Physical Therapy Science},
	author = {Shin, HyeonHui and Kim, KyeongMi},
	year = {2014},
	keywords = {Cervical flexion-relaxation ratio, Electromyography, Smartphone},
	pages = {1899--1901},
}


@article{gustafsson_texting_2017,
	title = {Texting on mobile phones and musculoskeletal disorders in young adults: {A} five-year cohort study},
	volume = {58},
	issn = {0003-6870},
	shorttitle = {Texting on mobile phones and musculoskeletal disorders in young adults},
	url = {https://doi.org/10.1016/j.apergo.2016.06.012},
	doi = {10.1016/j.apergo.2016.06.012},
	abstract = {The aim was to examine whether texting on a mobile phone is a risk factor for musculoskeletal disorders in the neck and upper extremities in a population of young adults. In a longitudinal population-based cohort study with Swedish young adults (aged 20–24 years) data were collected via a web-based questionnaire at baseline (n = 7092) and after one and five years. Cross-sectional associations were found between text messaging and reported ongoing symptoms in neck and upper extremities (odds ratios, ORs 1.3–2.0). Among symptom-free at baseline prospective associations were only found between text messaging and new cases of reported symptoms in the hand/fingers (OR 2.0) at one year follow up. Among those with symptoms at baseline prospective associations were found between text messaging and maintained pain in neck/upper back (OR 1.6). The results imply mostly short-term effects, and to a lesser extent, long-term effects on musculoskeletal disorders in neck and upper extremities.},
	language = {en},
	journal = {Applied Ergonomics},
	author = {Gustafsson, Ewa and Thomée, Sara and Grimby-Ekman, Anna and Hagberg, Mats},
	month = jan,
	year = {2017},
	keywords = {Neck pain, SMS, Upper extremities},
	pages = {208--214},
}

@article{basch_pedestrian_2015,
	title = {Pedestrian {Behavior} at {Five} {Dangerous} and {Busy} {Manhattan} {Intersections}},
	volume = {40},
	issn = {1573-3610},
	url = {https://doi.org/10.1007/s10900-015-0001-9},
	doi = {10.1007/s10900-015-0001-9},
	abstract = {Technology-related distracted behavior is an emergent national concern. Listening to, looking at or talking into an electronic device while walking divides attention, increasing the risk of injury. The purpose of this study was to quantify technology-related distracted pedestrian behavior at five dangerous and busy Manhattan intersections. Data were collected over ten cycles of signal changes at each of the four corners of five intersections at four times of day. Data for ‘Walk’ and ‘Don’t Walk’ signals were tallied separately. A total of 21,760 pedestrians were observed. Nearly one-third crossing on a ‘Walk’ signal (n = 5414, 27.8 \%), and nearly half crossing on a ‘Don’t Walk’ signal (n = 974; 42.0 \%) were wearing headphones, talking on a mobile phone, and/or looking down at an electronic device. Headphone use was the most common distraction.},
	language = {en},
	number = {4},
	journal = {Journal of Community Health},
	author = {Basch, Corey H. and Ethan, Danna and Zybert, Patricia and Basch, Charles E.},
	month = aug,
	year = {2015},
	pages = {789--792},
}


@article{wolk_pictogram_2017,
	title = {Pictogram-based mobile first medical aid communicator},
	volume = {121},
	issn = {1877-0509},
	url = {https://doi.org/10.1016/j.procs.2017.11.002},
	doi = {10.1016/j.procs.2017.11.002},
	abstract = {Recent progress in communications technology has been very rapid. High-speed mobile Internet access and mobile devices have enabled the development of robust technologies such as machine translation, automated speech recognition, voice synthesis, and even speech-to-speech translation. Communication applications that support sign language recognition are also being introduced and upgraded. Nonetheless, people with speech, hearing, or mental impairment still require special communication assistance, especially for medical purposes; this makes their health and life dependent on other people. Automatic solutions for speech recognition or voice synthesis from the text are poor fits for communication in the medical domain because they are dependent on error-prone statistical models. Additionally, in emergency cases, rapid information exchange is essential. Systems dependent on manual text input are insufficient. Recently introduced systems for automatic sign language recognition are dependent on statistical models and image and gesture quality. Such systems remain in early development and are based mostly on minimal hand gestures unsuitable for medical purposes. Furthermore, Internet-dependent solutions cannot be used in most countries requiring humanitarian aid. We propose a high-speed, intuitive, Internet-free, voice-free, and text-free tool suited for emergency medical communication. Our solution is a pictogram-based communication application that provides easy communication means for individuals who are speech- or hearing-impaired, have mental health issues impairing communication, or non-natives who do not speak the local language. It provides support and clarification in communication with such people using intuitive icons and interactive symbols easy to find on a mobile device. Such pictogram-based communication can be quite effective and, ultimately, make some people’s lives happier, easier, and safer. We have developed a conceptual prototype of a patient-physician communicator on a smartwatch that can be used for local as well as remote communication.},
	journal = {Procedia Computer Science},
	author = {Wołk, Krzysztof and Wołk, Agnieszka and Marasek, Krzystof and Glinkowski, Wojciech},
	year = {2017},
	keywords = {HPO, human phenotype ontology, machine translation, medical translation},
	pages = {3--10},
}

@phdthesis{sevens_words_2018,
	title = {Words {Divide}, {Pictographs} {Unite}: {Pictograph} {Communication} {Technologies} for {People} with an {Intellectual} {Disability}},
	shorttitle = {Words {Divide}, {Pictographs} {Unite}},
	url = {https://lirias.kuleuven.be/retrieve/518329},
	abstract = {In order to improve the accessibility of the Internet for users with reading and writing disabilities, we develop a set of tools that automatically translate Dutch natural language text into pictographs and vice versa for people with an intellectual disability (ID), allowing them to read and write status updates, emails, and chat messages in online environments. For the conversion of texts into pictographs, we start from an existing system (Vandeghinste et al. 2017). We evaluate the baseline Text-to-Pictograph translation system using automated metrics, manual assessments, and focus groups with real end users, and propose three improvements: We create a spelling correction tool for people with ID, we develop a syntactic simplification tool and a temporality detection module that uses deep syntactic analysis, and we implement a word sense disambiguation tool for improved semantic analysis. The added value of each one of these components is measured by a combination of automated metrics, manual evaluations, and, where possible, user studies. Conversely, the Pictograph-to-Text translation tool provides help in constructing Dutch textual messages by allowing a user to input a series of pictographs, and then translates these messages into natural language text. The challenge in Pictograph-to-Text translation is twofold. The first task involves the development of an accessible interface that allows people with ID to find the pictographs of their choice. The second task concerns the actual development of the Pictograph-to-Text translation engine. We discuss a variety of approaches, including language modelling and (neural) machine translation techniques, toward the generation of rich natural language text from underspecified pictograph input.},
	language = {eng},
	author = {Sevens, L.},
	collaborator = {Van Eynde, F. and Vandeghinste, V.},
	year = {2018},
}

@inproceedings{gruenefeld_guiding_2018,
	address = {Munich, Germany},
	title = {Guiding {Smombies}: {Augmenting} {Peripheral} {Vision} with {Low}-{Cost} {Glasses} to {Shift} the {Attention} of {Smartphone} {Users}},
	isbn = {978-1-5386-7592-2},
	shorttitle = {Guiding {Smombies}},
	url = {https://doi.org/10.1109/ISMAR-Adjunct.2018.00050},
	doi = {10.1109/ISMAR-Adjunct.2018.00050},
	language = {en},
	booktitle = {2018 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} {Adjunct} ({ISMAR}-{Adjunct})},
	publisher = {IEEE},
	author = {Gruenefeld, Uwe and Stratmann, Tim Claudius and Jung, Jinki and Lee, Hyeopwoo and Choi, Jeehye and Nanda, Abhilasha and Heuten, Wilko},
	month = oct,
	year = {2018},
	pages = {127--131},
}


@inproceedings{schroder_effects_2008,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Effects of {Icon} {Concreteness} and {Complexity} on {Semantic} {Transparency}: {Younger} vs. {Older} {Users}},
	isbn = {978-3-540-70540-6},
	shorttitle = {Effects of {Icon} {Concreteness} and {Complexity} on {Semantic} {Transparency}},
	doi = {10.1007/978-3-540-70540-6_12},
        url = {https://doi.org/10.1007/978-3-540-70540-6_12},
	abstract = {The semantic transparency of icons in mobile devices was investigated using 48 icons for 12 mobile phone functions. Icons included original ones as well as icons specifically designed for experimental purposes. In order to determine the impact of age, each 10 younger and 10 older adults were examined. Having been acquainted with a reference function, participants had to decide for each of four icons shown on a display as fast as possible whether they represented the respective function. Speed and accuracy of responses were used as dependent variables. Though older adults generally responded slower than younger ones, the very same effects of icon concreteness and complexity showed up in both age groups. Real phone icons did not yield a better performance indicating a suboptimal design. Overall, use of icons in mobile devices in principle can be recommended for users within a wide range of age, if icon design obeys ergonomic rules.},
	language = {en},
	booktitle = {Computers {Helping} {People} with {Special} {Needs}},
	publisher = {Springer},
	author = {Schröder, Sabine and Ziefle, Martina},
	editor = {Miesenberger, Klaus and Klaus, Joachim and Zagler, Wolfgang and Karshmer, Arthur},
	year = {2008},
	keywords = {ageing, complexity, concreteness, Icon recognition, mobile devices},
	pages = {90--97},
}


@article{hameen_anttila_pictograms_2004,
	title = {Do pictograms improve children's understanding of medicine leaflet information?},
	volume = {55},
	issn = {0738-3991},
	url = {https://doi.org/10.1016/j.pec.2003.04.006},
	doi = {10.1016/j.pec.2003.04.006},
	abstract = {There is a growing need for balanced drug information customized for special target groups such as children [Food and Drug Administration. Prescription Drug Product Labeling; Medication Guide Requirements; Proposed Rule. Part VII. Department of Health and Human Services, 21 CRF Part 201, et al. Federal Register 1995;60:44182–252; Dickinson D, Raynor DK, Duman M. Patient information leaflets for medicines: using consumer testing to determine the most effective design. Patient Educ Couns 2001;43:147–59]. Pictograms are one aid that may be used to make information easier to read and understand. The aim of this study was to test whether children understand pictograms developed by the United States Pharmacopeia (USP) [The United States Pharmacopeial Convention Inc. USP Pictograms. Retrieved 11 March 2002 from http://www.usp.org/], and especially, if the pictograms improve children's understanding of medicine leaflet information. Finnish elementary school children aged 7 years (n=28), 11 years (n=31) and 13 years (n=31) were interviewed and asked what they thought 15 USP pictograms mean. The two older age groups were also asked to read an “easy-to-read” leaflet for penicillin-V. Every second child was given a leaflet with a plain text and the others received the same text accompanied by pictograms. After reading the leaflet, the children were asked seven questions related to the text. Most of the children understood the meanings of the selected 15 pictograms correctly, the proportion of the correct explanations varying from 30 to 99\% according to the pictogram. Even well-understood pictograms did not help the children understand the leaflet information, although they reduced the need for probing. This study shows that the context in which pictograms are tested makes a difference in the results. Testing plain pictograms without incorporating them in their real context, e.g., in the patient information leaflet may exaggerate their usefulness in leaflet information.},
	language = {en},
	number = {3},
	journal = {Patient Education and Counseling},
	author = {Hämeen-Anttila, Katri and Kemppainen, Kati and Enlund, Hannes and Bush Patricia, J and Marja, Airaksinen},
	month = dec,
	year = {2004},
	keywords = {Children, Patient education, Patient information leaflet, Pictograms},
	pages = {371--378},
}


@misc{google_user_2021,
	title = {User {Interface} {\textbar} {Glass} {Explorer} {Edition}},
	url = {https://developers.google.com/glass/design/ui},
	language = {en},
	urldate = {2021-05-14},
	journal = {Google Developers},
	author = {Google},
	year = {2021},
}


@article{houts_role_2006,
	title = {The role of pictures in improving health communication: {A} review of research on attention, comprehension, recall, and adherence},
	volume = {61},
	issn = {07383991},
	shorttitle = {The role of pictures in improving health communication},
	url = {https://doi.org/10.1016/j.pec.2005.05.004},
	doi = {10.1016/j.pec.2005.05.004},
	abstract = {Objective: To assess the effects of pictures on health communications. Method: Peer reviewed studies in health education, psychology, education, and marketing journals were reviewed. There was no limit placed on the time periods searched. Results: Pictures closely linked to written or spoken text can, when compared to text alone, markedly increase attention to and recall of health education information. Pictures can also improve comprehension when they show relationships among ideas or when they show spatial relationships. Pictures can change adherence to health instructions, but emotional response to pictures affects whether they increase or decrease target behaviors. All patients can beneﬁt, but patients with low literacy skills are especially likely to beneﬁt. Patients with very low literacy skills can be helped by spoken directions plus pictures to take home as reminders or by pictures plus very simply worded captions. Practice implications: Educators should: (1) ask ‘‘how can I use pictures to support key points?’’, (2) minimize distracting details in pictures, (3) use simple language in conjunction with pictures, (4) closely link pictures to text and/or captions, (5) include people from the intended audience in designing pictures, (6) have health professionals plan the pictures, not artists, and (7) evaluate pictures’ effects by comparing response to materials with and without pictures.},
	language = {en},
	number = {2},
	journal = {Patient Education and Counseling},
	author = {Houts, Peter S. and Doak, Cecilia C. and Doak, Leonard G. and Loscalzo, Matthew J.},
	month = may,
	year = {2006},
	pages = {173--190},
}

@article{hildon_impact_2012,
	title = {Impact of format and content of visual display of data on comprehension, choice and preference: a systematic review},
	volume = {24},
	issn = {1464-3677, 1353-4505},
	shorttitle = {Impact of format and content of visual display of data on comprehension, choice and preference},
	url = {https://doi.org/10.1093/intqhc/mzr072},
	doi = {10.1093/intqhc/mzr072},
	abstract = {Purpose. Displays comparing the performance of healthcare providers are largely based on commonsense. To review the literature on the impact of compositional format and content of quantitative data displays on people’s comprehension, choice and preference. Data sources. Ovid databases, expert recommendations and snowballing techniques. Study selection. Evaluations of the impact of different formats (bar charts, tables and pictographs) and content (ordering, explanatory visual cues, etc.) of quantitative data displays meeting deﬁned quality criteria. Data extraction. Type of decision; decision-making domains; audiences; formats; content; methodology; ﬁndings.
Results of data synthesis. Most of the 30 studies used quantitative (n ¼ 26) methods with patients or public groups (n ¼ 28) rather than with professionals (n ¼ 2). Bar charts were the most frequent format, followed by pictographs and tables. As regards format, tables and pictographs appeared better understood than bar charts despite the latter being preferred. Although accessible to less numerate and older populations, pictographs tended to lead to more risk avoidance. Tables appeared accessible to all. Aspects of content enhancing the impact of data displays included giving visual explanatory cues and contextual information while still attempting simplicity (‘less is more’); ordering data; consistency. Icons rather than numbers were more user-friendly but could lead to over-estimation of risk. Uncertainty was not widely understood, nor well represented.
Conclusions. Though heterogeneous and limited in scope, there is sufﬁcient research evidence to inform the presentation of quantitative data that compares the performance of healthcare providers. The impact of new formats, such as funnel plots, needs to be evaluated.},
	language = {en},
	number = {1},
	journal = {International Journal for Quality in Health Care},
	author = {Hildon, Zoe and Allwood, Dominique and Black, Nick},
	month = feb,
	year = {2012},
	pages = {55--64},
}

@article{leos_toro_perceptions_2019,
	title = {Perceptions of effectiveness and believability of pictorial and text-only health warning labels for cannabis products among {Canadian} youth},
	volume = {73},
	issn = {0955-3959},
	url = {https://doi.org/10.1016/j.drugpo.2019.07.001},
	doi = {10.1016/j.drugpo.2019.07.001},
	abstract = {Background
Health warnings have been shown to increase knowledge and awareness of health risks, influence social norms, and reduce consumption of tobacco products. With the legalization of non-medical cannabis in Canada and other subnational jurisdictions, there is a need for empirical studies to examine the impact of cannabis health warnings on consumer perceptions and behaviour relevant to cannabis.
Methods
In October 2017, a between-group experiment was conducted as part of an online survey of Canadians aged 16 to 30 years (N = 870) recruited from a national consumer panel. Participants rated the perceived effectiveness and believability of either text-only or pictorial cannabis health warnings and then completed a message recall task. Participants also reported their level of support for cannabis warnings, and support for including cessation information and a quitline on the warnings.
Results
Pictorial health warnings for cannabis products were perceived as more effective and believable than text-only warnings (p {\textless} 0.001), and the superiority of pictorial warnings was found across different warnings: dose (p = 0.039), co-morbid drug use (p = 0.006), and pregnancy (p {\textless} 0.001). Pictorial warnings were also rated as more believable (p = 0.048). Overall, 87.7\% respondents supported having health warnings on cannabis products, and 84.0\% supported the inclusion of a quitline number on cannabis health warnings.
Conclusion
The current study provides the first empirical test of cannabis health warnings, consistent with the considerable body of evidence on the effectiveness of pictorial warnings on tobacco products. There was strong support for the inclusion of picture warnings and the inclusion of resources and quitlines on cannabis packaging.},
	language = {en},
	journal = {International Journal of Drug Policy},
	author = {Leos-Toro, Cesar and Fong, Geoffrey T. and Meyer, Samantha B. and Hammond, David},
	month = nov,
	year = {2019},
	keywords = {Cannabis consumer behaviour, Cannabis health communication, Cannabis labeling, Cannabis product packaging, Cannabis use},
	pages = {24--31},
}


@inproceedings{zhou_goodbye_2017,
	address = {New York, NY, USA},
	series = {{CHI} '17},
	title = {Goodbye {Text}, {Hello} {Emoji}: {Mobile} {Communication} on {WeChat} in {China}},
	isbn = {978-1-4503-4655-9},
	shorttitle = {Goodbye {Text}, {Hello} {Emoji}},
	url = {https://doi.org/10.1145/3025453.3025800},
	doi = {10.1145/3025453.3025800},
	abstract = {We present a qualitative study of mobile communication via WeChat in Southern China, focusing on the rapid proliferation of emoji and stickers and the lessening dependence on text. We use interview and observation data from 30 participants to investigate how rural, small town, and urban Chinese adults creatively and innovatively balance the use of emoji, stickers, and text in their mobile communication practices. We also discuss design implications of our research for the field of HCI, offering ways of leveraging the non-textual communication practices that we uncover, in scenarios where purely text-based communication may not suffice.},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhou, Rui and Hentschel, Jasmine and Kumar, Neha},
	month = may,
	year = {2017},
	keywords = {china, emoji, mobile, qualitative methods, stickers, wechat},
	pages = {748--759},
}


@article{rayner1977visual,
  title={Visual attention in reading: Eye movements reflect cognitive processes},
  author={Rayner, Keith},
  journal={Memory \& cognition},
  volume={5},
  number={4},
  pages={443--448},
  year={1977},
  publisher={Springer}
}

@article{bevan2018benefiting,
  title={Benefiting from ISO standards},
  author={Bevan, Nigel and Earthy, Jonathan},
  journal={The Wiley Handbook of Human Computer Interaction},
  volume={1},
  pages={51--69},
  year={2018},
  publisher={Wiley Online Library}
}

@inproceedings{fitrianie_communication_2005,
	title = {Communication in {Crisis} {Situations} {Using} {Icon} {Language}},
	doi = {10.1109/ICME.2005.1521685},
        url = {https://doi.org/10.1109/ICME.2005.1521685},
	abstract = {To reduce the ambiguity and the different semantic interpretation of human observers' reports, we propose a new paradigm in collaborating information using icons to represent concepts or ideas. Two prototypes of icon-based communication interfaces were developed with which users can create iconic messages to report situations where a crisis event occurs. The interfaces interpret and convert the messages to human natural language. A context-aware collaborative information system filters irrelevant and infidelity reports and shares the results for further decision making},
	booktitle = {2005 {IEEE} {International} {Conference} on {Multimedia} and {Expo}},
	author = {Fitrianie, S. and Rothkrantz, L.J.M.},
	month = jul,
	year = {2005},
	keywords = {Collaboration, Context, Decision making, Humans, Information filtering, Information filters, Information systems, Natural languages, Personal digital assistants, Prototypes},
	pages = {1370--1373},
}



@inproceedings{munemori_pictograph_2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Pictograph {Chat} {Communicator} {III}: {A} {Chat} {System} {That} {Embodies} {Cross}-{Cultural} {Communication}},
	isbn = {978-3-642-15393-8},
	shorttitle = {Pictograph {Chat} {Communicator} {III}},
	doi = {10.1007/978-3-642-15393-8_53},
        url = {https://doi.org/10.1007/978-3-642-15393-8_53},
	abstract = {The Pictograph Chat Communicator III is a modified version of the conventional system, where pictograph selection and the taxonomy of pictographs were taken a closer look. We added new pictographs (subjects, verbs, adjectives, 5W1H, symbols, and alphabets) and deleted unnecessary pictographs. We also changed the taxonomy of pictographs. Experiments were carried out 9 times in international conference halls of America, Vietnam, and Portugal, between people who do not share the same spoken language (or native language). As a result, the level of understanding is 91.1\%. We supposed that pictograph communication was enough in the ice-breaking communications.},
	language = {en},
	booktitle = {Knowledge-{Based} and {Intelligent} {Information} and {Engineering} {Systems}},
	publisher = {Springer},
	author = {Munemori, Jun and Fukuda, Taro and Mohd Yatid, Moonyati Binti and Nishide, Tadashi and Itou, Junko},
	editor = {Setchi, Rossitza and Jordanov, Ivan and Howlett, Robert J. and Jain, Lakhmi C.},
	year = {2010},
	pages = {473--482},
}


@inproceedings{cho_assisting_2008,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Assisting {Pictogram} {Selection} with {Semantic} {Interpretation}},
	isbn = {978-3-540-68234-9},
	doi = {10.1007/978-3-540-68234-9_8},
        url = {https://doi.org/10.1007/978-3-540-68234-9_8},
	abstract = {Participants at both end of the communication channel must share common pictogram interpretation to communicate. However, because pictogram interpretation can be ambiguous, pictogram communication can sometimes be difficult. To assist human task of selecting pictograms more likely to be interpreted as intended, we propose a semantic relevance measure which calculates how relevant a pictogram is to a given interpretation. The proposed measure uses pictogram interpretations and frequencies gathered from a web survey to define probability and similarity measurement of interpretation words. Moreover, the proposed measure is applied to categorized pictogram interpretations to enhance retrieval performance. Five pictogram categories are created using the five first level categories defined in the Concept Dictionary of EDR Electronic Dictionary. Retrieval performance among not-categorized interpretations, categorized and not-weighted interpretations, and categorized and weighted interpretations using semantic relevance measure were compared, and the categorized and weighted semantic relevance retrieval approach exhibited the highest F 1 measure and recall.},
	language = {en},
	booktitle = {The {Semantic} {Web}: {Research} and {Applications}},
	publisher = {Springer},
	author = {Cho, Heeryon and Ishida, Toru and Takasaki, Toshiyuki and Oyama, Satoshi},
	editor = {Bechhofer, Sean and Hauswirth, Manfred and Hoffmann, Jörg and Koubarakis, Manolis},
	year = {2008},
	keywords = {Good Night, Retrieval Performance, Retrieval Task, Semantic Interpretation, Word Query},
	pages = {65--79},
}

@inproceedings{sapkota_ubiquitous_2021,
	address = {Toulouse \& Virtual France},
	title = {Ubiquitous {Interactions} for {Heads}-{Up} {Computing}: {Understanding} {Users}’ {Preferences} for {Subtle} {Interaction} {Techniques} in {Everyday} {Settings}},
	isbn = {978-1-4503-8328-8},
	shorttitle = {Ubiquitous {Interactions} for {Heads}-{Up} {Computing}},
	url = {https://doi.org/10.1145/3447526.3472035},
	doi = {10.1145/3447526.3472035},
	abstract = {In order to satisfy users’ information needs while incurring minimum interference to their ongoing activities, previous studies have proposed using Optical Head-mounted Displays (OHMDs) with ∗Both authors contributed equally to this research.},
	language = {en},
	booktitle = {Proceedings of the 23rd {International} {Conference} on {Mobile} {Human}-{Computer} {Interaction}},
	publisher = {ACM},
	author = {Sapkota, Shardul and Ram, Ashwin and Zhao, Shengdong},
	month = sep,
	year = {2021},
	pages = {1--15},
}





































% Progress bar

@book{panero1979human,
  title={Human dimension \& interior space: a source book of design reference standards},
  author={Panero, Julius and Zelnik, Martin},
  year={1979},
  publisher={Watson-Guptill}
}

@article{argyle1976gaze,
  title={Gaze and mutual gaze.},
  author={Argyle, Michael and Cook, Mark},
  year={1976},
  publisher={Cambridge U Press}
}

@article{hessels_how_2020,
	title = {How does gaze to faces support face-to-face interaction? {A} review and perspective},
	volume = {27},
	issn = {1069-9384, 1531-5320},
	shorttitle = {How does gaze to faces support face-to-face interaction?},
	url = {https://doi.org/10.3758/s13423-020-01715-w},
	doi = {10.3758/s13423-020-01715-w},
	abstract = {Gaze—where one looks, how long, and when—plays an essential part in human social behavior. While many aspects of social gaze have been reviewed, there is no comprehensive review or theoretical framework that describes how gaze to faces supports face-to-face interaction. In this review, I address the following questions: (1) When does gaze need to be allocated to a particular region of a face in order to provide the relevant information for successful interaction; (2) How do humans look at other people, and faces in particular, regardless of whether gaze needs to be directed at a particular region to acquire the relevant visual information; (3) How does gaze support the regulation of interaction? The work reviewed spans psychophysical research, observational research, and eye-tracking research in both lab-based and interactive contexts. Based on the literature overview, I sketch a framework for future research based on dynamic systems theory. The framework holds that gaze should be investigated in relation to sub-states of the interaction, encompassing sub-states of the interactors, the content of the interaction as well as the interactive context. The relevant sub-states for understanding gaze in interaction vary over different timescales from microgenesis to ontogenesis and phylogenesis. The framework has important implications for vision science, psychopathology, developmental science, and social robotics.},
	language = {en},
	number = {5},
	journal = {Psychonomic Bulletin \& Review},
	author = {Hessels, Roy S.},
	month = oct,
	year = {2020},
	pages = {856--881},
}

@article{rosenholtz_capabilities_2016,
	title = {Capabilities and {Limitations} of {Peripheral} {Vision}},
	volume = {2},
	issn = {2374-4642, 2374-4650},
	url = {https://doi.org/10.1146/annurev-vision-082114-035733},
	doi = {10.1146/annurev-vision-082114-035733},
	abstract = {This review discusses several pervasive myths about peripheral vision, as well as what is actually true: Peripheral vision underlies a broad range of visual tasks, in spite of its signiﬁcant loss of information. New understanding of peripheral vision, including likely mechanisms, has deep implications for our understanding of vision. From peripheral recognition to visual search, from change blindness to getting the gist of a scene, a lossy but relatively ﬁxed peripheral encoding may determine the difﬁculty of many tasks. This ﬁnding suggests that the visual system may be more stable, and less dynamically changing as a function of attention, than previously assumed.},
	language = {en},
	number = {1},
	journal = {Annual Review of Vision Science},
	author = {Rosenholtz, Ruth},
	month = oct,
	year = {2016},
	pages = {437--457},
}

@article{strasburger_peripheral_2011,
	title = {Peripheral vision and pattern recognition: {A} review},
	volume = {11},
	issn = {1534-7362},
	shorttitle = {Peripheral vision and pattern recognition},
	url = {https://doi.org/10.1167/11.5.13},
	doi = {10.1167/11.5.13},
	abstract = {We summarize the various strands of research on peripheral vision and relate them to theories of form perception. After a historical overview, we describe quantiﬁcations of the cortical magniﬁcation hypothesis, including an extension of Schwartz’s cortical mapping function. The merits of this concept are considered across a wide range of psychophysical tasks, followed by a discussion of its limitations and the need for non-spatial scaling. We also review the eccentricity dependence of other low-level functions including reaction time, temporal resolution, and spatial summation, as well as perimetric methods. A central topic is then the recognition of characters in peripheral vision, both at low and high levels of contrast, and the impact of surrounding contours known as crowding. We demonstrate how Bouma’s law, specifying the critical distance for the onset of crowding, can be stated in terms of the retinocortical mapping. The recognition of more complex stimuli, like textures, faces, and scenes, reveals a substantial impact of mid-level vision and cognitive factors. We further consider eccentricity dependent limitations of learning, both at the level of perceptual learning and pattern category learning. Generic limitations of extrafoveal vision are observed for the latter in categorization tasks involving multiple stimulus classes. Finally, models of peripheral form vision are discussed. We report that peripheral vision is limited with regard to pattern categorization by a distinctly lower representational complexity and processing speed. Taken together, the limitations of cognitive processing in peripheral vision appear to be as signiﬁcant as those imposed on low-level functions and by way of crowding.},
	language = {en},
	number = {5},
	journal = {Journal of Vision},
	author = {Strasburger, H. and Rentschler, I. and Juttner, M.},
	month = dec,
	year = {2011},
	pages = {13--13},
}

@inproceedings{ku_peritext_2019,
	title = {{PeriText}: {Utilizing} {Peripheral} {Vision} for {Reading} {Text} on {Augmented} {Reality} {Smart} {Glasses}},
	shorttitle = {{PeriText}},
	doi = {10.1109/VR.2019.8798065},
        url = {https://doi.org/10.1109/VR.2019.8798065},
	abstract = {Augmented Reality (AR) provides real-time information by superimposing virtual information onto users' view of the real world. Our work is the first to explore how peripheral vision, instead of central vision, can be used to read text on AR and smart glasses. We present Peritext, a multiword reading interface using rapid serial visual presentation (RSVP). This enables users to observe the real world using central vision, while using peripheral vision to read virtual information. We first conducted a lab-based study to determine the effect of different text transformation by comparing reading efficiency among 3 capitalization schemes, 2 font faces, 2 text animation methods, and 3 different numbers of words for RSVP paradigm. We found that title case capitalization, sans-serif font and word-wise typewriter animation with multiword RSVP display resulted in better reading efficiency, which together formed our Peritext design. Another lab-based study followed, investigating the performance of the Peritext against control text, and the results showed significant better performance. Finally, we conducted a field study to collect user feedback while using Peritext in real-world walking scenarios, and all users reported a preference of 5° eccentricity over 8°.},
	booktitle = {2019 {IEEE} {Conference} on {Virtual} {Reality} and {3D} {User} {Interfaces} ({VR})},
	author = {Ku, Pin-Sung and Lin, Yu-Chih and Peng, Yi-Hao and Chen, Mike Y.},
	month = mar,
	year = {2019},
	keywords = {Animation, augmented reality, locomotion, mobile, Monitoring, multiword, peripheral vision, rapid serial visual presentation, reading interface, Smart glasses, Visualization},
	pages = {630--635},
}

@inproceedings{cidota_workspace_2016,
	address = {Geneva, Switzerland},
	title = {Workspace {Awareness} in {Collaborative} {AR} using {HMDs}: {A} {User} {Study} {Comparing} {Audio} and {Visual} {Notifications}},
	isbn = {978-1-4503-3680-2},
	shorttitle = {Workspace {Awareness} in {Collaborative} {AR} using {HMDs}},
	url = {https://doi.org/10.1145/2875194.2875204},
	doi = {10.1145/2875194.2875204},
	abstract = {For most professional tasks nowadays, it is necessary to work in teams. Such collaboration often requires the exchange of visual context-related information among the team members. For so-called shared workspace collaboration, awareness of other people’s activities is of utmost importance. We have developed an augmented reality (AR) framework in order to support visual communication between a team of two people who are virtually co-located. We address these people as the remote user, who uses a laptop and the local user, who wears a head-mounted display (HMD) with an RGB camera. The remote user can support the local user in solving a spatial problem by providing instructions as virtual objects in the view of the local user. For placing virtual objects in the shared workspace, we use a state-of-the-art algorithm for localization and mapping without markers. In this paper, we report on a user study that explores on how automatic audio and visual notiﬁcations about the remote user’s activities aﬀect the collaboration. The results show that in our current implementation, visual notiﬁcations are preferred over audio or no notiﬁcations independent from the level of diﬃculty of the task.},
	language = {en},
	booktitle = {Proceedings of the 7th {Augmented} {Human} {International} {Conference} 2016 on - {AH} '16},
	publisher = {ACM Press},
	author = {Cidota, Marina and Lukosch, Stephan and Datcu, Dragos and Lukosch, Heide},
	year = {2016},
	pages = {1--8},
}

@inproceedings{koelle_dont_2015,
	address = {Copenhagen Denmark},
	title = {Don't look at me that way!: {Understanding} {User} {Attitudes} {Towards} {Data} {Glasses} {Usage}},
	isbn = {978-1-4503-3652-9},
	shorttitle = {Don't look at me that way!},
	url = {https://doi.org/10.1145/2785830.2785842},
	doi = {10.1145/2785830.2785842},
	abstract = {Data glasses do carry promising potential for hands-free interaction, but also raise various concerns amongst their potential users. In order to gain insights into the nature of those concerns, we investigate how potential usage scenarios are perceived by device users and their peers. We present results of a two-step approach: a focus group discussion with 7 participants, and a user study with 38 participants. In particular, we look into differences between the usage of data glasses and more established devices such as smart phones. We provide quantitative measures for scenario-related social acceptability and point out factors that can inﬂuence user attitudes. Based on our quantitative and qualitative results, we derive design implications that might support the development of head-worn devices and applications with an improved social acceptability.},
	language = {en},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Koelle, Marion and Kranz, Matthias and Möller, Andreas},
	month = aug,
	year = {2015},
	pages = {362--372},
}

@inproceedings{Klinker2018StructureFI,
  title={Structure for innovations: A use case taxonomy for smart glasses in service processes},
  author={Kai Klinker and Lisa Berkemeier and Benedikt Zobel and H. W{\"u}ller and Veronika Huck-Fries and Manuel Wiesche and H. Remmers and Oliver Thomas and H. Krcmar},
  year={2018}
}

@phdthesis{rhodes_just_time_2000,
	title = {Just-{In}-{Time} {Information} {Retrieval}},
	abstract = {This thesis deﬁnes Just-In-Time Information Retrieval agents (JITIRs): a class of software agents that proactively present potentially valuable information based on a person's local context in an easily accessible yet non-intrusive manner. The research described experimentally demonstrates that such systems encourage the viewing and use of information that would not otherwise be viewed, by reducing the cognitive effort required to ﬁnd, evaluate and access information. Experiments and analysis of long-term use provide a deeper understanding of the different ways JITIRs can be valuable: by providing useful or supporting information that is relevant to the current task, by contextualizing the current task in a broader framework, by providing information that is not useful in the current task but leads to the discovery of other information that is useful, and by providing information that is not useful for the current task but is valuable for other reasons. Finally, this research documents heuristics and techniques for the design of JITIRs. These techniques are based on theory and are demonstrated by the ﬁeld-testing of three complete systems: the Remembrance Agent, Margin Notes, and Jimminy. Speciﬁcally, these heuristics are designed to make information accessible with low effort, and yet ignorable should the user wish to concentrate entirely on his primary task.},
	language = {en},
	author = {Rhodes, Bradley James},
	year = {2000},
}

@article{hobert_application_2016,
	title = {Application {Scenarios} of {Smart} {Glasses} in the {Industrial} {Sector}: {Results} of an {Empirical} {Study} {Among} {Domain} {Experts}},
	volume = {15},
	issn = {2196-6826},
	shorttitle = {Application {Scenarios} of {Smart} {Glasses} in the {Industrial} {Sector}},
	url = {https://doi.org/10.1515/icom-2016-0016},
	doi = {10.1515/icom-2016-0016},
	abstract = {Many companies in the industrial sector are currently facing massive changes in order to optimize processes and enable new customer demands (e. g. mass customization of products). Often, these changes are related to a modernization of existing infrastructure to enable cyber-physical systems and smart factories (so called Industry 4.0). These structural changes have effects on business processes and business models. Consequently, the factory workers need to adapt to the changing infrastructure and therefore, it is necessary to analyze how factory workers can be supported during their day-to-day work in the changed environment. Thus, an important aspect is the analysis of human computer interaction interfaces which aim at assisting factory workers. One promising human computer interface solution between cyber-physical systems and factory workers are smart glasses, as this technology is suited for assisting humans hands-free. Since prior research on application scenarios of smart glasses in the industrial sector is limited, the aim of our research is to identify relevant application scenarios. Therefore, we conducted a qualitative, explorative study by interviewing 21 domain experts. Based on this, we derived 15 application scenarios which can be used by both, research and practice, to develop and evaluate new human computer interaction interfaces for industrial applications.},
	language = {en},
	number = {2},
	journal = {i-com},
	author = {Hobert, Sebastian and Schumann, Matthias},
	month = aug,
	year = {2016},
	keywords = {Application Scenarios, Industrial Sector, Smart Glasses, Use Cases, Wearable Computer},
	pages = {133--143},
}

@article{rayner_eye_1998,
	title = {Eye movements in reading and information processing: 20 years of research},
	volume = {124},
	issn = {0033-2909},
	shorttitle = {Eye movements in reading and information processing},
	doi = {10.1037/0033-2909.124.3.372},
        url = {https://doi.org/10.1037/0033-2909.124.3.372},
	abstract = {Recent studies of eye movements in reading and other information processing tasks, such as music reading, typing, visual search, and scene perception, are reviewed. The major emphasis of the review is on reading as a specific example of cognitive processing. Basic topics discussed with respect to reading are (a) the characteristics of eye movements, (b) the perceptual span, (c) integration of information across saccades, (d) eye movement control, and (e) individual differences (including dyslexia). Similar topics are discussed with respect to the other tasks examined. The basic theme of the review is that eye movement data reflect moment-to-moment cognitive processes in the various tasks examined. Theoretical and practical considerations concerning the use of eye movement data are also discussed.},
	language = {eng},
	number = {3},
	journal = {Psychological Bulletin},
	author = {Rayner, K.},
	month = nov,
	year = {1998},
	pmid = {9849112},
	keywords = {Cognition, Humans, Saccades, Mental Processes, Reading},
	pages = {372--422},
}

@article{schotter_parafoveal_2012,
	title = {Parafoveal processing in reading},
	volume = {74},
	issn = {1943-393X},
	url = {https://doi.org/10.3758/s13414-011-0219-2},
	doi = {10.3758/s13414-011-0219-2},
	abstract = {The present review summarizes research investigating how words are identified parafoveally (and foveally) in reading. Parafoveal and foveal processing are compared when no other concurrent task is required (e.g., in single-word recognition tasks) and when both are required simultaneously (e.g., during reading). We first review methodologies used to study parafoveal processing (e.g., corpus analyses and experimental manipulations, including gaze-contingent display change experiments such as the boundary, moving window, moving mask, and fast priming paradigms). We then turn to a discussion of the levels of representation at which words are processed (e.g., orthographic, phonological, morphological, lexical, syntactic, and semantic). Next, we review relevant research regarding parafoveal processing, summarizing the extent to which words are processed at each of those levels of representation. We then review some of the most controversial aspects of parafoveal processing, as they relate to reading: (1) word skipping, (2) parafoveal-on-foveal effects, and (3) n + 1 and n + 2 preview benefit effects. Finally, we summarize two of the most advanced models of eye movements during reading and how they address foveal and parafoveal processing.},
	language = {en},
	number = {1},
	journal = {Attention, Perception, \& Psychophysics},
	author = {Schotter, Elizabeth R. and Angele, Bernhard and Rayner, Keith},
	month = jan,
	year = {2012},
	pages = {5--35},
}

@misc{wiki_fov_2021,
	title = {Field of view},
	url = {https://commons.wikimedia.org/wiki/File:Field_of_view.svg},
	language = {en},
	urldate = {2021-09-08},
	journal = {Wikipedia},
	author = {Zyxwv99},
	month = sep,
	year = {2021},
}

@inproceedings{nguyen_known_2015,
	address = {Seoul Republic of Korea},
	title = {The {Known} {Stranger}: {Supporting} {Conversations} between {Strangers} with {Personalized} {Topic} {Suggestions}},
	isbn = {978-1-4503-3145-6},
	shorttitle = {The {Known} {Stranger}},
	url = {https://doi.org/10.1145/2702123.2702411},
	doi = {10.1145/2702123.2702411},
	abstract = {Striking up a good conversation with new acquaintances is often difficult. In this paper we introduce a system that uses a ranking recommendation algorithm to generate real-time personalized topic suggestions during a conversation. The system then delivers the suggestions via Google Glass. We conducted a study with 38 pairs of strangers, who received such suggestions while conversing with a person they met for the first time. Participants found the suggestions to be helpful, but only at the right moments, and for certain types of speakers. Our results contribute to the understanding of how communication interventions influence people’s experience and behaviors, and enhance interpersonal interactions. Our study also presents design implications for applications on wearable devices to facilitate conversations between strangers.},
	language = {en},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Nguyen, Tien T. and Nguyen, Duyen T. and Iqbal, Shamsi T. and Ofek, Eyal},
	month = apr,
	year = {2015},
	pages = {555--564},
}

@inproceedings{williams_designing_2015,
	address = {Seoul Republic of Korea},
	title = {Designing {Conversation} {Cues} on a {Head}-{Worn} {Display} to {Support} {Persons} with {Aphasia}},
	isbn = {978-1-4503-3145-6},
	url = {https://doi.org/10.1145/2702123.2702484},
	doi = {10.1145/2702123.2702484},
	abstract = {Symbol-based dictionaries of text, images and sound can help individuals with aphasia find the words they need, but are often seen as a last resort because they tend to replace rather than augment the user’s natural speech. Through two design investigations, we explore head-worn displays as a means of providing unobtrusive, always-available, and glanceable vocabulary support. The first study used narrative storyboards as a design probe to explore the potential benefits and challenges of a head-worn approach over traditional augmented alternative communication (AAC) tools. The second study then evaluated a proof-ofconcept prototype in both a lab setting with the researcher and in situ with unfamiliar conversation partners at a local market. Findings suggest that a head-worn approach could better allow wearers to maintain focus on the conversation, reduce reliance on the availability of external tools (e.g., paper and pen) or people, and minimize visibility of the support by others. These studies should motivate further investigation of head-worn conversational support.},
	language = {en},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Williams, Kristin and Moffatt, Karyn and McCall, Denise and Findlater, Leah},
	month = apr,
	year = {2015},
	pages = {231--240},
}

@article{salvucci2013multitasking,
  title={Multitasking.},
  author={Salvucci, Dario D},
  year={2013},
  publisher={Oxford University Press}
}

@article{benbunan2012ethics,
  title={The ethics and etiquette of multitasking in the workplace},
  author={Benbunan-Fich, Raquel},
  journal={IEEE Technology and Society Magazine},
  volume={31},
  number={3},
  pages={15--19},
  year={2012},
  publisher={IEEE},
  doi={10.1109/MTS.2012.2211391},
  url = {https://doi.org/10.1109/MTS.2012.2211391},
}

@article{wang2012myth,
  title={The ``myth'' of media multitasking: Reciprocal dynamics of media multitasking, personal needs, and gratifications},
  author={Wang, Zheng and Tchernev, John M},
  journal={Journal of Communication},
  volume={62},
  number={3},
  pages={493--513},
  url = {https://doi.org/10.1111/j.1460-2466.2012.01641.x},
  year={2012},
  publisher={Oxford University Press}
}

@inproceedings{van_dantzich_scope_2002,
	address = {Trento, Italy},
	title = {Scope: providing awareness of multiple notifications at a glance},
	isbn = {978-1-58113-537-4},
	shorttitle = {Scope},
	url = {https://doi.org/10.1145/1556262.1556306},
	doi = {10.1145/1556262.1556306},
	abstract = {We describe the design and functionality of the Scope, a glanceable notification summarizer. The Scope is an information visualization designed to unify notifications and minimize distractions. It allows users to remain aware of notifications from multiple sources of information, including e-mail, instant messaging, information alerts, and appointments. The design employs a circular radar-like screen divided into sectors that group different kinds of notifications. The more urgent a notification is, the more centrally it is placed. Visual emphasis and annotation is used to reveal important properties of notifications. Several natural gestures allow users to zoom in on particular regions and to selectively drill down on items. We present key aspects of the Scope design, review the results of an initial user study, and describe the motivation and outcome of an iteration on the visual design.},
	language = {en},
	booktitle = {Proceedings of the {Working} {Conference} on {Advanced} {Visual} {Interfaces} - {AVI} '02},
	publisher = {ACM Press},
	author = {van Dantzich, Maarten and Robbins, Daniel and Horvitz, Eric and Czerwinski, Mary},
	year = {2002},
	pages = {267},
}

@article{bernard_new_2016,
	title = {A {New} {Font}, {Specifically} {Designed} for {Peripheral} {Vision}, {Improves} {Peripheral} {Letter} and {Word} {Recognition}, but {Not} {Eye}-{Mediated} {Reading} {Performance}},
	volume = {11},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0152506},
        url = {https://doi.org/10.1371/journal.pone.0152506},
	abstract = {Reading speed is dramatically reduced when readers cannot use their central vision. This is because low visual acuity and crowding negatively impact letter recognition in the periphery. In this study, we designed a new font (referred to as the Eido font) in order to reduce inter-letter similarity and consequently to increase peripheral letter recognition performance. We tested this font by running five experiments that compared the Eido font with the standard Courier font. Letter spacing and x-height were identical for the two monospaced fonts. Six normally-sighted subjects used exclusively their peripheral vision to run two aloud reading tasks (with eye movements), a letter recognition task (without eye movements), a word recognition task (without eye movements) and a lexical decision task. Results show that reading speed was not significantly different between the Eido and the Courier font when subjects had to read single sentences with a round simulated gaze-contingent central scotoma (10° diameter). In contrast, Eido significantly decreased perceptual errors in peripheral crowded letter recognition (-30\% errors on average for letters briefly presented at 6° eccentricity) and in peripheral word recognition (-32\% errors on average for words briefly presented at 6° eccentricity).},
	language = {eng},
	number = {4},
	journal = {PloS One},
	author = {Bernard, Jean-Baptiste and Aguilar, Carlos and Castet, Eric},
	year = {2016},
	pmid = {27074013},
	pmcid = {PMC4830533},
	keywords = {Adult, Eye Movements, Female, Form Perception, Humans, Male, Pattern Recognition, Visual, Photic Stimulation, Reading, Vision, Ocular, Young Adult},
	pages = {25},
}

@inproceedings{mayer_evaluating_2018,
	address = {Montreal QC, Canada},
	title = {Evaluating the {Disruptiveness} of {Mobile} {Interactions}: {A} {Mixed}-{Method} {Approach}},
	isbn = {978-1-4503-5620-6},
	shorttitle = {Evaluating the {Disruptiveness} of {Mobile} {Interactions}},
	url = {https://doi.org/10.1145/3173574.3173980},
	doi = {10.1145/3173574.3173980},
	abstract = {While the proliferation of mobile devices has rendered mobile notiﬁcations ubiquitous, researchers are only slowly beginning to understand how these technologies affect everyday social interactions. In particular, the negative social inﬂuence of mobile interruptions remains unexplored from a methodological perspective. This paper contributes a mixed-method evaluation procedure for assessing the disruptive impact of mobile interruptions in conversation. The approach combines quantitative eye tracking, qualitative analysis, and a simulated conversation environment to enable fast assessment of disruptiveness. It is intended to be used as a part of an iterative interaction design process. We describe our approach in detail, present an example of its use to study a new call declining technique, and reﬂect upon the pros and cons of our approach.},
	language = {en},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '18},
	publisher = {ACM Press},
	author = {Mayer, Sven and Lischke, Lars and Woźniak, Paweł W. and Henze, Niels},
	year = {2018},
	pages = {1--14},
}

@book{cambridge2008speaking,
  title={Speaking Test Preparation Pack for FCE Paperback with DVD},
  author={Cambridge ESOL},
  year={2008},
  publisher={Cambridge University Press}
}

@book{hall1966hidden,
  title={The hidden dimension},
  author={Hall, Edward Twitchell},
  volume={609},
  year={1966},
  publisher={Garden City, NY: Doubleday}
}

@misc{docstoctv_what_2014,
	title = {What {Kind} of {Business} {Is} {Crowdfunding} {Best} {For}?},
	url = {https://www.youtube.com/watch?v=kiwvTdqRBXk},
	abstract = {Karla De Leon emphasizes the best crowdfunding methods for different types of companies. Karla De Leon is the Co-Founder and President of Wazgo.com, a free platform created specifically to help small businesses succeed in crowdfunding and obtaining private investors. Docstoc is the premier online destination to start and grow small businesses.},
	urldate = {2021-12-06},
	author = {{docstocTV}},
	month = mar,
	year = {2014},
}















@book{rosenblum2011see,
  title={See what I'm saying: The extraordinary powers of our five senses},
  author={Rosenblum, Lawrence D},
  year={2011},
  publisher={WW Norton \& Company}
}


@article{itoh_towards_2021,
	title = {Towards {Indistinguishable} {Augmented} {Reality}: {A} {Survey} on {Optical} {See}-through {Head}-mounted {Displays}},
	volume = {54},
	issn = {0360-0300},
	shorttitle = {Towards {Indistinguishable} {Augmented} {Reality}},
	url = {https://doi.org/10.1145/3453157},
	doi = {10.1145/3453157},
	abstract = {Adding virtual information that is indistinguishable from reality has been a long-awaited goal in Augmented Reality (AR). While already demonstrated in the 1960s, only recently have Optical See-Through Head-Mounted Displays (OST-HMDs) seen a reemergence, partially thanks to large investments from industry, and are now considered to be the ultimate hardware for augmenting our visual perception. In this article, we provide a thorough review of state-of-the-art OST-HMD-related techniques that are relevant to realize the aim of an AR interface almost indistinguishable from reality. In this work, we have an initial look at human perception to define requirements and goals for implementing such an interface. We follow up by identifying three key challenges for building an OST-HMD-based AR interface that is indistinguishable from reality: spatial realism, temporal realism, and visual realism. We discuss existing works that aim to overcome these challenges while also reflecting against the goal set by human perception. Finally, we give an outlook into promising research directions and expectations for the years to come.},
	number = {6},
	journal = {ACM Computing Surveys},
	author = {Itoh, Yuta and Langlotz, Tobias and Sutton, Jonathan and Plopski, Alexander},
	month = jul,
	year = {2021},
	keywords = {wearable computing, head-mounted display, Augmented reality, mixed reality, near eye display, optical see through, review, visual coherence},
	pages = {120:1--120:36},
}

@article{milgram_taxonomy_1994,
	title = {Taxonomy of mixed reality visual displays},
	volume = {E77-D},
	issn = {0916-8532},
	language = {en},
	number = {12},
	journal = {IEICE Transactions on Information and Systems},
	author = {Milgram, Paul and Kishino, Fumio},
	year = {1994},
	pages = {1321--1329},
}


@article{azuma_survey_1997,
	title = {A {Survey} of {Augmented} {Reality}},
	volume = {6},
	issn = {1054-7460},
	url = {https://doi.org/10.1162/pres.1997.6.4.355},
	doi = {10.1162/pres.1997.6.4.355},
	abstract = {This paper surveys the field of Augmented Reality, in which 3-D virtual objects are integrated into a 3-D real environment in real time. It describes the medical, manufacturing, visualization, path planning, entertainment and military applications that have been explored. This paper describes the characteristics of Augmented Reality systems, including a detailed discussion of the tradeoffs between optical and video blending approaches. Registration and sensing errors are two of the biggest problems in building effective Augmented Reality systems, so this paper summarizes current efforts to overcome these problems. Future directions and areas requiring further research are discussed. This survey provides a starting point for anyone interested in researching or using Augmented Reality.},
	language = {en},
	number = {4},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Azuma, Ronald T},
	month = aug,
	year = {1997},
	keywords = {augmented-reality},
	pages = {355--385},
}



@inproceedings{gonzalez_constant_2004,
	address = {New York, NY, USA},
	series = {{CHI} '04},
	title = {"{Constant}, constant, multi-tasking craziness": managing multiple working spheres},
	isbn = {978-1-58113-702-6},
	shorttitle = {"{Constant}, constant, multi-tasking craziness"},
	url = {https://doi.org/10.1145/985692.985707},
	doi = {10.1145/985692.985707},
	abstract = {Most current designs of information technology are based on the notion of supporting distinct tasks such as document production, email usage, and voice communication. In this paper we present empirical results that suggest that people organize their work in terms of much larger and thematically connected units of work. We present results of fieldwork observation of information workers in three different roles: analysts, software developers, and managers. We discovered that all of these types of workers experience a high level of discontinuity in the execution of their activities. People average about three minutes on a task and somewhat more than two minutes using any electronic tool or paper document before switching tasks. We introduce the concept of working spheres to explain the inherent way in which individuals conceptualize and organize their basic units of work. People worked in an average of ten different working spheres. Working spheres are also fragmented; people spend about 12 minutes in a working sphere before they switch to another. We argue that design of information technology needs to support people's continual switching between working spheres.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {González, Victor M. and Mark, Gloria},
	month = apr,
	year = {2004},
	keywords = {attention management, empirical study, information overload, interruptions, personal information management},
	pages = {113--120},
}


@article{spink2008multitasking,
    author = {Spink, Amanda and Cole, Charles and Waller, Mary},
    title = {Multitasking behavior},
    journal = {Annual Review of Information Science and Technology},
    volume = {42},
    number = {1},
    pages = {93-118},
    doi = {10.1002/aris.2008.1440420110},
    url = {https://doi.org/10.1002/aris.2008.1440420110},
    eprint = {https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/aris.2008.1440420110},
    year = {2008}
}


@techreport{mcfarlane_interruption_1997,
	address = {Fort Belvoir, VA},
	title = {Interruption of {People} in {Human}-{Computer} {Interaction}: {A} {General} {Unifying} {Definition} of {Human} {Interruption} and {Taxonomy}:},
	shorttitle = {Interruption of {People} in {Human}-{Computer} {Interaction}},
	url = {https://doi.org/10.21236/ADA333587},
	language = {en},
	institution = {Defense Technical Information Center},
	author = {McFarlane, Daniel C.},
	month = dec,
	year = {1997},
	doi = {10.21236/ADA333587},
}


@article{mcfarlane_scope_2002,
	title = {The {Scope} and {Importance} of {Human} {Interruption} in {Human}-{Computer} {Interaction} {Design}},
	volume = {17},
	issn = {0737-0024, 1532-7051},
	url = {https://doi.org/10.1207/S15327051HCI1701_1},
	doi = {10.1207/S15327051HCI1701_1},
	language = {en},
	number = {1},
	journal = {Human–Computer Interaction},
	author = {McFarlane, Daniel C. and Latorella, Kara A.},
	month = mar,
	year = {2002},
	pages = {1--61},
}


@article{mcfarlane_comparison_2002,
	title = {Comparison of {Four} {Primary} {Methods} for {Coordinating} the {Interruption} of {People} in {Human}-{Computer} {Interaction}},
	volume = {17},
	issn = {0737-0024},
	url = {https://doi.org/10.1207/S15327051HCI1701_2},
	doi = {10.1207/S15327051HCI1701_2},
	abstract = {Interruptions can cause people to make mistakes or errors during human-computer interaction (HCI). Interruptions occur as an unavoidable side-effect of some important kinds of human computer-based activities, for example, (a) constantly monitor for unscheduled changes in information environments, (b) supervise background autonomous services, and (c) intermittently collaborate and communicate with other people. Fortunately, people have powerful innate cognitive abilities that they can potentially leverage to manage multiple concurrent activities if they have specific kinds of control and interaction support. There is great opportunity, therefore, for user-interface design to increase people's ability to successfully handle interruptions, and prevent expensive errors. The literature contains very little concrete design wisdom about how to solve the interruption problems in user interfaces (UIs). Coordination support, however, is identified as a most important design topic. This article presents the results of an empirical investigation to compare basic design solutions for coordinating human interruption in computer-based multitasks. A theory-based taxonomy of human interruption is used to identify the four primary methods for coordinating human interruption. An experiment with 36 participants compares these four different design solutions within an abstracted common user multitasking context. The results show important design tradeoffs for coordinating the interruption of people in HCI and support some UI design guidelines. Negotiation support is the best overall solution except where small differences in the timeliness of handling interruptions is critical and then immediate is best.},
	number = {1},
	journal = {Human–Computer Interaction},
	author = {McFarlane, Daniel C.},
	month = mar,
	year = {2002},
	pages = {63--139},
}


@article{addas_many_2015,
	title = {The many faces of information technology interruptions: a taxonomy and preliminary investigation of their performance effects: {Information} technology interruptions taxonomy and performance effects},
	volume = {25},
	issn = {13501917},
	shorttitle = {The many faces of information technology interruptions},
	url = {https://doi.org/10.1111/isj.12064},
	doi = {10.1111/isj.12064},
	abstract = {Despite the growing importance of information technology (IT) interruptions for individual work, very little is known about their nature and consequences. This paper develops a taxonomy that classiﬁes interruptions based on the relevance and structure of their content, and propositions that relate different interruption types to individual performance. A qualitative approach combining the use of log diaries of professional workers and semi-structured interviews with product development workers provide a preliminary validation of the taxonomy and propositions and allow for the discovery of a continuum of interruption events that fall in-between the extreme types in the taxonomy. The results show that some IT interruptions have positive effects on individual performance, whilst others have negative effects, or both. The taxonomy developed in the paper allows for a better understanding of the nature of different types of IT interruption and their consequences on individual work. By showing that different types of interruptions have different effects, the paper helps to explain and shed light on the inconsistent results of past research.},
	language = {en},
	number = {3},
	journal = {Information Systems Journal},
	author = {Addas, Shamel and Pinsonneault, Alain},
	month = may,
	year = {2015},
	pages = {231--273},
}


@inproceedings{horvitz_balancing_2005,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Balancing {Awareness} and {Interruption}: {Investigation} of {Notification} {Deferral} {Policies}},
	isbn = {978-3-540-31878-1},
	shorttitle = {Balancing {Awareness} and {Interruption}},
	doi = {10.1007/11527886_59},
        url = {https://doi.org/10.1007/11527886_59},
	abstract = {We review experiments with bounded deferral, a method aimed at reducing the disruptiveness of incoming messages and alerts in return for bounded delays in receiving information. Bounded deferral provides users with a means for balancing awareness about potentially urgent information with the cost of interruption.},
	language = {en},
	booktitle = {User {Modeling} 2005},
	publisher = {Springer},
	author = {Horvitz, Eric and Apacible, Johnson and Subramani, Muru},
	editor = {Ardissono, Liliana and Brna, Paul and Mitrovic, Antonija},
	year = {2005},
	keywords = {Busy State, Busy Time, Cost State, High Urgency, Incoming Message},
	pages = {433--437},
}


@article{paul_interruptive_2015,
	title = {Interruptive notifications in support of task management},
	volume = {79},
	issn = {10715819},
	url = {https://doi.org/10.1016/j.ijhcs.2015.02.001},
	doi = {10.1016/j.ijhcs.2015.02.001},
	abstract = {Our research explores how interruptive notiﬁcations support task management in a desktop environment. We conducted two user studies with a community of open source software users and developers to explore their experience with interruptive notiﬁcations. We found that certain kinds of notiﬁcations support multitasking, task prioritization, task management, as well as inﬂuence task disruption management. We discuss how these behaviors affect the notiﬁcation-task management user experience and offer design guidelines derived from these results to inform better design of systems that interrupt through notiﬁcation.},
	language = {en},
	journal = {International Journal of Human-Computer Studies},
	author = {Paul, Celeste Lyn and Komlodi, Anita and Lutters, Wayne},
	month = jul,
	year = {2015},
	pages = {20--34},
}


@misc{noauthor_push_2019,
	title = {Push {Notifications} {Statistics} (2021)},
	url = {https://www.businessofapps.com/research/push-notifications-statistics/},
	abstract = {Blackberry are credited with giving us the first instance of the push notification. This was as simple as a small notification that informed users when they had received an email. Over time the push notification has grown in both sophistication and ubiquity. The Blackberry was, as we know, targeted at business users. Apple’s iPhone brought the push notification into the mainstream – alongside the app. Google would follow when it entered the smartphone world. The modern push notification can include media, action buttons, and can be tailored to individual users. They can be used to convey information and updates, encourage users to engage with an app, send reminders, serve as a step in the user journey, and much more. They also extend beyond mobile devices,},
	language = {en},
	urldate = {2021-10-08},
	journal = {Business of Apps},
	author = {Business of Apps},
	month = oct,
	year = {2021},
}


@misc{statista_us_2021,
	title = {U.{S}. {Gen} {Z} social apps notifications 2021},
	url = {https://www.statista.com/statistics/1245420/us-notifications-to-social-app-ios-users/},
	abstract = {According to a 2021 study of social app usage of Gen Z iOS users in the United States, mobile users aged between 18 and 25 years old received an average of 165 notifications from Discord per week.},
	language = {en},
	urldate = {2021-10-08},
	journal = {Statista},
	author = {statista},
	year = {2021},
}


@misc{noauthor_desktop_2021,
	title = {Desktop vs {Mobile} vs {Tablet} {Market} {Share} {Worldwide}},
	url = {https://gs.statcounter.com/platform-market-share/desktop-mobile-tablet},
	abstract = {This graph shows the market share of desktop vs mobile vs tablet worldwide based on over 10 billion monthly page views.},
	language = {en},
	urldate = {2021-10-08},
	journal = {StatCounter Global Stats},
	month = oct,
	year = {2021},
}


@book{kalat_biological_2012,
	title = {Biological {Psychology}},
	isbn = {978-1-133-70973-2},
	abstract = {Dr. James W. Kalat's BIOLOGICAL PSYCHOLOGY is the most widely used text in the course area, and for good reason: an extremely high level of scholarship, clear and occasionally humorous writing style, and precise examples. Throughout all eleven editions, Kalat's goal has been to make biological psychology accessible to psychology students, not just to biology majors and pre-meds. Another goal has been to convey the excitement of the search for biological explanations of behavior, and Kalat delivers. Updated with new topics, examples, and recent research findings--and supported by new online bio-labs, part of the strongest media package yet--this text speaks to today's students and instructors.Important Notice: Media content referenced within the product description or the product text may not be available in the ebook version.},
	language = {en},
	publisher = {Cengage Learning},
	author = {Kalat, James W.},
	month = jan,
	year = {2012},
}

@book{goldstein_blackwell_2005,
	address = {Oxford, UK ; Malden, MA},
	series = {Blackwell handbooks of experimental psychology},
	title = {Blackwell handbook of sensation and perception},
	isbn = {978-0-631-20684-2},
	language = {en},
	number = {1},
	publisher = {Blackwell Pub},
	editor = {Goldstein, E. Bruce and Humphreys, Glyn W. and Shiffrar, Margaret and Yost, William A.},
	year = {2005},
	keywords = {Perception, Senses and sensation},
}

@book{goldstein_sensation_2016,
	address = {Boston, MA},
	edition = {10th edition},
	title = {Sensation and {Perception}},
	isbn = {978-1-305-58029-9},
	abstract = {This book tells the amazing story of perception -- how experiences are created by your senses and how you use these experiences to interact with the environment. You might be surprised to know that although perception is easy -- we see, hear, feel touch, and experience taste and smell without much effort -- the mechanisms that create perceptions are both extremely complex and hidden from our view. SENSATION AND PERCEPTION unravels these complexities by taking you on a journey that describes perceptual research in a clear easy-to-understand way, and by linking the results of this research to your everyday experience. The text is supported by beautiful color illustrations, a media program that makes perception come alive (in the MindTap digital learning solution), and learning aids to help you understand and remember what you have read.},
	language = {English},
	publisher = {Cengage Learning},
	author = {Goldstein, E. Bruce and Brockmole, James},
	month = feb,
	year = {2016},
}

@book{lindsay_human_2013,
	title = {Human {Information} {Processing}: {An} {Introduction} to {Psychology}},
	isbn = {978-0-12-450960-3},
	edition = {2d ed},
	shorttitle = {Human {Information} {Processing}},
	abstract = {Human Information Processing: An Introduction to Psychology aims to convey the excitement of modern experimental psychology to the beginning student. The book discusses the organization of auditory perceptions; neural information processing; and the theories of pattern recognition. The text also describes the visual system; the dimensions of vision; the auditory system; and the dimensions of sound. The neural basis of memory; transient memories; the structure of memory; and memory processes are also considered. The book further tackles language acquisition; the process of learning and cognitive development; problem solving; and decision making. The text also looks into motivation and the biochemical responses to stress. Psychologists and students taking psychology and related courses will find the book useful."},
	language = {English},
	publisher = {Academic Press},
	author = {Lindsay, Peter H. and Norman, Donald A.},
	month = sep,
	year = {2013},
	keywords = {Communication, Human information processing, Perception, Psycholinguistics},
}



@incollection{stokes_dominance_2015,
	address = {New York, NY, US},
	title = {The dominance of the visual},
	isbn = {978-0-19-983281-1},
        url = {https://doi.org/10.1093/acprof:oso/9780199832798.003.0015},
	abstract = {In this chapter, we first identify three levels at which a sense can be dominant, the levels of experience, experience-based judgment, and all-things-considered judgment (section 2). Then, taking touch as our test case, we argue that vision exercises two kinds of dominance, perception-perception dominance, in which visual perception affects how we interpret nonvisual stimuli (section 3), and imagery-perception dominance, in which visual imagery affects how we interpret nonvisual stimuli (section 4). We then consider why vision exercises these kinds of dominance over touch (section 5), and how this makes vision both psychologically and epistemically special (section 6). This allows speculation about the conditions in which vision dominates touch (section 7). We close with a rough generalization to the relation between vision and other senses (section 8). To be clear we don't aim to legitimize vision-centrism in perception-studies. We aim, instead, to identify (some) relations among the senses that partly explain extant vision-centrism. In fact, our line of thought has the implication that modalities should be analyzed differently, given important phenomenological and informational aspects of vision by contrast with nonvisual modalities. By this same token, a methodological prescription of our analysis is that we should avoid an overcorrection in which perception studies would treat vision as just another sense. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
	booktitle = {Perception and its modalities},
	publisher = {Oxford University Press},
	author = {Stokes, Dustin and Biggs, Stephen},
	year = {2015},
	keywords = {Dominance, Imagery, Sensory Integration, Tactual Perception, Visual Perception},
	pages = {350--378},
}



@techreport{alvarado_sensation_2011,
	title = {Sensation and {Perception}: {A} {Unit} {Lesson} {Plan} for {High} {School} {Psychology} {Teachers}: (545242012-001)},
	shorttitle = {Sensation and {Perception}},
	url = {https://doi.org/10.1037/e545242012-001},
	language = {en},
	institution = {American Psychological Association},
	author = {Alvarado, Sandra and Kanter-Braem, Bonnie and Manz, Kathleen and Masciopinto, Peter and McKenna, Eileen and Nelson, Dana and Williams, Christopher and Korek, Kent and Wozniak, William},
	year = {2011},	
	doi = {10.1037/e545242012-001},
}

@book{kahneman1973attention,
  title={Attention and effort},
  author={Kahneman, Daniel},
  volume={1063},
  year={1973},
  publisher={Citeseer}
}

@incollection{wickens_processing_1991,
	title = {Processing resources and attention},
	isbn = {978-1-00-306944-7},
	abstract = {This chapter explains the resource concept in single-task performance. The resource concept is founded on the underlying assumption that the human operator has a limited capacity for processing resources that may be allocated to task performance. Two tasks demand more resources than one; therefore, timesharing can lead to a situation in which one or both have fewer resources than required, and hence, performance on one or both may deteriorate. The foundation for the resources concept in dual-task performance may be found in the early theoretical work of Broadbent (1958) and Kahneman (1973). The concept of resources in dual-task performance is most applicable and important in understanding and describing the effect of task difficulty. Different tasks are characterized by the dichotomy between stage-defined and code-defined resources. The enhancement of dual-task performance seems to result from circumstances in which a common mental set, processing routine, or timing mechanism can be activated in service of the two tasks.},
	booktitle = {Multiple-task performance},
	publisher = {CRC Press},
	author = {Wickens, Christopher D.},
	year = {1991},
}


@inproceedings{oulasvirta_interaction_2005,
	address = {Portland, Oregon, USA},
	title = {Interaction in 4-second bursts: the fragmented nature of attentional resources in mobile {HCI}},
	isbn = {978-1-58113-998-3},
	shorttitle = {Interaction in 4-second bursts},
	url = {https://doi.org/10.1145/1054972.1055101},
	doi = {10.1145/1054972.1055101},
	abstract = {When on the move, cognitive resources are reserved partly for passively monitoring and reacting to contexts and events, and partly for actively constructing them. The Resource Competition Framework (RCF), building on the Multiple Resources Theory, explains how psychosocial tasks typical of mobile situations compete for cognitive resources and then suggests that this leads to the depletion of resources for task interaction and eventually results in the breakdown of fluent interaction. RCF predictions were tested in a semi-naturalistic field study measuring attention during the performance of assigned Web search tasks on mobile phone while moving through nine varied but typical urban situations. Notably, we discovered up to eight-fold differentials between micro-level measurements of attentional resource fragmentation, for example from spans of over 16 seconds in a laboratory condition dropping to bursts of just a few seconds in difficult mobile situations. By calibrating perceptual sampling, reducing resources from tasks of secondary importance, and resisting the impulse to switch tasks before finalization, participants compensated for the resource depletion. The findings are compared to previous studies in office contexts. The work is valuable in many areas of HCI dealing with mobility.},
	language = {en},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems  - {CHI} '05},
	publisher = {ACM Press},
	author = {Oulasvirta, Antti and Tamminen, Sakari and Roto, Virpi and Kuorelahti, Jaana},
	year = {2005},
}

@incollection{wobbrock_situationally_2019,
	address = {London},
	title = {Situationally-{Induced} {Impairments} and {Disabilities}},
	isbn = {978-1-4471-7440-0},
	url = {https://doi.org/10.1007/978-1-4471-7440-0_5},
	abstract = {This chapter presents an overview of situationally-induced impairments and disabilities, or SIIDs, which are caused by situations, contexts, or environments that negatively affect the abilities of people interacting with technology, especially when they are on-the-go. Although the lived experience of SIIDs is, of course, unlike that of health-induced impairments and disabilities, both can be approached from an accessibility point-of-view, as both beneﬁt from improving access and use in view of constraints on ability. This chapter motivates the need for the conception of SIIDs, relates the history of this conception, and places SIIDs within a larger framework of Wobbrock et al.’s ability-based design (ACM Trans Access Comput 3(3), 2011, Commun ACM 61(6):62\-71, 2018). Various SIIDs are named, categorized, and linked to prior research that investigates them. They are also illustrated with examples in a space deﬁned by two dimensions, location and duration, which describe the source of the impairing forces and the length of those forces’ persistence, respectively. Results from empirical studies are offered, which show how situational factors affect technology use and to what extent. Finally, speciﬁc projects undertaken by this chapter’s author and his collaborators show how some situational factors can be addressed in interactive computing through advanced sensing, modeling, and adapting to users and situations. As interactive computing continues to move beyond the desktop and into the larger dynamic world, SIIDs will continue to affect all users, with implications for human attention, action, autonomy, and safety.},
	language = {en},
	booktitle = {Web {Accessibility}},
	publisher = {Springer London},
	author = {Wobbrock, Jacob O.},
	editor = {Yesilada, Yeliz and Harper, Simon},
	year = {2019},
	doi = {10.1007/978-1-4471-7440-0_5},
	pages = {59--92}
}

@article{paridon2010multitasking, 
    title={Multitasking in work-related situations and its relevance for occupational health and safety: Effects on performance, subjective strain and physiological parameters}, 
    volume={6},
    url={https://doi.org/10.5964/ejop.v6i4.226}, 
    DOI={10.5964/ejop.v6i4.226},
    abstractNote={In the area of occupational health and safety multitasking becomes more and more important. Studies have shown that multitasking leads to a decrease in performance. However, studies often try to identify underlying mental mechanisms. Multitasking and its consequences for occupational health and safety are rarely considered. In this study, the effects of multitasking were investigated using two work-related scenarios. Changes were assessed in relation to three areas: performance values, subjective strain and physiological parameters. Data was also analyzed with respect to possible gender and age differences. Due to a focus on people of working age, the participants were aged between 21 and 60 years old. Multitasking led to reduced performance and increased levels of subjective strain. Changes in physiological parameters appear to be dependent on the type of task. There were no gender and virtually no age differences regarding the single-task compared to the multitasking condition. Overall, the data suggests that multitasking in the workplace should be minimized, at least for certain tasks, in order to prevent mistakes and potential accidents as well as mental strain. Further research should be carried out to investigate the long-term effects of multitasking on performance and health.}, 
    number={4}, 
    journal={Europe’s Journal of Psychology},
    author={Paridon, Hiltraut M. and Kaufmann, Marlen},
    year={2010}, 
    month=nov, 
    pages={110-124} 
}


@book{wickens_attention_2013,
	title = {Attention},
	url = {https://doi.org/10.1093/oxfordhb/9780199757183.013.0003},
	language = {en},
	publisher = {Oxford University Press},
	author = {Wickens, Christopher D.},
	month = feb,
	year = {2013},
	doi = {10.1093/oxfordhb/9780199757183.013.0003},
}


@misc{apa_attention_2021,
	title = {attention – {APA} {Dictionary} of {Psychology}},
	url = {https://dictionary.apa.org/attention},
	abstract = {attention n. a state in which cognitive resources are focused on certain aspects of the environment rather than on others and the central nervous system is in a state of readiness to respond to stimuli. Because it has been presumed that human beings do not have an infinite capacity to attend to everything—focusing on certain items at the expense of others—much of the research in this field has been devoted to discerning which factors influence attention and to understanding the neural mechanisms that are involved in the selective processing of information. For example, past experience affects perceptual experience (we notice things that have meaning for us), and some activities (e.g., reading) require conscious participation (i.e., voluntary attention). However, attention can also be captured (i.e., directed involuntarily) by qualities of stimuli in the environment, such as intensity, movement, repetition, contrast, and novelty. See also divided attention; effortless attention; focal attention; involuntary attention; postvoluntary attention; primary attention; secondary attention; selective attention; spatial attention; visual attention.},
	language = {en},
	urldate = {2021-10-16},
	author = {APA},
	year = {2021},
}


@article{rauschnabel_augmented_2015,
	title = {Augmented {Reality} {Smart} {Glasses}: {Definition}, {Conceptual} {Insights}, and {Managerial} {Importance}},
	abstract = {During the last years, the developments of new media have revolutionized individuals’ behavior tremendously. Particularly mobile devices have developed an ‘always and everywhere online’ mentality. But what comes next? Recent developments and forecasts propose the rise of a new technology that is termed ‘Wearable Augmented Reality Devices”, where smart glasses (such as Microsoft Hololens or Google Glass) represent prominent examples. These technologies offer much potential for companies and societies, which are discussed in this article. By doing so, this paper provides managers and researchers an applied description of the technology and a discussion of how it differs from existing mobile and augmented reality technologies. Finally, a discussion of how smart glasses can increase firm value is provided.},
	language = {en},
	journal = {Unpublished Working Paper, The University of Michigan-Dearborn, College of Business},
	author = {Rauschnabel, Philipp A and Brem, Alexander and Ro, Young K},
	year = {2015},
	pages = {22},
}


@incollection{norman_psychological_1986,
	edition = {0},
	title = {Psychological {Issues} in {Support} of {Multiple} {Activities}},
	isbn = {978-0-367-80732-0},
	url = {https://doi.org/10.1201/b15703-13},
	language = {en},
	booktitle = {User {Centered} {System} {Design}},
	publisher = {CRC Press},
	author = {Miyata, Yoshiro and Norman, Donald A.},
	editor = {Norman, Donald A. and Draper, Stephen W.},
	month = jan,
	year = {1986},
	doi = {10.1201/b15703-13},
	pages = {265--284},
}



@article{bailey_need_2006,
	title = {On the need for attention-aware systems: {Measuring} effects of interruption on task performance, error rate, and affective state},
	volume = {22},
	issn = {07475632},
	shorttitle = {On the need for attention-aware systems},
	url = {https://doi.org/10.1016/j.chb.2005.12.009},
	doi = {10.1016/j.chb.2005.12.009},
	abstract = {This paper reports results from a controlled experiment (N = 50) measuring eﬀects of interruption on task completion time, error rate, annoyance, and anxiety. The experiment used a sample of primary and peripheral tasks representative of those often performed by users. Our experiment diﬀers from prior interruption experiments because it measures eﬀects of interrupting a user’s tasks along both performance and aﬀective dimensions and controls for task workload by manipulating only the time at which peripheral tasks were displayed – between vs. during the execution of primary tasks. Results show that when peripheral tasks interrupt the execution of primary tasks, users require from 3\% to 27\% more time to complete the tasks, commit twice the number of errors across tasks, experience from 31\% to 106\% more annoyance, and experience twice the increase in anxiety than when those same peripheral tasks are presented at the boundary between primary tasks. An important implication of our work is that attention-aware systems could mitigate eﬀects of interruption by deferring presentation of peripheral information until coarse boundaries are reached during task execution. As our results show, deferring presentation for a short time, i.e. just a few seconds, can lead to a large mitigation of disruption.},
	language = {en},
	number = {4},
	journal = {Computers in Human Behavior},
	author = {Bailey, Brian P. and Konstan, Joseph A.},
	month = jul,
	year = {2006},
	pages = {685--708},
}


@inproceedings{pielot_didnt_2014,
	address = {New York, NY, USA},
	series = {{CHI} '14},
	title = {Didn't you see my message? predicting attentiveness to mobile instant messages},
	isbn = {978-1-4503-2473-1},
	shorttitle = {Didn't you see my message?},
	url = {https://doi.org/10.1145/2556288.2556973},
	doi = {10.1145/2556288.2556973},
	abstract = {Mobile instant messaging (e.g., via SMS or WhatsApp) often goes along with an expectation of high attentiveness, i.e., that the receiver will notice and read the message within a few minutes. Hence, existing instant messaging services for mobile phones share indicators of availability, such as the last time the user has been online. However, in this paper we not only provide evidence that these cues create social pressure, but that they are also weak predictors of attentiveness. As remedy, we propose to share a machine-computed prediction of whether the user will view a message within the next few minutes or not. For two weeks, we collected behavioral data from 24 users of mobile instant messaging services. By the means of machine-learning techniques, we identified that simple features extracted from the phone, such as the user's interaction with the notification center, the screen activity, the proximity sensor, and the ringer mode, are strong predictors of how quickly the user will attend to the messages. With seven automatically selected features our model predicts whether a phone user will view a message within a few minutes with 70.6\% accuracy and a precision for fast attendance of 81.2\%},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Pielot, Martin and de Oliveira, Rodrigo and Kwak, Haewoon and Oliver, Nuria},
	month = apr,
	year = {2014},
	keywords = {asynchronous communication, attentiveness, availability, messaging, mobile devices, prediction},
	pages = {3319--3328},
}


@inproceedings{dey_getting_2011,
	address = {New York, NY, USA},
	series = {{UbiComp} '11},
	title = {Getting closer: an empirical investigation of the proximity of user to their smart phones},
	isbn = {978-1-4503-0630-0},
	shorttitle = {Getting closer},
	url = {https://doi.org/10.1145/2030112.2030135},
	doi = {10.1145/2030112.2030135},
	abstract = {Much research in ubiquitous computing assumes that a user's phone will be always on and at-hand, for collecting user context and for communicating with a user. Previous work with the previous generation of mobile phones has shown that such an assumption is false. Here, we investigate whether this assumption about users' proximity to their mobile phones holds for a new generation of mobile phones, smart phones. We conduct a data collection field study of 28 smart phone owners over a period of 4 weeks. We show that in fact this assumption is still false, with the within arm's reach proximity being true close to 50\% of the time, similar to the earlier work. However, we also show that smart phone proximity within the same room (arm+room) as the user is true almost 90\% of the time. We discuss the reasons for these phone proximities and the implications of this on the development of mobile phone applications, particularly those that collect user and environmental context, and delivering notification to users. We also show that we can accurately predict the proximity at the arm level and arm+room level with 75 and 83\% accuracy, respectively, with features simple to collect and model on a mobile phone. Further we show that for several individuals who are almost always within the arm+room level, we can predict this level with over 90\% accuracy.},
	booktitle = {Proceedings of the 13th international conference on {Ubiquitous} computing},
	publisher = {Association for Computing Machinery},
	author = {Dey, Anind K. and Wac, Katarzyna and Ferreira, Denzil and Tassini, Kevin and Hong, Jin-Hyuk and Ramos, Julian},
	month = sep,
	year = {2011},
	keywords = {mobile devices, mobility, proximity, smart phone},
	pages = {163--172},
}


@inproceedings{mehrotra_designing_2015,
	address = {Osaka, Japan},
	title = {Designing content-driven intelligent notification mechanisms for mobile applications},
	isbn = {978-1-4503-3574-4},
	url = {https://doi.org/10.1145/2750858.2807544},
	doi = {10.1145/2750858.2807544},
	abstract = {An increasing number of notiﬁcations demanding the smartphone user’s attention, often arrive at an inappropriate moment, or carry irrelevant content. In this paper we present a study of mobile user interruptibility with respect to notiﬁcation content, its sender, and the context in which a notiﬁcation is received. In a real-world study we collect around 70,000 instances of notiﬁcations from 35 users. We group notiﬁcations according to the applications that initiated them, and the social relationship between the sender and the receiver. Then, by considering both content and context information, such as the current activity of a user, we discuss the design of classiﬁers for learning the most opportune moment for the delivery of a notiﬁcation carrying a speciﬁc type of information. Our results show that such classiﬁers lead to a more accurate prediction of users’ interruptibility than an alternative approach based on user-deﬁned rules of their own interruptibility.},
	language = {en},
	booktitle = {Proceedings of the 2015 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} - {UbiComp} '15},
	publisher = {ACM Press},
	author = {Mehrotra, Abhinav and Musolesi, Mirco and Hendley, Robert and Pejovic, Veljko},
	year = {2015},
	pages = {813--824},
}


@article{anderson_survey_2018,
	title = {A {Survey} of {Attention} {Management} {Systems} in {Ubiquitous} {Computing} {Environments}},
	volume = {2},
	issn = {2474-9567, 2474-9567},
	url = {https://doi.org/10.1145/3214261},
	doi = {10.1145/3214261},
	language = {en},
	number = {2},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Anderson, Christoph and Hübener, Isabel and Seipp, Ann-Kathrin and Ohly, Sandra and David, Klaus and Pejovic, Veljko},
	month = jul,
	year = {2018},
	pages = {1--27},
}


@article{latorella_effects_1998,
	title = {Effects of {Modality} on {Interrupted} {Flight} {Deck} {Performance}: {Implications} for {Data} {Link}},
	volume = {42},
	issn = {2169-5067},
	shorttitle = {Effects of {Modality} on {Interrupted} {Flight} {Deck} {Performance}},
	url = {https://doi.org/10.1177/154193129804200120},
	doi = {10.1177/154193129804200120},
	abstract = {Externally-imposed tasks frequently interrupt ongoing task performance in the commercial flight deck. While normally managed without consequence, basic research as well as aviation accident and incident investigations show that interruptions can negatively affect performance and safety. This research investigates the influence of interruption and interrupted task modality on pilot performance in a simulated commercial flight deck. Fourteen current commercial airline pilots performed approach scenarios in a fixed-base flight simulator. Air traffic control instructions, conveyed either aurally or visually (via a data link system) interrupted a visual task (obtaining information from the Flight Management System) and an auditory task (listening to the automated terminal information service recording). Some results confirm the hypothesized performance advantage of cross-modality conditions, more compelling nature of auditory interruptions, and interruption-resistance of auditory ongoing tasks. However, taken together, results suggest the four interaction conditions had different effects on pilot performance. These results have implications for the design of data link systems, and for facilitating interruption management through interface design, aiding, and training programs.},
	language = {en},
	number = {1},
	journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
	author = {Latorella, Kara A.},
	month = oct,
	year = {1998},
	pages = {87--91},
}


@incollection{stephanidis_properties_2015,
	address = {Cham},
	title = {Properties of a {Peripheral} {Head}-{Mounted} {Display} ({PHMD})},
	volume = {528},
	isbn = {978-3-319-21380-4},
	url = {https://doi.org/10.1007/978-3-319-21380-4_37},
	abstract = {In this paper we propose a definition for Peripheral Head-Mounted Display (PHMD) for Near Field Displays. This paper introduces a taxonomy for head-mounted displays that is based on the property of its functionality and the ability of our human eye to perceive peripheral information, instead of being technology-dependent. The aim of this paper is to help designers to understand the perception of the human eye, as well as to discuss the factors one needs to take into consideration when designing visual interfaces for PHMDs. We envision this term to help classifying devices such as Google Glass, which are often misclassified as a Head-Up Display (HUD) following NASA’s definition.},
	language = {en},
	booktitle = {{HCI} {International} 2015 - {Posters}’ {Extended} {Abstracts}},
	publisher = {Springer International Publishing},
	author = {Matthies, Denys J. C. and Haescher, Marian and Alm, Rebekka and Urban, Bodo},
	editor = {Stephanidis, Constantine},
	year = {2015},
	doi = {10.1007/978-3-319-21380-4_37},
	pages = {208--213},
}


@article{polonen_near_eye_2009,
	title = {Near-to-{Eye} {Display}—{An} {Accessory} for {Handheld} {Multimedia} {Devices}: {Subjective} {Studies}},
	volume = {5},
	issn = {1551-319X},
	shorttitle = {Near-to-{Eye} {Display}—{An} {Accessory} for {Handheld} {Multimedia} {Devices}},
	url = {https://doi.org/10.1109/JDT.2009.2025056},
	doi = {10.1109/JDT.2009.2025056},
	abstract = {Fifty-eight people used a mobile phone/near-to-eye display combination with three different applications: movie viewing, game playing, and reading. After a 40-min immersion period participants completed several questionnaires related to the usage experience, comfort, workload, and individual features. We found many differences in user experiences between tasks as well as a number of associations between individual factors and experiences reported. Participants’ opinions on the near-to-eye display/mobile phone combination were generally positive, and several beneﬁts were reported: namely, a more engrossing experience and longer use time in the future. We also compared experiences from mobile phone/near-to-eye display setups to mobile phone and TV usage.},
	language = {en},
	number = {9},
	journal = {Journal of Display Technology},
	author = {Polonen, Monika and Hakkinen, Jukka},
	month = sep,
	year = {2009},
	pages = {358--367},
}


@inproceedings{zhou_ubiquitous_2019,
	address = {London, United Kingdom},
	title = {Ubiquitous smart eyewear interactions using implicit sensing and unobtrusive information output},
	isbn = {978-1-4503-6869-8},
	url = {https://doi.org/10.1145/3341162.3348392},
	doi = {10.1145/3341162.3348392},
	abstract = {Premature technology, privacy, intrusiveness, power consumption, and user habits are all factors potentially contributing to the lack of social acceptance of smart glasses. After investigating the recent development of commercial smart eyewear and its related research, we propose a design space for ubiquitous smart eyewear interactions while maximising interactivity with minimal obtrusiveness. We focus on implicit and explicit interactions enabled by the combination of miniature sensor technology, low-resolution display and simplistic interaction modalities. Additionally, we are presenting example applications outlining future development directions. Finally, we aim at raising the awareness of designing for ubiquitous eyewear with implicit sensing and unobtrusive information output abilities.},
	language = {en},
	booktitle = {Proceedings of the 2019 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} and {Proceedings} of the 2019 {ACM} {International} {Symposium} on {Wearable} {Computers}  - {UbiComp}/{ISWC} '19},
	publisher = {ACM Press},
	author = {Zhou, Qiushi and Newn, Joshua and Tag, Benjamin and Lee, Hao-Ping and Wang, Chaofan and Velloso, Eduardo},
	year = {2019},
	pages = {661--666},
}


@article{vadas_reading_2006,
	title = {Reading on the {Go}: {An} {Evaluation} of {Three} {Mobile} {Display} {Technologies}},
	abstract = {As mobile technology becomes a more integral part of our everyday lives, understanding the impact of different displays on perceived ease of use and overall performance is becoming increasingly important. In this paper, we evaluate three mobile displays: the MicroOptical SV-3, the Sony Librie´, and the OQO Model 01. These displays each use different underlying technologies and offer unique features which could impact mobile use. The OQO is a hand-held device that utilizes a traditional transﬂective liquid crystal display (LCD). The MicroOptical SV-3 is a head-mounted display that uses a miniature LCD and offers hands free use. Finally, the Librie´ uses a novel, low power reﬂective electronic ink technology. We present a controlled 15-participant evaluation to assess the effectiveness of using these displays for reading while in motion.},
	language = {en},
    url = {http://hdl.handle.net/1853/13112},
	author = {Vadas, Kristin and Lyons, Kent and Ashbrook, Daniel and Yi, Ji Soo and Starner, Thad and Jacko, Julie},
	year = {2006},
	pages = {16},
}


@article{yeh_head_2003,
	title = {Head {Up} versus {Head} {Down}: {The} {Costs} of {Imprecision}, {Unreliability}, and {Visual} {Clutter} on {Cue} {Effectiveness} for {Display} {Signaling}},
	volume = {45},
	issn = {0018-7208, 1547-8181},
	shorttitle = {Head {Up} versus {Head} {Down}},
	url = {https://doi.org/10.1518/hfes.45.3.390.27249},
	doi = {10.1518/hfes.45.3.390.27249},
	abstract = {We conducted 2 experiments to investigate the clutter-scan trade-off between the cost of increasing clutter by overlaying complex information onto the forward field of view using a helmet-mounted display (HMD) and the cost of scanning when presenting this information on a handheld display. In the first experiment, this tradeoff was examined in terms of the spatial accuracy of target cuing data in a relatively sparse display; in the second, the spatial accuracy of the cue was varied more radically in an information-rich display. Participants were asked to detect and identify targets hidden in the far domain while performing a monitoring task in the near domain using either an HMD or a handheld display. The results revealed that on a sparse display, the reduced scanning from the HMD presentation of cuing outweighed the costs of clutter for cued targets, regardless of cue precision, but no benefit was found for uncued targets. When the HMD displayed task-irrelevant information, however, target detection was hindered by the extraneous clutter in the forward field of view relative to the handheld display condition, and this cost of clutter increased as the amount of data that needed to be inspected increased. Potential applications of this research include the development of design considerations for head-up displays for aviation and military applications.},
	language = {en},
	number = {3},
	journal = {Human Factors: The Journal of the Human Factors and Ergonomics Society},
	author = {Yeh, Michelle and Merlo, James L. and Wickens, Christopher D. and Brandenburg, David L.},
	month = sep,
	year = {2003},
	pages = {390--407},
}

@inproceedings{bipat_analyzing_2019,
	address = {Glasgow, Scotland Uk},
	title = {Analyzing the {Use} of {Camera} {Glasses} in the {Wild}},
	isbn = {978-1-4503-5970-2},
	url = {https://doi.org/10.1145/3290605.3300651},
	doi = {10.1145/3290605.3300651},
	abstract = {Camera glasses enable people to capture point-of-view videos using a common accessory, hands-free. In this paper, we investigate how, when, and why people used one such product: Spectacles. We conducted 39 semi-structured interviews and surveys with 191 owners of Spectacles. We found that the form factor elicits sustained usage behaviors, and opens opportunities for new use-cases and types of content captured. We provide a usage typology, and highlight societal and individual factors that influence the classification of behaviors.},
	language = {en},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '19},
	publisher = {ACM Press},
	author = {Bipat, Taryn and Bos, Maarten Willem and Vaish, Rajan and Monroy-Hernández, Andrés},
	year = {2019},
	pages = {1--8},
}

@inproceedings{dingler_language_2017,
	location = {Vienna, Austria},
	title = {Language learning on-the-go: opportune moments and design of mobile microlearning sessions},
	isbn = {978-1-4503-5075-4},
	url = {https://doi.org/10.1145/3098279.3098565},
	doi = {10.1145/3098279.3098565},
	shorttitle = {Language learning on-the-go},
	eventtitle = {the 19th International Conference},
	pages = {1--12},
	booktitle = {Proceedings of the 19th International Conference on Human-Computer Interaction with Mobile Devices and Services  - {MobileHCI} '17},
	publisher = {{ACM} Press},
	author = {Dingler, Tilman and Weber, Dominik and Pielot, Martin and Cooper, Jennifer and Chang, Chung-Cheng and Henze, Niels},
	date = {2017},
	year={2017},
	langid = {english}
}

@article{cai_waitsuite_2017,
	title = {{WaitSuite}: {Productive} {Use} of {Diverse} {Waiting} {Moments}},
	volume = {24},
	issn = {1073-0516},
	shorttitle = {{WaitSuite}},
	url = {https://doi.org/10.1145/3044534},
	doi = {10.1145/3044534},
	abstract = {The busyness of daily life makes it difficult to find time for informal learning. Yet, learning requires significant time and effort, with repeated exposures to educational content on a recurring basis. Despite the struggle to find time, there are numerous moments in a day that are typically wasted due to waiting, such as while waiting for the elevator to arrive, wifi to connect, or an instant message to arrive. We introduce the concept of wait-learning: automatically detecting wait time and inviting people to learn while waiting. Our approach is to design seamless interactions that augment existing wait time with productive opportunities. Combining wait time with productive work opens up a new class of software systems that overcome the problem of limited time. In this article, we establish a design space for wait-learning and explore this design space by creating WaitSuite, a suite of five different wait-learning apps that each uses a different kind of waiting. For one of these apps, we conducted a feasibility study to evaluate learning and to understand how exercises should be timed during waiting periods. Subsequently, we evaluated multiple kinds of wait-learning in a two-week field study of WaitSuite with 25 people. We present design implications for wait-learning, and a theoretical framework that describes how wait time, ease of accessing the learning task, and competing demands impact the effectiveness of wait-learning in different waiting scenarios. These findings provide insight into how wait-learning can be designed to minimize interruption to ongoing tasks and maximize engagement with learning.},
	number = {1},
	journal = {ACM Transactions on Computer-Human Interaction},
	author = {Cai, Carrie J. and Ren, Anji and Miller, Robert C.},
	month = mar,
	year = {2017},
	keywords = {attention management, Micro-learning, microtasks, productivity, wait-learning},
	pages = {7:1--7:41},
}

@incollection{hutchison_context_sensitive_2007,
	address = {Berlin, Heidelberg},
	title = {Context-{Sensitive} {Microlearning} of {Foreign} {Language} {Vocabulary} on a {Mobile} {Device}},
	volume = {4794},
	isbn = {978-3-540-76651-3 978-3-540-76652-0},
	url = {https://doi.org/10.1007/978-3-540-76652-0_4},
	language = {en},
	booktitle = {Ambient {Intelligence}},
	publisher = {Springer Berlin Heidelberg},
	author = {Beaudin, Jennifer S. and Intille, Stephen S. and Munguia Tapia, Emmanuel and Rockinson, Randy and Morris, Margaret E.},
	year = {2007},
	doi = {10.1007/978-3-540-76652-0_4},
	pages = {55--72},
}


@article{isaacs_mobile_2009,
	title = {Mobile {Microwaiting} {Moments}: {The} {Role} of {Context} in {Receptivity} to {Content} {While} on the {Go}},
	language = {en},
	journal = {PARC white paper},
	author = {Isaacs, Ellen and Yee, Nicholas and Schiano, Diane J and Good, Nathan and Ducheneaut, Nicolas and Bellotti, Victoria},
	year = {2009},
	pages = {10},
}


@article{bell_view_2001,
	title = {View {Management} for {Virtual} and {Augmented} {Reality}},
	abstract = {We describe a view-management component for interactive 3D user interfaces. By view management, we mean maintaining visual constraints on the projections of objects on the view plane, such as locating related objects near each other, or preventing objects from occluding each other. Our view-management component accomplishes this by modifying selected object properties, including position, size, and transparency, which are tagged to indicate their constraints. For example, some objects may have geometric properties that are determined entirely by a physical simulation and which cannot be modified, while other objects may be annotations whose position and size are flexible.},
	language = {en},
	author = {Bell, Blaine and Feiner, Steven and Höllerer, Tobias},
    url = {https://doi.org/10.1145/502348.502363},
	year = {2001},
	pages = {10},
}

@inproceedings{kohei_tanaka_information_2008,
	address = {Cambridge, UK},
	title = {An information layout method for an optical see-through head mounted display focusing on the viewability},
	isbn = {978-1-4244-2840-3},
	url = {https://doi.org/10.1109/ISMAR.2008.4637340},
	doi = {10.1109/ISMAR.2008.4637340},
	abstract = {Accessing information when we are on the move is a key feature if mobile computing environments, and using an optical see-through head mounted display (HMD) is one of the most suitable ways to do this. Although the HMD can display information without interfering with the user’s view, when the sight behind the display is too complex or too bright, the information displayed can bee very difﬁcult to see. To solve this problem, we have created a way of laying out information for the optical see-through HMD. The ideal area for displaying information is determined by evaluating the sight image behind the HMD captured by a pantoscopic camera mounted on it. Moreover, if there is no suitable area for displaying information, our method select involves using the sight image around users use to the ideal direction and instructing them to face the direction. Our method displays information to ideal areas.},
	language = {en},
	booktitle = {2008 7th {IEEE}/{ACM} {International} {Symposium} on {Mixed} and {Augmented} {Reality}},
	publisher = {IEEE},
	author = {{Kohei Tanaka} and {Yasue Kishino} and {Masakazu Miyamae} and {Tsutomu Terada} and {Shojiro Nishio}},
	month = sep,
	year = {2008},
	pages = {139--142},
}


@article{azuma_road_2019,
	title = {The road to ubiquitous consumer augmented reality systems},
	volume = {1},
	issn = {2578-1863},
	url = {https://doi.org/10.1002/hbe2.113},
	doi = {10.1002/hbe2.113},
	abstract = {The tremendous rise of interest and hype in augmented reality ({AR}) is justified by its long-term potential as the technology with the best chance to supplant smartphones, by becoming the dominant platform and interface for accessing digital information. However, we are still far from achieving an ideal {AR} system that is ubiquitously accepted by consumers and reaches this potential. This paper focuses on the two fastest paths leading to ubiquitous consumer {AR} systems: (a) offshoots of enterprise {AR} systems, and (b) systems that initially target niche consumer {AR} usages and subsequently expand in capabilities. To justify these two paths, this paper describes some history of {AR}, recent changes due to new developments, and specific obstacles and challenges. Not all challenges are technical. Social acceptance and usages are also crucial. This paper identifies specific characteristics, approaches, and strategies that are most likely to succeed, and compares these to the characteristics and development of previous successful consumer technologies, including smartphones and devices that improve human eyesight in specific situations.},
	pages = {26--32},
	number = {1},
	journaltitle = {Human Behavior and Emerging Technologies},
	author = {Azuma, Ronald T.},
	date = {2019},
	langid = {english},
	keywords = {augmented reality, social acceptance, optical see-through, mixed reality, immersive experiences, usages},
}



@misc{chia_smart_2019,
	title = {Smart glasses are back: {What}’s new this time?},
	shorttitle = {Smart glasses are back},
	url = {https://www.slashgear.com/smart-glasses-are-back-whats-new-this-time-06594307/},
	abstract = {Smart glasses have been on adverts, movies and the news for decades now. From Google Glass way back in 2012, to Peter Parker’s EDITH spectacles, we’ve seen why there’s certainly a place for tech li…},
	language = {en-US},
	urldate = {2019-10-08},
	journal = {SlashGear},
	author = {Chia, Osmond},
	year = {2019},
}

@misc{conditt_worlds_2018,
	title = {Worlds collide: {VR} and {AR} in 2018 {\textbar} {Engadget}},
	url = {https://www.engadget.com/2017-12-20-vr-and-ar-in-2018.html},
	urldate = {2022-02-20},
	journal = {engadget},
	author = {Conditt, Jess},
	year = {2018},
}


@inproceedings{farve_user_2016,
	address = {Santa Clara, California, USA},
	title = {User {Attention} with {Head}-{Worn} {Displays}},
	isbn = {978-1-4503-4082-3},
	url = {https://doi.org/10.1145/2851581.2892530},
	doi = {10.1145/2851581.2892530},
	abstract = {Recently there has been a surge of interest in wearable devices both in industry and academia. This includes the introduction of head-worn devices into everyday life. Head-worn devices have the advantage of containing a screen that is easily seen by the wearer at all times, in contrast with other device screens, which can be hidden in pockets or simply easily ignored. However, during certain activities it can be difficult to get the wearer to notice messages even when presented through head-worn devices. For certain applications, it may be important that the user does not miss a particular notification or warning. Not much is known about which methods work best to attract the users' attention in such situations. We describe results from two user studies to determine the best method to catch the attention of a user with a head-worn display.},
	language = {en},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems} - {CHI} {EA} '16},
	publisher = {ACM Press},
	author = {Farve, Niaja and Achituv, Tal and Maes, Pattie},
	year = {2016},
	pages = {2467--2473},
}


@inproceedings{zhu_bishare_2020,
	address = {New York, NY, USA},
	title = {{BISHARE}: {Exploring} {Bidirectional} {Interactions} {Between} {Smartphones} and {Head}-{Mounted} {Augmented} {Reality}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {{BISHARE}},
	url = {https://doi.org/10.1145/3313831.3376233},
	abstract = {In pursuit of a future where HMD devices can be used in tandem with smartphones and other smart devices, we present BISHARE, a design space of cross-device interactions between smartphones and ARHMDs. Our design space is unique in that it is bidirectional in nature, as it examines how both the HMD can be used to enhance smartphone tasks, and how the smartphone can be used to enhance HMD tasks. We then present an interactive prototype that enables cross-device interactions across the proposed design space. A 12-participant user study demonstrates the promise of the design space and provides insights, observations, and guidance for the future.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Fengyuan and Grossman, Tovi},
	month = apr,
	year = {2020},
	keywords = {augmented reality, smartphones, cross-device computing, mixed-reality computing},
	pages = {1--14},
}


@article{hakoama2011impact,
  title={The impact of cell phone use on social networking and development among college students},
  author={Hakoama, Mikiyasu and Hakoyama, Shotaro},
  journal={The American Association of Behavioral and Social Sciences Journal},
  volume={15},
  number={1},
  pages={20},
  year={2011}
}



@inproceedings{chang_i_2019,
	address = {Taipei Taiwan},
	title = {I {Think} {It}'s {Her}: {Investigating} {Smartphone} {Users}' {Speculation} about {Phone} {Notifications} and {Its} {Influence} on {Attendance}},
	isbn = {978-1-4503-6825-4},
	shorttitle = {I {Think} {It}'s {Her}},
	url = {https://doi.org/10.1145/3338286.3340125},
	doi = {10.1145/3338286.3340125},
	abstract = {Smartphone users’ decisions about whether to attend to a notification after sensing it are under-researched. We therefore studied 33 Android users, and found that they speculated extensively about notifications’ sources—i.e., which apps and which senders were responsible for them—before attending to them. The participants’ speculation about apps was both more common and more accurate than that about senders. They also were more likely to 1) perceive notifications as important, 2) attend to them, and 3) consider them beneficial if they speculated about them than if they did not or could not. Participants’ speculations were based on the alert’s inherent characteristics, context, and temporality. Inaccurate speculations were mainly caused by unclear signals, insufficient clues, and a multiplicity of possible sources. Ringer mode affected the accuracy of user speculation, but not its frequency or the frequency of attending to notifications.},
	language = {en},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Chang, Yung-Ju and Chung, Yi-Ju and Shih, Yi-Hao},
	month = oct,
	year = {2019},
	pages = {1--13},
}



@inproceedings{pielot_dismissed_2018,
	address = {Barcelona Spain},
	title = {Dismissed!: a detailed exploration of how mobile phone users handle push notifications},
	isbn = {978-1-4503-5898-9},
	shorttitle = {Dismissed!},
	url = {https://doi.org/10.1145/3229434.3229445},
	doi = {10.1145/3229434.3229445},
	abstract = {We analyzed 794,525 notiﬁcations from 278 mobile phone users and how they were handled. Our study advances prior analyses in two ways: ﬁrst, we systematically split notiﬁcations into ﬁve categories, including a novel separation of messages into individual- and group messages. Second, we conduct a comprehensive analysis of the behaviors involved in attending the notiﬁcations. Our participants received a median number of 56 notiﬁcations per day, which does not indicate that the number of notiﬁcations has increased over the past years. We further show that messaging apps create most of the notiﬁcations, and that other types of notiﬁcations rarely lead to a conversion (rates between ca. 15 and 25\%). A surprisingly large fraction of notiﬁcations is received while the phone is unlocked or the corresponding app is in foreground, hinting at possibility to optimize for this scenario. Finally, we show that the main difference in handling notiﬁcations is how long users leave them unattended if they will ultimately not consume them.},
	language = {en},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Pielot, Martin and Vradi, Amalia and Park, Souneil},
	month = sep,
	year = {2018},
	pages = {1--11},
}


@inproceedings{pejovic_interruptme_2014,
	address = {New York, NY, USA},
	series = {{UbiComp} '14},
	title = {{InterruptMe}: designing intelligent prompting mechanisms for pervasive applications},
	isbn = {978-1-4503-2968-2},
	shorttitle = {{InterruptMe}},
	url = {https://doi.org/10.1145/2632048.2632062},
	doi = {10.1145/2632048.2632062},
	abstract = {The mobile phone represents a unique platform for interactive applications that can harness the opportunity of an immediate contact with a user in order to increase the impact of the delivered information. However, this accessibility does not necessarily translate to reachability, as recipients might refuse an initiated contact or disfavor a message that comes in an inappropriate moment. In this paper we seek to answer whether, and how, suitable moments for interruption can be identified and utilized in a mobile system. We gather and analyze a real-world smartphone data trace and show that users' broader context, including their activity, location, time of day, emotions and engagement, determine different aspects of interruptibility. We then design and implement InterruptMe, an interruption management library for Android smartphones. An extensive experiment shows that, compared to a context-unaware approach, interruptions elicited through our library result in increased user satisfaction and shorter response times.},
	booktitle = {Proceedings of the 2014 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Pejovic, Veljko and Musolesi, Mirco},
	month = sep,
	year = {2014},
	keywords = {context-aware computing, interruptibility, machine learning, mobile sensing},
	pages = {897--908},
}


@article{chuang_ambient_2017,
	title = {Ambient {Notification} {Environments} ({Dagstuhl} {Seminar} 17161)},
	volume = {7},
	issn = {2192-5283},
	url = {https://doi.org/10.4230/DagRep.7.4.38},
	doi = {10.4230/DagRep.7.4.38},
	number = {4},
	journal = {Dagstuhl Reports},
	author = {Chuang, Lewis and Gehring, Sven and Kay, Judy and Schmidt, Albrecht},
	editor = {Chuang, Lewis and Gehring, Sven and Kay, Judy and Schmidt, Albrecht},
	year = {2017},
	keywords = {Ambient Notifications, Dagstuhl Seminar, Skill Transfer},
	pages = {38--82},
}


@inproceedings{horvitz_busybody_2004,
	address = {New York, NY, USA},
	series = {{CSCW} '04},
	title = {{BusyBody}: creating and fielding personalized models of the cost of interruption},
	isbn = {978-1-58113-810-8},
	shorttitle = {{BusyBody}},
	url = {https://doi.org/10.1145/1031607.1031690},
	doi = {10.1145/1031607.1031690},
	abstract = {Interest has been growing in opportunities to build and deploy statistical models that can infer a computer user's current interruptability from computer activity and relevant contextual information. We describe a system that intermittently asks users to assess their perceived interruptability during a training phase and that builds decision-theoretic models with the ability to predict the cost of interrupting the user. The models are used at run-time to compute the expected cost of interruptions, providing a mediator for incoming notifications, based on a consideration of a user's current and recent history of computer activity, meeting status, location, time of day, and whether a conversation is detected.},
	booktitle = {Proceedings of the 2004 {ACM} conference on {Computer} supported cooperative work},
	publisher = {Association for Computing Machinery},
	author = {Horvitz, Eric and Koch, Paul and Apacible, Johnson},
	month = nov,
	year = {2004},
	keywords = {cost of interruption, models of attention, notification systems},
	pages = {507--510},
}


@inproceedings{leiva_back_2012,
	address = {New York, NY, USA},
	series = {{MobileHCI} '12},
	title = {Back to the app: the costs of mobile application interruptions},
	isbn = {978-1-4503-1105-2},
	shorttitle = {Back to the app},
	url = {https://doi.org/10.1145/2371574.2371617},
	doi = {10.1145/2371574.2371617},
	abstract = {Smartphone users might be interrupted while interacting with an application, either by intended or unintended circumstances. In this paper, we report on a large-scale observational study that investigated mobile application interruptions in two scenarios: (1) intended back and forth switching between applications and (2) unintended interruptions caused by incoming phone calls. Our findings reveal that these interruptions rarely happen (at most 10\% of the daily application usage), but when they do, they may introduce a significant overhead (can delay completion of a task by up to 4 times). We conclude with a discussion of the results, their limitations, and a series of implications for the design of mobile phones.},
	booktitle = {Proceedings of the 14th international conference on {Human}-computer interaction with mobile devices and services},
	publisher = {Association for Computing Machinery},
	author = {Leiva, Luis and Böhmer, Matthias and Gehring, Sven and Krüger, Antonio},
	month = sep,
	year = {2012},
	keywords = {application switching, interruptions, large-scale study, resumption lags, task deferral, task interleaving},
	pages = {291--294},
}

@inproceedings{gluck_matching_2007,
	address = {San Jose, California, USA},
	title = {Matching attentional draw with utility in interruption},
	isbn = {978-1-59593-593-9},
	url = {https://doi.org/10.1145/1240624.1240631},
	doi = {10.1145/1240624.1240631},
	abstract = {This research examines a design guideline that aims to increase the positive perception of interruptions. The guideline advocates matching the amount of attention attracted by an interruption’s notification method (attentional draw) to the utility of the interruption content. Our first experiment examined a set of 10 visual notification signals in terms of their detection times and established a set of three significantly different signals along the spectrum of attentional draw. Our second experiment investigated matching these different signals to interruption content with different levels of utility. Results indicate that the matching strategy decreases annoyance and increases perception of benefit compared to a strategy that uses the same signal regardless of interruption utility, with no significant impact on workload or performance. Design implications arising from the second experiment as well as recommendations for future work are discussed.},
	language = {en},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '07},
	publisher = {ACM Press},
	author = {Gluck, Jennifer and Bunt, Andrea and McGrenere, Joanna},
	year = {2007},
	pages = {41--50},
}


@book{millodot_dictionary_2008,
	address = {Edinburgh ; New York},
	edition = {7th edition},
	title = {Dictionary of {Optometry} and {Visual} {Science}},
	isbn = {978-0-7020-2958-5},
	language = {English},
	publisher = {Butterworth-Heinemann},
	author = {Millodot, Michel},
	month = dec,
	year = {2008},
}

@inproceedings{gutwin_peripheral_2017,
	address = {Denver Colorado USA},
	title = {Peripheral {Popout}: {The} {Influence} of {Visual} {Angle} and {Stimulus} {Intensity} on {Popout} {Effects}},
	isbn = {978-1-4503-4655-9},
	shorttitle = {Peripheral {Popout}},
	url = {https://doi.org/10.1145/3025453.3025984},
	doi = {10.1145/3025453.3025984},
	abstract = {By exploiting visual popout effects, interface designers can rapidly draw a user’s attention to salient information objects in a display. A variety of different visual stimuli can be used to achieve popout effects, including color, shape, size, motion, luminance, and flashing. However, there is a lack of understanding about how accurately different intensities of these effects support popout, particularly as targets move further from the center of the visual field. We therefore conducted a study to examine the accuracy of popout target identification using different visual variables, each at five different levels of intensity, and at a wide range of angles from the display center. Results show that motion is a strong popout stimulus, even at low intensities and wide angles. Identification accuracy decreases rapidly across visual angle with other popout stimuli, particularly with shape and color. The findings have relevance to a wide variety of applications, particularly as multi-display desktop environments increase in size and visual extent.},
	language = {en},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Gutwin, Carl and Cockburn, Andy and Coveney, Ashley},
	month = may,
	year = {2017},
	pages = {208--219},
}





% GradNotif

@article{mccrickard_evaluating_2001,
	title = {Evaluating {Animation} in the {Periphery} as a {Mechanism} for {Maintaining} {Awareness}},
	abstract = {Small animated displays such as tickers and faders are increasingly being used to convey information on computer screens. Relatively little is understood, however, about their use as peripheral displays, that is, tools for communicating lower-priority awareness information to people. This article describes two experiments that examine the tradeoff of communication capability versus distraction in peripheral displays. We found that the presence of animated textual peripheral displays did not distract people from a central information browsing task, and we identiﬁed particular animation and display characteristics that facilitate different information-centric tasks.},
	language = {en},
	author = {McCrickard, D Scott and Catrambone, Richard and Stasko, John T},
	year = {2001},
	pages = {8},
}

@inproceedings{maglio_tradeoffs_2000,
	address = {New York, NY, USA},
	series = {{CHI} '00},
	title = {Tradeoffs in displaying peripheral information},
	isbn = {978-1-58113-216-8},
	url = {https://doi.org/10.1145/332040.332438},
	doi = {10.1145/332040.332438},
	abstract = {Peripheral information is information that is not central to a person's current task, but provides the person the opportunity to learn more, to do a better job, or to keep track of less important tasks. Though peripheral information displays are ubiquitous, they have been rarely studied. For computer users, a common peripheral display is a scrolling text display that provides announcements, sports scores, stock prices, or other news. In this paper, we investigate how to design peripheral displays so that they provide the most information while having the least impact on the user's performance on the main task. We report a series of experiments on scrolling displays aimed at examining tradeoffs between distraction of scrolling motion and memorability of information displayed. Overall, we found that continuously scrolling displays are more distracting than displays that start and stop, but information in both is remembered equally well. These results are summarized in a set of design recommendations.},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Maglio, Paul P. and Campbell, Christopher S.},
	month = apr,
	year = {2000},
	keywords = {dual-task tradeoffs, peripheral information, user interface design},
	pages = {241--248},
}

@misc{vuzix_guide_2018,
	title = {Vuzix Blade® Dev Kit User Experience (UX) Design Guidelines},
	url = {http://files.vuzix.com/Content/Upload/Vuzix Blade UX Design Guidelines.pdf},
	urldate = {2022-02-01},
	author = {Vuzix Corporation},
	year = {2018},
}

@misc{vuzix_companion_2021,
	title = {Vuzix {Companion}},
	url = {https://play.google.com/store/apps/details?id=com.vuzix.companion&hl=en_SG&gl=US},
	abstract = {Companion app for Vuzix smart glasses},
	language = {en},
	urldate = {2021-05-22},
	author = {vuzix},
	month = oct,
	year = {2021},
}

@misc{vuzix_vuzix_2021,
	title = {Vuzix {Blade} {Smart} {Glasses}},
	url = {https://www.vuzix.com/products/blade-smart-glasses},
	abstract = {Discover the Vuzix Blade smart glasses.},
	language = {en},
	urldate = {2021-05-22},
	journal = {Vuzix},
	author = {vuzix},
	month = oct,
	year = {2021},
}

@misc{android_android_2021,
	title = {Android {Notifications} {Overview}},
	url = {https://developer.android.com/guide/topics/ui/notifiers/notifications},
	language = {en},
	urldate = {2021-02-08},
	journal = {Android Developers},
	author = {Android},
	year = {2021},
}

@article{bernard_comparing_2003,
	title = {Comparing the effects of text size and format on the readibility of computer-displayed {Times} {New} {Roman} and {Arial} text},
	volume = {59},
	issn = {10715819},
	url = {https://doi.org/10.1016/S1071-5819(03)00121-6},
	doi = {10.1016/S1071-5819(03)00121-6},
	abstract = {Times New Roman and Arial typefaces in 10- and 12-point, dot-matrix and anti-aliased format conditions were compared for readability (accuracy, reading speed, and accuracy/ reading speed), as well as perceptions of typeface legibility, sharpness, ease of reading, and general preference. In assessing readability, the 10-point anti-aliased Arial typeface was read slower than the other type conditions. Examining perceptions of typeface legibility, sharpness, and ease of reading detected signiﬁcant effects for typeface, size, and format. Overall, the 12point dot-matrix Arial typeface was preferred to the other typefaces. Recommendations for appropriate typeface combinations for computer-displayed text are discussed.},
	language = {en},
	number = {6},
	journal = {International Journal of Human-Computer Studies},
	author = {Bernard, Michael L. and Chaparro, Barbara S. and Mills, Melissa M. and Halcomb, Charles G.},
	month = dec,
	year = {2003},
	pages = {823--835},
}

@inproceedings{borst_what_2015,
	address = {Seoul, Republic of Korea},
	title = {What {Makes} {Interruptions} {Disruptive}?: {A} {Process}-{Model} {Account} of the {Effects} of the {Problem} {State} {Bottleneck} on {Task} {Interruption} and {Resumption}},
	isbn = {978-1-4503-3145-6},
	shorttitle = {What {Makes} {Interruptions} {Disruptive}?},
	url = {https://doi.org/10.1145/2702123.2702156},
	doi = {10.1145/2702123.2702156},
	abstract = {In this paper we present a computational cognitive model of task interruption and resumption, focusing on the effects of the problem state bottleneck. Previous studies have shown that the disruptiveness of interruptions is for an important part determined by three factors: interruption duration, interrupting-task complexity, and moment of interruption. However, an integrated theory of these effects is still missing. Based on previous research into multitasking, we propose a first step towards such a theory in the form of a process model that attributes these effects to problem state requirements of both the interrupted and the interrupting task. Subsequently, we tested two predictions of this model in two experiments. The experiments confirmed that problem state requirements are an important predictor for the disruptiveness of interruptions. This suggests that interfaces should be designed to a) interrupt users at lowproblem state moments and b) maintain the problem state for the user when interrupted.},
	language = {en},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '15},
	publisher = {ACM Press},
	author = {Borst, Jelmer P. and Taatgen, Niels A. and van Rijn, Hedderik},
	year = {2015},
	pages = {2971--2980},
}

@article{buchner_advantage_2009,
	title = {The advantage of positive text-background polarity is due to high display luminance},
	volume = {52},
	issn = {0014-0139},
	url = {https://doi.org/10.1080/00140130802641635},
	doi = {10.1080/00140130802641635},
	abstract = {Reading text from computer screens is better when text is printed in dark letters on light background (positive polarity) than when it is printed in light letters on dark background (negative polarity). An experiment is presented that tests whether this positive polarity advantage is due to the fact that overall display luminance is typically higher for positive than for negative polarity displays. To this end, text-background polarity and display luminance were manipulated independently. No positive polarity advantage was observed when overall display luminance of positive and negative polarity displays was equivalent. There was only an effect of display luminance, with better performance for the higher-luminance displays. This suggests that the positive polarity advantage is in fact due to the typically higher luminance of positive polarity displays. Readability of text presented on computer screens (e.g. on websites) is better when the overall display luminance level is high, as in positive polarity displays (dark letters on light background). Display polarity per se does not affect readability.},
	number = {7},
	journal = {Ergonomics},
	author = {Buchner, Axel and Mayr, Susanne and Brandt, Martin},
	month = jul,
	year = {2009},
	pmid = {19562598},
	keywords = {display polarity, luminance, reading},
	pages = {882--886},
}

@inproceedings{darroch_effect_2005,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Effect} of {Age} and {Font} {Size} on {Reading} {Text} on {Handheld} {Computers}},
	isbn = {978-3-540-31722-7},
    url = {https://doi.org/10.1007/11555261_23},
	doi = {10.1007/11555261_23},
	abstract = {Though there have been many studies of computer based text reading, only a few have considered the small screens of handheld computers. This paper presents an investigation into the effect of varying font size between 2 and 16 point on reading text on a handheld computer. By using both older and younger participants the possible effects of age were examined. Reading speed and accuracy were measured and subjective views of participants recorded. Objective results showed that there was little difference in reading performance above 6 point, but subjective comments from participants showed a preference for sizes in the middle range. We therefore suggest, for reading tasks, that designers of interfaces for mobile computers provide fonts in the range of 8-12 point to maximize readability for the widest range of users.},
	language = {en},
	booktitle = {Human-{Computer} {Interaction} - {INTERACT} 2005},
	publisher = {Springer},
	author = {Darroch, Iain and Goodman, Joy and Brewster, Stephen and Gray, Phil},
	editor = {Costabile, Maria Francesca and Paternò, Fabio},
	year = {2005},
	keywords = {Font Size, Reading Speed, Reading Time, Short Passage, Small Screen},
	pages = {253--266},
}

@misc{google_material_2022,
	title = {Material {Design}},
	url = {https://material.io/design/platform-guidance/android-notifications.html#style},
	abstract = {Notifications provide short, timely, and relevant information about your app when it’s not in use.},
	language = {en},
	urldate = {2022-03-02},
	journal = {Material Design},
	author = {Google},
	year = {2022},
}

@article{gujar_comparative_1998,
	title = {A {Comparative} {Evaluation} of {Display} {Technologies} for {Reading}},
	volume = {42},
	issn = {2169-5067},
	url = {https://doi.org/10.1177/154193129804200601},
	doi = {10.1177/154193129804200601},
	abstract = {This paper describes experiments investigating factors that contribute to the readability of computer displays. We present two experiments that focus on reading text from various display technologies, ranging from paper to novel, high-resolution, flat panel displays. This work represents a sequence of controlled experiments and field studies aimed at better understanding the affordances of paper and corresponding design requirements for portable reading devices. Our efforts update previous studies and consider new factors afforded by advances in display technology. Although our findings indicate no statistically significant performance differences between reading from paper and reading from electronic displays for intensive, short proofreading tasks, users nonetheless indicate a strong subjective preference for paper. Evidence from a second experiment indicate that the previously unexamined factors of weight, flexibility and thickness are significant factors behind this.},
	language = {en},
	number = {6},
	journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
	author = {Gujar, Anuj U. and Harrison, Beverly L. and Fishkin, Kenneth P.},
	month = oct,
	year = {1998},
	pages = {527--531},
}

@inproceedings{jankowski_integrating_2010,
	address = {New York, NY, USA},
	series = {{CHI} '10},
	title = {Integrating {Text} with {Video} and {3D} {Graphics}: {The} {Effects} of {Text} {Drawing} {Styles} on {Text} {Readability}},
	isbn = {978-1-60558-929-9},
	shorttitle = {Integrating {Text} with {Video} and {3D} {Graphics}},
	url = {https://doi.org/10.1145/1753326.1753524},
	doi = {10.1145/1753326.1753524},
	abstract = {There have been many studies of computer based text reading. However, only a few have considered text integrated with video and 3D graphics. This paper presents an investigation into the effects of varying (a) text drawing style (plain, billboard, Anti-Interference, shadow), (b) image polarity (positive and negative), and (c) background style (video and 3D) on text readability. Reading speed and accuracy were measured and subjective views of participants recorded. Results showed that: (a) there was little difference in reading performance for the video and 3D backgrounds; (b) the negative presentation outperformed the positive presentation; (c) the billboard drawing styles supported the best performance; subjective comments showed a preference for the billboard style. We therefore suggest, for reading tasks, that designers of interfaces for games, video, and augmented reality provide billboard style to maximize readability for the widest range of applications.},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Jankowski, Jacek and Samp, Krystian and Irzynska, Izabela and Jozwowicz, Marek and Decker, Stefan},
	month = apr,
	year = {2010},
	keywords = {3d graphics, aesthetics, augmented reality, image polarity, legibility, readability, text drawing styles},
	pages = {1321--1330},
}

@article{jorna_image_1991,
	title = {Image {Quality} {Determines} {Differences} in {Reading} {Performance} and {Perceived} {Image} {Quality} with {CRT} and {Hard}-{Copy} {Displays}},
	volume = {33},
	issn = {0018-7208},
	url = {https://doi.org/10.1177/001872089103300407},
	doi = {10.1177/001872089103300407},
	abstract = {The effects of physical image quality on reading and on perceived image quality from CRT and hard copy displays (photographs) were studied. The results showed that as the image quality of a display increased, indicated by an increase in the value of the modulation transfer function area (MTFA), the reading speed and subjective image quality ratings increased. This change in reading speed and perceived image quality occurred similarly for both hard-copy and soft-copy conditions. If the image qualities of the displayed text are similar, hard-copy and softcopy displays will yield equivalent reading speeds.},
	language = {en},
	number = {4},
	journal = {Human Factors},
	author = {Jorna, Gerard C. and Snyder, Harry L.},
	month = aug,
	year = {1991},
	pages = {459--469},
}

@book{millett_new_2017,
	title = {New {Zealand} speed readings for {ESL} learners.},
	isbn = {978-0-475-10503-5},
	language = {en},
	author = {Millett, Sonia},
	year = {2017},
}

@book{quinn1974speed,
  title={Speed reading: A course for learners of English},
  author={Quinn, Elizabeth and Nation, Ian Stephen Paul},
  year={1974},
  publisher={Oxford University Press}
}

@misc{ankrum_computer_2021,
	title = {Computer {Monitor} {Height}, {Angle}, and {Distance} - {Ergonomics} {Guidelines}},
	url = {https://www.si.mahidol.ac.th/simi/hci/monitor-ergonomics.htm},
	urldate = {2022-02-01},
	author = {Ankrum, Dennis},
	year = {2021},
}












@book{ware_information_2013,
	address = {Waltham, MA},
	title = {Information {Visualization}: {Perception} for {Design}},
	isbn = {978-0-12-381464-7},
	shorttitle = {Information {Visualization}},
	abstract = {Most designers know that yellow text presented against a blue background reads clearly and easily, but how many can explain why, and what really are the best ways to help others and ourselves clearly see key patterns in a bunch of data? When we use software, access a website, or view business or scientific graphics, our understanding is greatly enhanced or impeded by the way the information is presented. This book explores the art and science of why we see objects the way we do. Based on the science of perception and vision, the author presents the key principles at work for a wide range of applications--resulting in visualization of improved clarity, utility, and persuasiveness. The book offers practical guidelines that can be applied by anyone: interaction designers, graphic designers of all kinds (including web designers), data miners, and financial analysts.},
	language = {English},
	author = {Ware, Colin},
	year = {2013},
}


@article{rau_modality_2019,
	title = {Modality capacity and appropriateness in multimodal display of complex non-semantic information stream},
	volume = {130},
	issn = {10715819},
	url = {https://doi.org/10.1016/j.ijhcs.2019.06.008},
	doi = {10.1016/j.ijhcs.2019.06.008},
	abstract = {The design of multimodal output should be based on modality capacity and appropriateness. Previous relevant research had various limitations such as using over-simpliﬁed tasks. We proposed a paradigm with virtual reality to explore the capacity and appropriateness of complex non-semantic information stream. In two experiments, ﬁfty-six college students identiﬁed location, magnitude, and/or frequency/duration of visual, auditory, and haptic stimuli, and the bi- and tri-modal combinations. We found that (1) for stimuli of 2–4 bits, visual stimuli were identiﬁed faster, more accurately, and with lower workload (p values {\textless} 0.001) than auditory and haptic stimuli. (2) Multimodal redundant stimuli were identiﬁed with similar accuracy, response time, and workload as its best unimodal component (p values ≥ 0.068). (3) For visual stimuli, magnitude and location were identiﬁed more accurately than duration; for haptic stimuli, location was identiﬁed more accurately than magnitude and duration. (4) When two targets within one modality were to be identiﬁed simultaneously, performance of processing visual stimuli deteriorated least, and performance of processing auditory stimuli deteriorated most. Vision has the most general appropriateness and largest capacity for non-semantic information stream, which cannot be overcome by multimodal redundant output. These ﬁndings should be considered when designing multimodal interfaces.},
	language = {en},
	journal = {International Journal of Human-Computer Studies},
	author = {Rau, Pei-Luen Patrick and Zheng, Jian},
	month = oct,
	year = {2019},
	pages = {166--178},
}

@article{hsia_information_1971,
	title = {The {Information} {Processing} {Capacity} of {Modality} and {Channel} {Performance}},
	volume = {19},
	issn = {0001-2890},
	url = {https://www.jstor.org/stable/30217635},
	number = {1},
	journal = {AV Communication Review},
	author = {Hsia, H. J.},
	year = {1971},
	pages = {51--75},
}


@inproceedings{matthies_scaling_2018,
	address = {Berlin, Germany},
	title = {Scaling {Notifications} {Beyond} {Alerts}: {From} {Subtly} {Drawing} {Attention} up to {Forcing} the {User} to {Take} {Action}},
	isbn = {978-1-4503-5949-8},
	shorttitle = {Scaling {Notifications} {Beyond} {Alerts}},
	url = {https://doi.org/10.1145/3266037.3266096},
	doi = {10.1145/3266037.3266096},
	abstract = {Research has been done in sophisticated notifications, still, devices today mainly stick to a binary level of information, while they are either attention drawing or silent. We propose scalable notifications, which adjust the intensity level reaching from subtle to obtrusive and even going beyond that level while forcing the user to take action. To illustrate the technical feasibility and validity of this concept, we developed three prototypes. The prototypes provided mechano-pressure, thermal, and electrical feedback, which were evaluated in different lab studies. Our first prototype provides subtle poking through to high and frequent pressure on the user’s spine, which significantly improves back posture. In a second scenario, the user is able to perceive the overuse of a drill by an increased temperature on the palm of a hand until the heat is intolerable, forcing the user to eventually put down the tool. The last application comprises of a speed control in a driving simulation, while electric muscle stimulation on the users’ legs, conveys information on changing the car’s speed by a perceived tingling until the system forces the foot to move involuntarily. In conclusion, all studies’ findings support the feasibility of our concept of a scalable notification system, including the system forcing an intervention.},
	language = {en},
	booktitle = {The 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology} {Adjunct} {Proceedings}  - {UIST} '18 {Adjunct}},
	publisher = {ACM Press},
	author = {Matthies, Denys J.C. and Daza Parra, Laura Milena and Urban, Bodo},
	year = {2018},
	pages = {45--47},
}


@inproceedings{fukushima_comparing_2020,
	address = {Porto de Galinhas, Brazil},
	title = {Comparing {World} and {Screen} {Coordinate} {Systems} in {Optical} {See}-{Through} {Head}-{Mounted} {Displays} for {Text} {Readability} while {Walking}},
	isbn = {978-1-72818-508-8},
	url = {https://doi.org/10.1109/ISMAR50242.2020.00093},
	doi = {10.1109/ISMAR50242.2020.00093},
	abstract = {Augmented reality (AR) optical-see-through (OST) head-mounted displays (HMD) have developed to a point where browsing information on the go is possible. In this paper, we investigate the readability of text on an AR HMD while the user is walking. There are two common methods of displaying text on a HMD: anchoring the text on the screen coordinate system or the world coordinate system. We report on the results of two laboratory experiments comparing text readability when the text is displayed in these two coordinate systems, and while the participants walked on a treadmill. In the ﬁrst experiment, the participants read letter strings comprising Sloane letters, whereas the second experiment used English words. In addition to evaluating the text readability and workload experienced by participants, we employed IMU sensors to compare the effects of the text display method on the participants’ head movement and gait. In both experiments, the reading speed and head movement were signiﬁcantly higher and mental workload signiﬁcantly lower for the world coordinate system than for the screen coordinate system. These results suggest that text readability while walking is better on the world coordinate system, and displaying text with the screen coordinate system results in an unnatural gait owing to the user trying to keep their head still in an effort to stabilize the HMD screen.},
	language = {en},
	booktitle = {2020 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR})},
	publisher = {IEEE},
	author = {Fukushima, Shogo and Hamada, Takeo and Hautasaari, Ari},
	month = nov,
	year = {2020},
	pages = {649--658},
}


@book{styles_psychology_2005,
	address = {London},
	title = {The psychology of attention},
	isbn = {978-1841693972},
	language = {en},
	publisher = {Taylor \& Francis e-Library},
	author = {Styles, Elizabeth A},
	year = {2006},
}


@inproceedings{fischer_effects_2010,
	address = {Lisbon, Portugal},
	title = {Effects of content and time of delivery on receptivity to mobile interruptions},
	isbn = {978-1-60558-835-3},
	url = {https://doi.org/10.1145/1851600.1851620},
	doi = {10.1145/1851600.1851620},
	abstract = {In this paper we investigate effects of the content of interruptions and of the time of interruption delivery on mobile phones. We review related work and report on a naturalistic quasi-experiment using experience-sampling that showed that the receptivity to an interruption is influenced by its content rather than by its time of delivery in the employed modality of delivery – SMS. We also examined the underlying variables that increase the perceived quality of content and found that the factors interest, entertainment, relevance and actionability influence people’s receptivity significantly. Our findings inform system design that seeks to provide context-sensitive information or to predict interruptibility and suggest the consideration of receptivity as an extension to the way we think and reason about interruptibility.},
	language = {en},\
	booktitle = {Proceedings of the 12th international conference on {Human} computer interaction with mobile devices and services - {MobileHCI} '10},
	publisher = {ACM Press},
	author = {Fischer, Joel E. and Yee, Nick and Bellotti, Victoria and Good, Nathan and Benford, Steve and Greenhalgh, Chris},
	year = {2010},\
}


@inproceedings{mehrotra_my_2016,
	address = {Santa Clara, California, USA},
	title = {My {Phone} and {Me}: {Understanding} {People}'s {Receptivity} to {Mobile} {Notifications}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {My {Phone} and {Me}},
	url = {https://doi.org/10.1145/2858036.2858566},
	doi = {10.1145/2858036.2858566},
	abstract = {Notiﬁcations are extremely beneﬁcial to users, but they often demand their attention at inappropriate moments. In this paper we present an in-situ study of mobile interruptibility focusing on the effect of cognitive and physical factors on the response time and the disruption perceived from a notiﬁcation. Through a mixed method of automated smartphone logging and experience sampling we collected 10372 in-thewild notiﬁcations and 474 questionnaire responses on notiﬁcation perception from 20 users. We found that the response time and the perceived disruption from a notiﬁcation can be inﬂuenced by its presentation, alert type, sender-recipient relationship as well as the type, completion level and complexity of the task in which the user is engaged. We found that even a notiﬁcation that contains important or useful content can cause disruption. Finally, we observe the substantial role of the psychological traits of the individuals on the response time and the disruption perceived from a notiﬁcation.},
	language = {en},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '16},
	publisher = {ACM Press},
	author = {Mehrotra, Abhinav and Pejovic, Veljko and Vermeulen, Jo and Hendley, Robert and Musolesi, Mirco},
	year = {2016},
	pages = {1021--1032},
}


@inproceedings{yuan_how_2017,
	address = {Denver, Colorado, USA},
	title = {How {Busy} {Are} {You}?: {Predicting} the {Interruptibility} {Intensity} of {Mobile} {Users}},
	isbn = {978-1-4503-4655-9},
	shorttitle = {How {Busy} {Are} {You}?},
	url = {https://doi.org/10.1145/3025453.3025946},
	doi = {10.1145/3025453.3025946},
	abstract = {Smartphones frequently notify users about newly available messages or other notiﬁcations. It can be very disruptive when these notiﬁcations interrupt users while they are busy. Our work here is based on the observation that people usually exhibit different levels of busyness at different contexts. This means that classifying users’ interruptibility as a binary status, interruptible or not interruptible, is not sufﬁcient to accurately measure their availability towards smartphone interruptions. In this paper, we propose, implement and evaluate a two-stage hierarchical model to predict people’s interruptibility intensity. Our work is the ﬁrst to introduce personality traits into interruptibility prediction model, and we found that personality data improves the prediction signiﬁcantly. Our model bootstraps the prediction with similar people’s data, and provides a good initial prediction for users whose individual models have not been trained on their own data yet. Overall prediction accuracy of our model can reach 66.1\%.},
	language = {en},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '17},
	publisher = {ACM Press},
	author = {Yuan, Fengpeng and Gao, Xianyi and Lindqvist, Janne},
	year = {2017},
	pages = {5346--5360},
}


@misc{alsop_ar_2022,
	title = {{AR} glasses unit sales worldwide 2024},
	url = {https://www.statista.com/statistics/610496/smart-ar-glasses-shipments-worldwide/},
	abstract = {In 2021, unit sales of augmented reality (AR) glasses among the leading brands worldwide are expected to amount to 410 thousand units, rising to 3.9 million units by 2024.},
	language = {en},
	urldate = {2021-09-28},
	journal = {Statista},
	author = {Alsop, Thomas},
	month = jan,
	year = {2022},
}


@article{rensink_see_1997,
	title = {To {See} or not to {See}: {The} {Need} for {Attention} to {Perceive} {Changes} in {Scenes}},
	volume = {8},
	issn = {0956-7976, 1467-9280},
	shorttitle = {To {See} or not to {See}},
	url = {https://doi.org/10.1111/j.1467-9280.1997.tb00427.x},
	doi = {10.1111/j.1467-9280.1997.tb00427.x},
	abstract = {When looking at a scene, observers feel thPaatshtlheery, 1s9e8e8;itPshillips, 1974). An initial display was presented for entire structure in great detail and can immediat1e0l0yton5o0t0icmes,anfoyllowed by a brief interstimulus interval (ISI), folchanges in it. However, when brief blank fields arelopwlaecdebdybaestewcoenedndisplay in which one of the items was removed or alternating displays of an original and a modified screenplea,cead sotnrihkailnf gthe trials. Responses were forced-choice guesses failure of perception is induced: Identification of chabaonugtews hbeetchoem r aeschange had occurred. Observers were found to be extremely difficult, even when changes are large anpdoormaatddeetreectpienagtc-hange if old and new displays were separated by an edly. Identification is much faster when a verbal cIuSIeofismoprre othvaind6e0dt,o 70 ms.},
	language = {en},
	number = {5},
	journal = {Psychological Science},
	author = {Rensink, Ronald A. and O'Regan, J. Kevin and Clark, James J.},
	month = sep,
	year = {1997},
	pages = {368--373},
}


@inproceedings{mccay_peet_saliency_2012,
	address = {Austin, Texas, USA},
	title = {On saliency, affect and focused attention},
	isbn = {978-1-4503-1015-4},
	url = {https://doi.org/10.1145/2207676.2207751},
	doi = {10.1145/2207676.2207751},
	abstract = {We study how the visual catchiness (saliency) of relevant information impacts user engagement metrics such as focused attention and emotion (affect). Participants completed tasks in one of two conditions, where the task-relevant information either appeared salient or non-salient. Our analysis provides insights into relationships between saliency, focused attention, and affect. Participants reported more distraction in the non-salient condition, and non-salient information was slower to find than salient. Lackof-saliency led to a negative impact on affect, while saliency maintained positive affect, suggesting its helpfulness. Participants reported that it was easier to focus in the salient condition, although there was no significant improvement in the focused attention scale rating. Finally, this study suggests user interest in the topic is a good predictor of focused attention, which in turn is a good predictor of positive affect. These results suggest that enhancing saliency of user-interested topics seems a good strategy for boosting user engagement.},
	language = {en},
	booktitle = {Proceedings of the 2012 {ACM} annual conference on {Human} {Factors} in {Computing} {Systems} - {CHI} '12},
	publisher = {ACM Press},
	author = {McCay-Peet, Lori and Lalmas, Mounia and Navalpakkam, Vidhya},
	year = {2012},
	pages = {541},
}


@book{lee_oxford_2013,
	edition = {1st edition},
	title = {The Oxford Handbook of Cognitive Engineering},
	isbn = {978-0-19-997146-6},
	url = {https://doi.org/10.1093/oxfordhb/9780199757183.001.0001},
	language = {en},
	publisher = {Oxford University Press},
	editor = {Lee, John D. and Kirlik, Alex},
	month = feb,
	year = {2013},
	doi = {10.1093/oxfordhb/9780199757183.001.0001},
}


@article{zulkernain_mobile_2010,
	title = {A {Mobile} {Intelligent} {Interruption} {Management} {System}},
    url = {https://doi.org/10.3217/jucs-016-15-2060},
	doi = {10.3217/jucs-016-15-2060},
	abstract = {The architecture of a system named Mobile Intelligent Interruptions Management (MIIM), created for the automated administration of personal unavailability with regard to cell phones, is proposed and Simulation and evaluation results show that its computational volumes are low enough for a mobile device. Mobile phones have become the most hated device that people cannot live without. For its primary usage as a communication device, it has surpassed any other medium. But it comes with a high price, interruption, anywhere anytime. These unwanted interruptions cause loss of productivity and also mostly not beneficial to the immediate task at hand, and moving them few minutes into the future can increase productivity. Considering receiver's unavailability, it is possible to manage cell phone disruptions using advanced features like sensing capability, ubiquitous computing and context aware systems. This paper proposes the architecture of a system named Mobile Intelligent Interruptions Management (MIIM), created for the automated administration of personal unavailability with regard to cell phones. We provide the problem description of interruption and its impact. Next, we state the desirable characteristics and architecture of the MIIM system. We also provide a case study implementation of MIIM system on the Android platform. Simulation and evaluation results show that its computational volumes are low enough for a mobile device. The analysis of the system also successfully satisfies all the characteristics requirements.},
	journal = {J. Univers. Comput. Sci.},
	author = {Zulkernain, Sina and Madiraju, P. and Ahamed, Sheikh Iqbal},
	year = {2010},
}

@inproceedings{begole_lilsys_2004,
	address = {Chicago, Illinois, USA},
	title = {Lilsys: {Sensing} {Unavailability}},
	isbn = {978-1-58113-810-8},
	shorttitle = {Lilsys},
	url = {https://doi.org/10.1145/1031607.1031691},
	doi = {10.1145/1031607.1031691},
	abstract = {As communications systems increasingly gather and propagate information about people’s reachability or “presence”, users need better tools to minimize undesired interruptions while allowing desired ones. We review the salient elements of presence and availability that people use when initiating face-to-face communication. We discuss problems with current strategies for managing one’s availability in telecommunication media. We describe a prototype system called Lilsys which passively collects availability cues gathered from users’ actions and environment using ambient sensors and provides machine inferencing of unavailability. We discuss observations and design implications from deploying Lilsys.},
	language = {en},
	booktitle = {Proceedings of the 2004 {ACM} conference on {Computer} supported cooperative work  - {CSCW} '04},
	publisher = {ACM Press},
	author = {Begole, James "Bo" and Matsakis, Nicholas E. and Tang, John C.},
	year = {2004},
}

@inproceedings{lopez_tovar_managing_2015,
	address = {Atlanta, Georgia, USA},
	title = {Managing {Smartphone} {Interruptions} through {Adaptive} {Modes} and {Modulation} of {Notifications}},
	isbn = {978-1-4503-3306-1},
	url = {https://doi.org/10.1145/2678025.2701390},
	doi = {10.1145/2678025.2701390},
	abstract = {Smartphones are capable of alerting their users to different kinds of digital interruption using different modalities and with varying modulation. Smart notiﬁcation is the capability of a smartphone for selecting the user’s preferred kind of alert in particular situations using the full vocabulary of notiﬁcation modalities and modulations. It therefore goes well beyond attempts to predict if or when to silence a ringing phone call. We demonstrate smart notiﬁcation for messages received from a document retrieval system while the user is attending a meeting. The notiﬁcation manager learns about their notiﬁcation preferences from users’ judgements about videos of meetings. It takes account of the relevance of the interruption to the meeting, whether the user is busy and the sensed location of the smartphone. Through repeated training, the notiﬁcation manager learns to reliably predict the preferred notiﬁcation modes for users and this learning continues to improve with use.},
	language = {en},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Intelligent} {User} {Interfaces} - {IUI} '15},
	publisher = {ACM Press},
	author = {Lopez-Tovar, Hugo and Charalambous, Andreas and Dowell, John},
	year = {2015},
	pages = {296--299},
}

@inproceedings{sarker_assessing_2014,
	address = {New York, NY, USA},
	series = {{UbiComp} '14},
	title = {Assessing the availability of users to engage in just-in-time intervention in the natural environment},
	isbn = {978-1-4503-2968-2},
	url = {http://doi.org/10.1145/2632048.2636082},
	doi = {10.1145/2632048.2636082},
	abstract = {Wearable wireless sensors for health monitoring are enabling the design and delivery of just-in-time interventions (JITI). Critical to the success of JITI is to time its delivery so that the user is available to be engaged. We take a first step in modeling users' availability by analyzing 2,064 hours of physiological sensor data and 2,717 self-reports collected from 30 participants in a week-long field study. We use delay in responding to a prompt to objectively measure availability. We compute 99 features and identify 30 as most discriminating to train a machine learning model for predicting availability. We find that location, affect, activity type, stress, time, and day of the week, play significant roles in predicting availability. We find that users are least available at work and during driving, and most available when walking outside. Our model finally achieves an accuracy of 74.7\% in 10-fold cross-validation and 77.9\% with leave-one-subject-out.},
	booktitle = {Proceedings of the 2014 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Sarker, Hillol and Sharmin, Moushumi and Ali, Amin Ahsan and Rahman, Md. Mahbubur and Bari, Rummana and Hossain, Syed Monowar and Kumar, Santosh},
	month = sep,
	year = {2014},
	keywords = {interruption, EMA, intervention, mobile application, mobile health, self-report},
	pages = {909--920},
}

@article{pielot_beyond_2017,
	title = {Beyond {Interruptibility}: {Predicting} {Opportune} {Moments} to {Engage} {Mobile} {Phone} {Users}},
	volume = {1},
	issn = {2474-9567, 2474-9567},
	shorttitle = {Beyond {Interruptibility}},
	url = {https://doi.org/10.1145/3130956},
	doi = {10.1145/3130956},
	language = {en},
	number = {3},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Pielot, Martin and Cardoso, Bruno and Katevas, Kleomenis and Serrà, Joan and Matic, Aleksandar and Oliver, Nuria},
	month = sep,
	year = {2017},
	pages = {1--25},
}

@inproceedings{okoshi_reducing_2015,
	address = {Osaka, Japan},
	title = {Reducing users' perceived mental effort due to interruptive notifications in multi-device mobile environments},
	isbn = {978-1-4503-3574-4},
	url = {https://doi.org/10.1145/2750858.2807517},
	doi = {10.1145/2750858.2807517},
	abstract = {In today’s ubiquitous computing environment where users carry, manipulate, and interact with an increasing number of networked devices, applications and web services, human attention is the new bottleneck in computing. It is therefore important to minimize a user’s mental effort due to notiﬁcations, especially in situations where users are mobile and using multiple wearable and mobile devices. To this end, we propose Attelia II, a novel middleware that identiﬁes breakpoints in users’ lives while using those devices, and delivers notiﬁcations at these moments. Attelia II works in real-time and uses only the mobile and wearable devices that users naturally use and wear, without any modiﬁcations to applications, and without any dedicated psycho-physiological sensors. Our in-the-wild evaluation in users’ multi-device environment (smart phones and smart watches) with 41 participants for 1 month validated the effectiveness of Attelia. Our new physical activity-based breakpoint detection, in addition to the UI Event-based breakpoint detection, resulted in a 71.8\% greater reduction of users’ perception of workload, compared with our previous system that used UI events only. Adding this functionality to a smart watch reduced workload perception by 19.4\% compared to random timing of notiﬁcation deliveries. Our multi-device breakpoint detection across smart phones and watches resulted in about 3 times greater reduction in workload perception than our previous system.},
	language = {en},
	booktitle = {Proceedings of the 2015 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} - {UbiComp} '15},
	publisher = {ACM Press},
	author = {Okoshi, Tadashi and Ramos, Julian and Nozaki, Hiroki and Nakazawa, Jin and Dey, Anind K. and Tokuda, Hideyuki},
	year = {2015},
	pages = {475--486},
}

@inproceedings{weber_situ_2016,
	address = {Heidelberg Germany},
	title = {In-situ investigation of notifications in multi-device environments},
	isbn = {978-1-4503-4461-6},
	url = {https://doi.org/10.1145/2971648.2971732},
	doi = {10.1145/2971648.2971732},
	abstract = {Smart devices have arrived in our everyday lives. Being able to notify the user about events is a core feature of these devices. Related work investigated interruptions caused by notiﬁcations on single devices. In this paper, we investigate notiﬁcations in multi-device environments by analyzing the results of a week-long in-situ study with 16 participants. We used the Experience Sampling Method (ESM) and recorded the participants’ interaction with smartphones, smartwatches, tablets and PCs. Disregarding the type or content of notiﬁcations, we found that the smartphone is the preferred device on which to be notiﬁed. Further, we found that the proximity to the device, whether it is currently being used and the user’s current location can be used to predict if the user wants to receive notiﬁcations on a device. The ﬁndings can be used to design future multi-device aware smart notiﬁcation systems.},
	language = {en},
	booktitle = {Proceedings of the 2016 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing}},
	publisher = {ACM},
	author = {Weber, Dominik and Voit, Alexandra and Kratzer, Philipp and Henze, Niels},
	month = sep,
	year = {2016},
	pages = {1259--1264},
}

@inproceedings{zuger_reducing_2017,
	address = {Denver Colorado USA},
	title = {Reducing {Interruptions} at {Work}: {A} {Large}-{Scale} {Field} {Study} of {FlowLight}},
	isbn = {978-1-4503-4655-9},
	shorttitle = {Reducing {Interruptions} at {Work}},
	url = {https://doi.org/10.1145/3025453.3025662},
	doi = {10.1145/3025453.3025662},
	abstract = {Due to the high number and cost of interruptions at work, several approaches have been suggested to reduce this cost for knowledge workers. These approaches predominantly focus either on a manual and physical indicator, such as headphones or a closed ofﬁce door, or on the automatic measure of a worker’s interruptibilty in combination with a computer-based indicator. Little is known about the combination of a physical indicator with an automatic interruptibility measure and its long-term impact in the workplace. In our research, we developed the FlowLight, that combines a physical trafﬁc-light like LED with an automatic interruptibility measure based on computer interaction data. In a large-scale and long-term ﬁeld study with 449 participants from 12 countries, we found, amongst other results, that the FlowLight reduced the interruptions of participants by 46\%, increased their awareness on the potential disruptiveness of interruptions and most participants never stopped using it.},
	language = {en},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Züger, Manuela and Corley, Christopher and Meyer, André N. and Li, Boyang and Fritz, Thomas and Shepherd, David and Augustine, Vinay and Francis, Patrick and Kraft, Nicholas and Snipes, Will},
	month = may,
	year = {2017},
	pages = {61--72},
}

@article{akcayir_advantages_2017,
	title = {Advantages and challenges associated with augmented reality for education: {A} systematic review of the literature},
	volume = {20},
	issn = {1747938X},
	shorttitle = {Advantages and challenges associated with augmented reality for education},
	url = {https://doi.org/10.1016/j.edurev.2016.11.002},
	doi = {10.1016/j.edurev.2016.11.002},
	abstract = {This study presents a systematic review of the literature on augmented reality (AR) used in educational settings. We consider factors such as publication year, learner type (e.g., K-12, higher education, and adult), technologies in AR, and the advantages and challenges of using AR in educational settings. The full range of SSCI journals was surveyed and a total of 68 research articles were selected for analysis. The ﬁndings reveal an increase in the number of AR studies during the last four years. The most reported advantage of AR is that it promotes enhanced learning achievement. Some noted challenges imposed by AR are usability issues and frequent technical problems. We found several other challenges and numerous advantages of AR usage, which are discussed in detail. In addition, current gaps in AR research and needs in the ﬁeld are identiﬁed, and suggestions are offered for future research.},
	language = {en},
	journal = {Educational Research Review},
	author = {Akçayır, Murat and Akçayır, Gökçe},
	month = feb,
	year = {2017},
	keywords = {augmented-reality, survey, education},
	pages = {1--11},
}

@article{zarraonandia_augmented_2013,
	title = {An augmented lecture feedback system to support learner and teacher communication: {An} augmented lecture feedback system},
	volume = {44},
	issn = {00071013},
	shorttitle = {An augmented lecture feedback system to support learner and teacher communication},
	url = {https://doi.org/10.1111/bjet.12047},
	doi = {10.1111/bjet.12047},
	abstract = {In this paper, it is advocated that the feedback loop between learners and teachers could be improved by making use of augmented reality (AR) techniques. The bidirectional communication between teacher and learners is sometimes hampered by students’ fear of showing themselves up in front of their classmates. In order to overcome this problem, a system is proposed whereby teachers receive immediate and private feedback both individualised for each student as well as aggregated for the whole class. With that purpose, the teacher, who is equipped with a head-mounted AR display, can visualise symbols that represent the status students have stated using private devices in relation to the lecture content. In order to explore the possibilities of this approach, an experience was conducted in a lecture on a university course. The results are encouraging and suggest that as this technology matures and less intrusive AR display models become available, it could provide effective support to improve communication and interaction during lectures.},
	language = {en},
	number = {4},
	journal = {British Journal of Educational Technology},
	author = {Zarraonandia, Telmo and Aedo, Ignacio and Díaz, Paloma and Montero, Alvaro},
	month = jul,
	year = {2013},
	pages = {616--628},
}

@article{ibrahim_arbis_2018,
	title = {{ARbis} {Pictus}: {A} {Study} of {Vocabulary} {Learning} with {Augmented} {Reality}},
	volume = {24},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{ARbis} {Pictus}},
	url = {https://doi.org/10.1109/TVCG.2018.2868568},
	doi = {10.1109/TVCG.2018.2868568},
	abstract = {We conducted a fundamental user study to assess potential beneﬁts of AR technology for immersive vocabulary learning. With the idea that AR systems will soon be able to label real-world objects in any language in real time, our within-subjects (N=52) lab-based study explores the effect of such an AR vocabulary prompter on participants learning nouns in an unfamiliar foreign language, compared to a traditional ﬂashcard-based learning approach. Our results show that the immersive AR experience of learning with virtual labels on real-world objects is both more effective and more enjoyable for the majority of participants, compared to ﬂashcards. Speciﬁcally, when participants learned through augmented reality, they scored signiﬁcantly better on both same-day and 4-day delayed productive recall tests than when they learned using the ﬂashcard method. We believe this result is an indication of the strong potential for language learning in augmented reality, particularly because of the improvement shown in sustained recall compared to the traditional approach.},
	language = {en},
	number = {11},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Ibrahim, Adam and Huynh, Brandon and Downey, Jonathan and Hollerer, Tobias and Chun, Dorothy and O'donovan, John},
	month = nov,
	year = {2018},
	keywords = {Basque-learning, flashcard-based-learning, incidental-learning},
	pages = {2867--2874},
}

@inproceedings{ban_augmented_2013,
	address = {Paris, France},
	title = {Augmented endurance: controlling fatigue while handling objects by affecting weight perception using augmented reality},
	isbn = {978-1-4503-1899-0},
	shorttitle = {Augmented endurance},
	url = {https://doi.org/10.1145/2470654.2470665},
	doi = {10.1145/2470654.2470665},
	abstract = {The main contribution of this paper is to develop a method for alleviating fatigue during handling medium-weight objects and augmenting our endurance by affecting our weight perception with augmented reality technology. To assist people to lift medium-weight objects without a complex structure or various costs, we focus on the phenomenon that our weight perception during handling objects is affected by visual properties. Our hypothesis is that this illusionary effect in weight perception can be applied to reduce fatigue while handling medium-weight objects without mechatronics-based physical assistance.},
	language = {en},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '13},
	publisher = {ACM Press},
	author = {Ban, Yuki and Narumi, Takuji and Fujii, Tatsuya and Sakurai, Sho and Imura, Jun and Tanikawa, Tomohiro and Hirose, Michitaka},
	year = {2013},
}

@article{chicchi_giglioli_augmented_2015,
	title = {Augmented {Reality}: {A} {Brand} {New} {Challenge} for the {Assessment} and {Treatment} of {Psychological} {Disorders}},
	volume = {2015},
	issn = {1748-670X, 1748-6718},
	shorttitle = {Augmented {Reality}},
	url = {https://doi.org/10.1155/2015/862942},
	doi = {10.1155/2015/862942},
	language = {en},
	journal = {Computational and Mathematical Methods in Medicine},
	author = {Chicchi Giglioli, Irene Alice and Pallavicini, Federica and Pedroli, Elisa and Serino, Silvia and Riva, Giuseppe},
	year = {2015},
	pages = {1--12},
}

@inproceedings{piumsomboon_mini_me_2018,
	address = {Montreal QC, Canada},
	title = {Mini-{Me}: {An} {Adaptive} {Avatar} for {Mixed} {Reality} {Remote} {Collaboration}},
	isbn = {978-1-4503-5620-6},
	shorttitle = {Mini-{Me}},
	url = {https://doi.org/10.1145/3173574.3173620},
	doi = {10.1145/3173574.3173620},
	abstract = {We present Mini-Me, an adaptive avatar for enhancing Mixed Reality (MR) remote collaboration between a local Augmented Reality (AR) user and a remote Virtual Reality (VR) user. The Mini-Me avatar represents the VR user’s gaze direction and body gestures while it transforms in size and orientation to stay within the AR user’s field of view. A user study was conducted to evaluate Mini-Me in two collaborative scenarios: an asymmetric remote expert in VR assisting a local worker in AR, and a symmetric collaboration in urban planning. We found that the presence of the MiniMe significantly improved Social Presence and the overall experience of MR collaboration.},
	language = {en},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '18},
	publisher = {ACM Press},
	author = {Piumsomboon, Thammathip and Lee, Gun A. and Hart, Jonathon D. and Ens, Barrett and Lindeman, Robert W. and Thomas, Bruce H. and Billinghurst, Mark},
	year = {2018},
	pages = {1--13},
}

@incollection{de_paolis_natural_2014,
	address = {Cham},
	title = {Natural {Interaction} and {Wearable} {Augmented} {Reality} for the {Enjoyment} of the {Cultural} {Heritage} in {Outdoor} {Conditions}},
	volume = {8853},
	isbn = {978-3-319-13969-2},
	url = {https://doi.org/10.1007/978-3-319-13969-2_20},
	abstract = {In this paper, a ﬁrst prototype of a wearable, interactive augmented reality (AR) system for the enjoyment of the cultural heritage in outdoor environments, is presented. By using a binocular see-through display and a time-of-ﬂight (ToF) depth sensor, the system provides the users with a visual augmentation of their surroundings and with touchless interaction techniques to interact with synthetic elements overlapping with the real world. The papers describes the hardware and software system components, and details the interface speciﬁcally designed for a socially acceptable cultural heritage exploration. Furthermore, the paper discusses the lesson learned from the ﬁrst public presentation of the prototype we have carried out in Naples, Italy.},
	language = {en},
	booktitle = {Augmented and {Virtual} {Reality}},
	publisher = {Springer International Publishing},
	author = {Caggianese, Giuseppe and Neroni, Pietro and Gallo, Luigi},
	editor = {De Paolis, Lucio Tommaso and Mongelli, Antonio},
	year = {2014},
	doi = {10.1007/978-3-319-13969-2_20},
	pages = {267--282},
}

@inproceedings{peng_roma_2018,
	address = {Montreal QC, Canada},
	title = {{RoMA}: {Interactive} {Fabrication} with {Augmented} {Reality} and a {Robotic} {3D} {Printer}},
	isbn = {978-1-4503-5620-6},
	shorttitle = {{RoMA}},
	url = {https://doi.org/10.1145/3173574.3174153},
	doi = {10.1145/3173574.3174153},
	abstract = {We present the Robotic Modeling Assistant (RoMA), an interactive fabrication system providing a fast, precise, hands-on and in-situ modeling experience. As a designer creates a new model using RoMA AR CAD editor, features are constructed concurrently by a 3D printing robotic arm sharing the same design volume. The partially printed physical model then serves as a tangible reference for the designer as she adds new elements to her design. RoMA’s proxemics-inspired handshake mechanism between the designer and the 3D printing robotic arm allows the designer to quickly interrupt printing to access a printed area or to indicate that the robot can take full control of the model to finish printing. RoMA lets users integrate real-world constraints into a design rapidly, allowing them to create well-proportioned tangible artifacts or to extend existing objects. We conclude by presenting the strengths and limitations of our current design.},
	language = {en},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '18},
	publisher = {ACM Press},
	author = {Peng, Huaishu and Briggs, Jimmy and Wang, Cheng-Yao and Guo, Kevin and Kider, Joseph and Mueller, Stefanie and Baudisch, Patrick and Guimbretière, François},
	year = {2018},
	pages = {1--12},
}

@inproceedings{roy_follow_my_lead_2017,
	address = {New York, NY, USA},
	series = {{CHI} '17},
	title = {Follow-{My}-{Lead}: {Intuitive} {Indoor} {Path} {Creation} and {Navigation} {Using} {Interactive} {Videos}},
	isbn = {978-1-4503-4655-9},
	shorttitle = {Follow-{My}-{Lead}},
	url = {https://doi.org/10.1145/3025453.3025976},
	doi = {10.1145/3025453.3025976},
	abstract = {We present Follow-My-Lead, an alternative indoor navigation technique that uses visual information recorded on an actual navigation path as a navigational guide. Its design revealed a trade-off between the fidelity of information provided to users and their effort to acquire it. Our first experiment revealed that scrolling through a continuous image stream of the navigation path is highly informative, but it becomes tedious with constant use. Discrete image checkpoints require less effort, but can be confusing. A balance may be struck by adding fast video transitions between image checkpoints, but precise control is required to handle difficult situations. Authoring still image checkpoints is also difficult, and this inspired us to invent a new technique using video checkpoints. We conducted a second experiment on authoring and navigation performance and found video checkpoints plus fast video transitions to be better than both image checkpoints plus fast video transitions and traditional written instructions.},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Roy, Quentin and Perrault, Simon T. and Zhao, Shengdong and Davis, Richard C. and Pattena Vaniyar, Anuroop and Vechev, Velko and Lee, Youngki and Misra, Archan},
	month = may,
	year = {2017},
	keywords = {egocentric visual navigation., indoor navigation, leader-follower, mobile computing, smartglasses, video, wearable computing},
	pages = {5703--5715},
}

@article{piekarski_arquake_2002,
	title = {{ARQuake}: the outdoor augmented reality gaming system},
	volume = {45},
	issn = {0001-0782},
	shorttitle = {{ARQuake}},
	url = {https://doi.org/10.1145/502269.502291},
	doi = {10.1145/502269.502291},
	number = {1},
	journal = {Communications of the ACM},
	author = {Piekarski, Wayne and Thomas, Bruce},
	month = jan,
	year = {2002},
	pages = {36--38},
}

@inproceedings{fan_augmented_2016,
	address = {New York, NY, USA},
	series = {{AH} '16},
	title = {Augmented {Winter} {Ski} with {AR} {HMD}},
	isbn = {978-1-4503-3680-2},
	url = {https://doi.org/10.1145/2875194.2875202},
	doi = {10.1145/2875194.2875202},
	abstract = {At time of writing, several affordable Head-Mounted Displays (HMD) are going to be released to the mass market, most of them for Virtual Reality (VR with Oculus Rift, Samsung Gear...) but also for indoor Augmented Reality (AR) with Hololens. We have investigated how to adapt such HMD as Oculus Rift for an outdoor AR ski slope. Rather than setting physical obstacles such as poles, our system employs AR to render dynamic obstacles by different means. During the demo, skiers will wear a video-see-through HMD while trying to ski on a real ski slope where AR obstacles are rendered.},
	booktitle = {Proceedings of the 7th {Augmented} {Human} {International} {Conference} 2016},
	publisher = {Association for Computing Machinery},
	author = {Fan, Kevin and Seigneur, Jean-Marc and Guislain, Jonathan and Nanayakkara, Suranga and Inami, Masahiko},
	month = feb,
	year = {2016},
	keywords = {Augmented Reality (AR), Augmented Winter Sports, Head-Mounted Display (HMD), Visual Augmentation, Wearable Augmentation},
	pages = {1--2},
}

@misc{bach_us_2021,
	title = {U.{S}. {Army} to use {HoloLens} technology in high-tech headsets for soldiers},
	url = {https://news.microsoft.com/transform/u-s-army-to-use-hololens-technology-in-high-tech-headsets-for-soldiers/},
	abstract = {Microsoft will soon produce thousands of mixed-reality headsets for U.S. Army soldiers.},
	language = {en-US},
	urldate = {2022-04-13},
	journal = {Transform},
	author = {Bach, Deborah},
	month = jun,
	year = {2021},
}

@article{anandapadmanaban_holo_sextant_2018,
	title = {Holo-{SEXTANT}: an {Augmented} {Reality} {Planetary} {EVA} {Navigation} {Interface}},
	shorttitle = {Holo-{SEXTANT}},
	url = {http://hdl.handle.net/2346/74212},
	abstract = {Future planetary exploration for teams of astronauts and rovers can be enhanced through the use of augmented reality (AR) for the purpose of navigating a planned traverse. We present Holo-SEXTANT: a proof of concept AR navigation system tested during simulated Extravehicular Activities (EVA) during the Biologic Analog Science Associated with Lava Terrains (BASALT) exploration field campaign in November 2017, at Hawai’i Volcanoes National Park. Wrist displays and tablets have long been standard tools for navigation and used for analog planetary EVA traverses. However, they distract the astronaut from their environment as the astronaut repeatedly has to look at the display leading to the potential for loss of situational awareness. More primitive navigation methods, such as guidance through voice commands from mission control can also take up mental resources and remove the focus from exploring the environment. Holo-SEXTANT introduces a new approach that allows traverse plans to be overlaid on the terrain in the display, enabling the user to view their environment while always keeping track of the location of the path. The system has geolocation awareness and thus relies only on geographic coordinates of the path as an input, allowing for the display of any arbitrary traverse path. It can be actuated by voice control and includes real-time information displays relevant to the user’s location. During the BASALT deployment, the Holo-SEXTANT system was tested in hazardous terrain where no natural or visually obvious paths exist, making the tool essential. We present data on the quality of the navigation achieved with the AR display and prove that this is a viable solution for navigation. We highlight limitations observed during our in-field testing and feedback from the analog astronaut crew involved in the BASALT 2017 campaign. We conclude with a set of recommendations for future development of more advanced AR navigation interfaces.},
	month = jul,
	year = {2018},
}

@inproceedings{zuger_interruptibility_2015,
	address = {New York, NY, USA},
	series = {{CHI} '15},
	title = {Interruptibility of {Software} {Developers} and its {Prediction} {Using} {Psycho}-{Physiological} {Sensors}},
	isbn = {978-1-4503-3145-6},
	url = {https://doi.org/10.1145/2702123.2702593},
	doi = {10.1145/2702123.2702593},
	abstract = {Interruptions of knowledge workers are common and can cause a high cost if they happen at inopportune moments. With recent advances in psycho-physiological sensors and their link to cognitive and emotional states, we are interested whether such sensors might be used to measure interruptibility of a knowledge worker. In a lab and a field study with a total of twenty software developers, we examined the use of psycho-physiological sensors in a real-world context. The results show that a Naive Bayes classifier based on psycho-physiological features can be used to automatically assess states of a knowledge worker's interruptibility with high accuracy in the lab as well as in the field. Our results demonstrate the potential of these sensors to avoid expensive interruptions in a real-world context. Based on brief interviews, we further discuss the usage of such an interruptibility measure and interruption support for software developers.},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Züger, Manuela and Fritz, Thomas},
	month = apr,
	year = {2015},
	keywords = {interruptibility, lab/field study, psycho-physiological},
	pages = {2981--2990},
}

@inproceedings{iqbal_investigating_2005,
	address = {Portland, OR, USA},
	title = {Investigating the effectiveness of mental workload as a predictor of opportune moments for interruption},
	isbn = {978-1-59593-002-6},
	url = {https://doi.org/10.1145/1056808.1056948},
	doi = {10.1145/1056808.1056948},
	abstract = {This work investigates the use of workload-aligned task models for predicting opportune moments for interruption. From models for several tasks, we selected boundaries with the lowest (Best) and highest (Worst) mental workload. We compared effects of interrupting primary tasks at these and Random moments on resumption lag, annoyance, and social attribution. Results show that interrupting tasks at predicted Best moments consistently caused less resumption lag and annoyance, and fostered more social attribution. Thus, the use of workload-aligned task models offers a systematic method for predicting opportune moments for interruption.},
	language = {en},
	booktitle = {{CHI} '05 extended abstracts on {Human} factors in computing systems  - {CHI} '05},
	publisher = {ACM Press},
	author = {Iqbal, Shamsi T. and Bailey, Brian P.},
	year = {2005},
	pages = {1489},
}

@inproceedings{pejovic_investigating_2015,
	address = {New York, NY, USA},
	series = {{MobileHCI} '15},
	title = {Investigating {The} {Role} of {Task} {Engagement} in {Mobile} {Interruptibility}},
	isbn = {978-1-4503-3653-6},
	url = {https://doi.org/10.1145/2786567.2794336},
	doi = {10.1145/2786567.2794336},
	abstract = {Context-awareness of mobile phones is a cornerstone of recent efforts in automatic determination of user interruptibility. Modalities such as a user's location, her physical activity, time of day, can be used in machine learning models to infer if a user is going to welcome an incoming notification or not. However, the success of context-aware interruptibility systems questions the existing theory of interruptibility, that is based on the internal state of the user, not her surroundings. In this work we examine the role of a user's internal context, defined by her engagement in the current task, on the sentiment towards an interrupting mobile notification. We collect and analyse real-world data on interruptibility of twenty subjects over two weeks, and show that the internal state indeed impacts user interruptibility.},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services} {Adjunct}},
	publisher = {Association for Computing Machinery},
	author = {Pejovic, Veljko and Musolesi, Mirco and Mehrotra, Abhinav},
	month = aug,
	year = {2015},
	keywords = {Context-aware computing, Interruptibility, Multitasking, Notifications},
	pages = {1100--1105},
}

@inproceedings{chewar_unpacking_2004,
	address = {New York, NY, USA},
	series = {{DIS} '04},
	title = {Unpacking critical parameters for interface design: evaluating notification systems with the {IRC} framework},
	isbn = {978-1-58113-787-3},
	shorttitle = {Unpacking critical parameters for interface design},
	url = {http://doi.org/10.1145/1013115.1013155},
	doi = {10.1145/1013115.1013155},
	abstract = {We elaborate a proposal for capturing, extending, and reusing design knowledge gleaned through usability testing. The proposal is specifically targeted to address interface design for notification systems, but its themes can be generalized to any constrained and well-defined genre of interactive system design. We reiterate arguments for and against using critical parameters to characterize user goals and usability artifacts. Responding to residual arguments, we suggest that clear advantages for research cohesion, design knowledge reuse, and HCI education are possible if several challenges are overcome. As a first step, we recommend a slight variation to the concept of a critical parameter, which would allow both abstract and concrete knowledge representation. With this concept, we demonstrate a feasible approach by introducing equations that elaborate and allow evolution of notification system critical parameters, which is made operational with a variety of usability evaluation instruments. A case study illustrates how one general instrument allowed system designs to be meaningfully compared and resulted in valuable inferences for interface reengineering. Broad implications and conclusions about this approach will be of interest to others concerned with using critical parameters in interface design, development of notification systems interfaces, or approaches to design rationale and knowledge reuse.},
	booktitle = {Proceedings of the 5th conference on {Designing} interactive systems: processes, practices, methods, and techniques},
	publisher = {Association for Computing Machinery},
	author = {Chewar, C. M. and McCrickard, D. Scott and Sutcliffe, Alistair G.},
	month = aug,
	year = {2004},
	keywords = {claims, design reuse, peripheral display, usability evaluation},
	pages = {279--288},
}

@article{tungare_exploratory_2008,
	title = {An {Exploratory} {Study} of {Calendar} {Use}},
	url = {http://arxiv.org/abs/0809.3447},
	abstract = {In this paper, we report on findings from an ethnographic study of how people use their calendars for personal information management (PIM). Our participants were faculty, staff and students who were not required to use or contribute to any specific calendaring solution, but chose to do so anyway. The study was conducted in three parts: first, an initial survey provided broad insights into how calendars were used; second, this was followed up with personal interviews of a few participants which were transcribed and content-analyzed; and third, examples of calendar artifacts were collected to inform our analysis. Findings from our study include the use of multiple reminder alarms, the reliance on paper calendars even among regular users of electronic calendars, and wide use of calendars for reporting and life-archival purposes. We conclude the paper with a discussion of what these imply for designers of interactive calendar systems and future work in PIM research.},
	journal = {arXiv:0809.3447 [cs]},
	author = {Tungare, Manas and Perez-Quinones, Manuel and Sams, Alyssa},
	month = sep,
	year = {2008},
}

@article{kelley_how_1982,
	title = {How professional persons keep their calendars: {Implications} for computerization},
	volume = {55},
	issn = {2044-8325},
	shorttitle = {How professional persons keep their calendars},
	url = {https://doi.org/10.1111/j.2044-8325.1982.tb00098.x},
	doi = {10.1111/j.2044-8325.1982.tb00098.x},
	abstract = {Twenty-three professional persons were interviewed extensively to find out how they keep their appointment calendars and to extract from that information suggestions about how calendars could be computerized. For the majority of the persons interviewed calendars are indispensable to the conduct of their business, and, in some cases, their personal lives. At the same time the data show an unexpectedly large amount of diversity in the kinds of calendars people use and in the ways they use them. Substantially more than half of the respondents have more than one calendar, with two persons using as many as six calendars at once. Portability and access from diverse locations are important for many persons. Concerns about privacy vary widely: some persons keep their calendars closely guarded, others allow free access to them. Relevant time spans covered by calendars are enormous. Some few people are concerned only with the current day and the day following, others may plan appointments a year or more in advance. A substantial number of appointments are changed after they have been made and, once again, the range is large, from about 2 per cent for some persons to about 80 per cent for others. Archiving, query patterns, and the insertion of correlated information into calendars also vary greatly among various users.},
	language = {en},
	number = {4},
	journal = {Journal of Occupational Psychology},
	author = {Kelley, J. F. and Chapanis, Alphonse},
	year = {1982},
}

@inproceedings{weber_annotif_2019,
	address = {Pisa, Italy},
	title = {Annotif: a system for annotating mobile notifications in user studies},
	isbn = {978-1-4503-7624-2},
	shorttitle = {Annotif},
	url = {https://doi.org/10.1145/3365610.3365611},
	doi = {10.1145/3365610.3365611},
	abstract = {Notifications are an essential feature of smartphones. While they support users in staying up-to-date, they are also a prominent source of interruptions. A deeper understanding of mobile notifications is required to avoid adverse effects. However, assessing mobile notifications is challenging as user studies on mobile notifications are typically conducted in-situ. Surveying users may lead to additional interruptions, and the content of notifications is inherently private. In this paper, we introduce a privacy-aware system for annotating mobile notifications in user studies. In an in-situ case study, participants annotated their notifications for one week. Participants perceived 38.91\% of their notifications as not important and over half (51.75\%) as non-urgent. Only 6.33\% of the notifications were rated as both very important and very urgent. We discuss influencing factors, including a breakdown of messaging notifications, and implications for future smart notification systems that continue to fulfill users’ information need while respecting their digital well-being.},
	language = {en},
	booktitle = {Proceedings of the 18th {International} {Conference} on {Mobile} and {Ubiquitous} {Multimedia}  - {MUM} '19},
	publisher = {ACM Press},
	author = {Weber, Dominik and Voit, Alexandra and Kollotzek, Gisela and Henze, Niels},
	year = {2019},
	pages = {1--12},
}

@inproceedings{erickson_exploring_2020,
	address = {New York, NY, USA},
	series = {{SUI} '20},
	title = {Exploring the {Limitations} of {Environment} {Lighting} on {Optical} {See}-{Through} {Head}-{Mounted} {Displays}},
	isbn = {978-1-4503-7943-4},
	url = {https://doi.org/10.1145/3385959.3418445},
	doi = {10.1145/3385959.3418445},
	abstract = {Due to the additive light model employed by most optical see-through head-mounted displays (OST-HMDs), they provide the best augmented reality (AR) views in dark environments, where the added AR light does not have to compete against existing real-world lighting. AR imagery displayed on such devices loses a significant amount of contrast in well-lit environments such as outdoors in direct sunlight. To compensate for this, OST-HMDs often use a tinted visor to reduce the amount of environment light that reaches the user’s eyes, which in turn results in a loss of contrast in the user’s physical environment. While these effects are well known and grounded in existing literature, formal measurements of the illuminance and contrast of modern OST-HMDs are currently missing. In this paper, we provide illuminance measurements for both the Microsoft HoloLens 1 and its successor the HoloLens 2 under varying environment lighting conditions ranging from 0 to 20,000 lux. We evaluate how environment lighting impacts the user by calculating contrast ratios between rendered black (transparent) and white imagery displayed under these conditions, and evaluate how the intensity of environment lighting is impacted by donning and using the HMD. Our results indicate the further need for refinement in the design of future OST-HMDs to optimize contrast in environments with illuminance values greater than or equal to those found in indoor working environments.},
	booktitle = {Symposium on {Spatial} {User} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Erickson, Austin and Kim, Kangsoo and Bruder, Gerd and Welch, Gregory F.},
	month = oct,
	year = {2020},
	keywords = {Visual Perception, Contrast, Augmented Reality, Environment Lighting, Illuminance, Optical See-Through Head-Mounted Displays},
	pages = {1--8},
}

@inproceedings{ang_study_2020,
	title = {A {Study} on the {Effect} of the {Real}-world {Backgrounds} using {Colour} {Blending} {Technique} on {Optical} {See}-through {AR} {User} {Interface} {Design}},
	doi = {10.1109/ICIDM51048.2020.9339664},
    url = {https://doi.org/10.1109/ICIDM51048.2020.9339664},
	abstract = {Through the few numbers of formal study that shows the usability of the optical see-through augmented reality (AR) display, especially in the outdoor environment, has been affected by ambient lighting conditions and dynamic real-world backgrounds. They used painted posters which represented a real-world background to examine the effect. Under changing lighting conditions, the colour palette of the environment can also cause considerable problems. For example, specific label colours can be affected by the similarity of the selected colour scheme. Besides, the actual outdoor light source illuminates the actual objects in outdoor AR systems, while the augmented virtual objects are illuminated by a virtual light source. The colour differentials arise from these two light sources, with the actual object and virtual object being visualized as a combination of the colours induced by the two light sources. Furthermore, there is a visible colour difference between the real object and the virtual object. This paper studies the effect of the real-world backgrounds using colour blending technique on optical see-through AR user interface design. It enables AR graphics to be overlaid onto real-world backgrounds as nicely as painted posters. Colour blending effects influenced physical materials as backgrounds are almost the same as their corresponding poster backgrounds, even if each pair of colours are just a metameric match.},
	booktitle = {2020 6th {International} {Conference} on {Interactive} {Digital} {Media} ({ICIDM})},
	author = {Ang, Siao Ying and Ng, Giap Weng},
	month = dec,
	year = {2020},
	keywords = {augmented reality, Visualization, Color, colour blending, Integrated optics, Light sources, Lighting, Optical design techniques, optical see-through, user interface, User interfaces},
	pages = {1--4},
}

@inproceedings{david_hincapie_ramos_smartcolor_2014,
	address = {Munich, Germany},
	title = {{SmartColor}: {Real}-time color correction and contrast for optical see-through head-mounted displays},
	isbn = {978-1-4799-6184-9},
	shorttitle = {{SmartColor}},
	url = {https://doi.org/10.1109/ISMAR.2014.6948426},
	doi = {10.1109/ISMAR.2014.6948426},
	abstract = {Users of optical see-through head-mounted displays (OHMD) perceive color as a blend of the display color and the background. Color-blending is a major usability challenge as it leads to loss of color encodings and poor text legibility. Color correction aims at mitigating color blending by producing an alternative color which, when blended with the background, more closely approaches the color originally intended. To date, approaches to color correction do not yield optimal results or do not work in real-time. This paper makes two contributions. First, we present QuickCorrection, a realtime color correction algorithm based on display profiles. We describe the algorithm, measure its accuracy and analyze two implementations for the OpenGL graphics pipeline. Second, we present SmartColor, a middleware for color management of userinterface components in OHMD. SmartColor uses color correction to provide three management strategies: correction, contrast, and show-up-on-contrast. Correction determines the alternate color which best preserves the original color. Contrast determines the color which best warranties text legibility while preserving as much of the original hue. Show-up-on-contrast makes a component visible when a related component does not have enough contrast to be legible. We describe the SmartColor’s architecture and illustrate the color strategies for various types of display content.},
	language = {en},
	booktitle = {2014 {IEEE} {International} {Symposium} on {Mixed} and {Augmented} {Reality} ({ISMAR})},
	publisher = {IEEE},
	author = {David Hincapie-Ramos, Juan and Ivanchuk, Levko and Sridharan, Srikanth Kirshnamachari and Irani, Pourang},
	month = sep,
	year = {2014},
	keywords = {Accuracy, Adaptive optics, Algorithm design and analysis, Color, Color Blending, Contrast, Correction, Graphics, Head-Mounted Displays, Image color analysis, Real-time systems, See-through Displays, Transparency},
	pages = {187--194},
}

@inproceedings{matsuura_readability_2019,
	address = {London United Kingdom},
	title = {Readability and legibility of fonts considering shakiness of head mounted displays},
	isbn = {978-1-4503-6870-4},
	url = {https://doi.org/10.1145/3341163.3347748},
	doi = {10.1145/3341163.3347748},
	abstract = {In wearable computing environments, users acquire visual information in various scenes using a head mounted display (HMD). However, this induces problems due to their diﬀerences from conventional displays such as smartphone and e-books. In this research, we focused on the problem of vertical shock caused by walking. This problem interferes with seeing information on HMDs. In this paper, we discuss selection of font shapes to minimize the eﬀect of this problem. If we can clarify the characteristics of the readability of fonts in wearable computing environments, the application designers can select fonts that strike a balance between intended design elements and readability. In this paper, we ﬁrst investigated the characteristics of fonts used in Japan considering the HMD swing that results from walking, from the viewpoints of readability (text readability) and legibility (ease of letter recognition) using six diﬀerent fonts. From this evaluation, we ﬁnd that fonts with very thin horizontal lines and with very thin horizontal and vertical lines should not be presented on HMDs.},
	language = {en},
	booktitle = {Proceedings of the 23rd {International} {Symposium} on {Wearable} {Computers}},
	publisher = {ACM},
	author = {Matsuura, Yuki and Terada, Tsutomu and Aoki, Tomohiro and Sonoda, Susumu and Isoyama, Naoya and Tsukamoto, Masahiko},
	month = sep,
	year = {2019},
	pages = {150--159},
}

@article{barnard_empirical_2005,
	title = {An empirical comparison of use-in-motion evaluation scenarios for mobile computing devices},
	volume = {62},
	issn = {10715819},
	url = {https://doi.org/10.1016/j.ijhcs.2004.12.002},
	doi = {10.1016/j.ijhcs.2004.12.002},
	language = {en},
	number = {4},
	journal = {International Journal of Human-Computer Studies},
	author = {Barnard, Leon and Yi, Ji Soo and Jacko, Julie A. and Sears, Andrew},
	month = apr,
	year = {2005},
	pages = {487--520},
}

@inproceedings{roumen_notiring_2015,
	address = {Seoul, Republic of Korea},
	title = {{NotiRing}: {A} {Comparative} {Study} of {Notification} {Channels} for {Wearable} {Interactive} {Rings}},
	isbn = {978-1-4503-3145-6},
	shorttitle = {{NotiRing}},
	url = {https://doi.org/10.1145/2702123.2702350},
	doi = {10.1145/2702123.2702350},
	abstract = {We conducted an empirical investigation of wearable interactive rings on the noticeability of four instantaneous notification channels (light, vibration, sound, poke) and a channel with gradually increased temperature (thermal) during five levels of physical activity (laying down, sitting, standing, walking, and running). Results showed that vibration was the most reliable and fastest channel to convey notification, followed by poke and sound which shared similar noticeability. The noticeability of these three channels was not affected by the level of physical activity. The other two channels, light and thermal, were less noticeable and were affected by the level of physical activity. Our post-experimental survey indicates that while noticeability has a significant influence on user preference, each channel has its own unique advantages that make it suitable for different notification scenarios.},
	language = {en},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '15},
	publisher = {ACM Press},
	author = {Roumen, Thijs and Perrault, Simon T. and Zhao, Shengdong},
	year = {2015},
	pages = {2497--2500},
}

@inproceedings{je_pokering_2018,
	address = {New York, NY, USA},
	series = {{CHI} '18},
	title = {{PokeRing}: {Notifications} by {Poking} {Around} the {Finger}},
	isbn = {978-1-4503-5620-6},
	shorttitle = {{PokeRing}},
	url = {https://doi.org/10.1145/3173574.3174116},
	doi = {10.1145/3173574.3174116},
	abstract = {Smart-rings are ideal for subtle and always-available haptic notifications due to their direct contact with the skin. Previous researchers have highlighted the feasibility of haptic technology in smart-rings and their promise in delivering noticeable stimulations by poking a limited set of planar locations on the finger. However, the full potential of poking as a mechanism to deliver richer and more expressive information on the finger is overlooked. With three studies and a total of 76 participants, we informed the design of PokeRing, a smart-ring capable of delivering information via stimulating eight different locations around the index finger's proximal phalanx. We report our evaluation of the performance of PokeRing in semi-realistic wearable conditions, (standing and walking), and its effective usage for information transfer with twenty-one spatio-temporal patterns designed by six interaction designers in a workshop. Finally, we present three applications that exploit PokeRing's notification usages.},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Je, Seungwoo and Lee, Minkyeong and Kim, Yoonji and Chan, Liwei and Yang, Xing-Dong and Bianchi, Andrea},
	month = apr,
	year = {2018},
	keywords = {haptics, notification, poke, ring, wearable},
	pages = {1--10},
}

@incollection{sexton_15_1988,
	address = {San Diego},
	series = {Cognition and {Perception}},
	title = {15 - {Cockpit}–{Crew} {Systems} {Design} and {Integration}},
	isbn = {978-0-08-057090-7},
	url = {https://doi.org/10.1016/B978-0-08-057090-7.50021-7},
	abstract = {This chapter focuses on the design and integration of the cockpit-crew systems. A change in crew systems design philosophies, technologies, and cockpit layouts have begun in recent years. Several factors have been influential in causing that change. Probably the most important was the rapid rate at which advanced technologies applicable to crew systems were becoming available. The engineering community saw the advantages of incorporating new technologies—particularly in the area of avionics—for purposes of saving weight and space, while at the same time increasing reliability and supportability. Crew systems designers were, therefore, able to begin modernizing flight stations and were even encouraged by other design disciplines to incorporate new technology crew systems such as CRTs; integrated control-displays for communications, navigation, and transponders; and digital color weather radars. At the same time, operators of larger civil and military aircraft perceived large cost savings in salaries, personnel benefits, on-board equipment, and operating weight for each crew member that could be eliminated from the cockpit crew. To deal with problems, crew systems design teams have been organized at almost all of the major airframe manufacturers. Meanwhile, advances in avionics technology, particularly in computing capacity and data buses, permit integration of aircraft systems and functions in ways that were heretofore impossible or impractical. Future aircraft will be truly integrated systems. Applying artificial intelligence through expert systems will undoubtedly have far-reaching effects on crew systems of the future.},
	language = {en},
	booktitle = {Human {Factors} in {Aviation}},
	publisher = {Academic Press},
	author = {Sexton, George A.},
	editor = {Wiener, Earl L. and Nagel, David C.},
	month = jan,
	year = {1988},
	doi = {10.1016/B978-0-08-057090-7.50021-7},
	pages = {495--526},
}

@misc{noauthor_continental_2022,
	title = {Continental {Automotive}},
	url = {http://www.continental-automotive.com/en-gl/Passenger-Cars/User-Experience/Head-Up-Displays},
	abstract = {Head-Up-Displays},
	language = {English},
	urldate = {2022-04-17},
	year = {2022},
	journal = {Continental Automotive},
}

@article{monk_effect_2008,
	title = {The effect of interruption duration and demand on resuming suspended goals},
	volume = {14},
	issn = {1939-2192},
	doi = {10.1037/a0014402},
    url = {https://doi.org/10.1037/a0014402},
	abstract = {The time to resume task goals after an interruption varied depending on the duration and cognitive demand of interruptions, as predicted by the memory for goals model (Altmann \& Trafton, 2002). Three experiments using an interleaved tasks interruption paradigm showed that longer and more demanding interruptions led to longer resumption times in a hierarchical, interactive task. The resumption time profile for durations up to 1 min supported the role of decay in defining resumption costs, and the interaction between duration and demand supported the importance of goal rehearsal in mitigating decay. These findings supported the memory for goals model, and had practical implications for context where tasks are frequently interleaved such as office settings, driving, emergency rooms, and aircraft cockpits. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	journal = {Journal of Experimental Psychology: Applied},
	author = {Monk, Christopher A. and Trafton, J. Gregory and Boehm-Davis, Deborah A.},
	year = {2008},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Goals, Memory},
	pages = {299--313},
}

@article{allen2005spreading,
  title={Spreading the load: Mobile information and communications technologies and their effect on information overload.},
  author={Allen, David K and Shoard, M},
  journal={Information Research: An International Electronic Journal},
  volume={10},
  number={2},
  pages={n2},
  year={2005},
  publisher={ERIC},
  url = {https://eric.ed.gov/?id=EJ1082034},
}

@article{matthes_too_2020,
title = {``Too much to handle'': Impact of mobile social networking sites on information overload, depressive symptoms, and well-being},
journal = {Computers in Human Behavior},
volume = {105},
pages = {106217},
year = {2020},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.106217},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219304364},
author = {Jörg Matthes and Kathrin Karsay and Desirée Schmuck and Anja Stevic},
keywords = {Social networking sites, Information overload, Depressive symptoms, Well-being, Smartphone use, Panel survey},
abstract = {Mobile social networking sites (SNS) are frequently theorized to lead to perceived information overload, which may affect the well-being of individuals in negative ways. However, the available body of research is mainly based on cross-sectional data. Based on the limited capacity model of motivated mediated message processing (Lang, 2002), we tested the over-time relationships between mobile SNS use, information overload, depressive symptoms, and well-being in a two-wave panel study. Using a quota sample of adults (NT2 = 461), we found that YouTube use increased perceived information overload for all individuals. WhatsApp and Snapchat use did only lead to perceived information overload for older adults. Facebook as well as Instagram use were unrelated to perceived information overload. Furthermore, perceptions of information overload were a significant predictor of depressive symptoms, which in turn, negatively influenced individuals’ well-being over time. Implications of these findings are discussed.}
}

@inproceedings{faulhaber_priority_dependent_2022,
	title = {Priority-{Dependent} {Display} of {Notifications} in the {Peripheral} {Field} of {View} of {Smart} {Glasses}},
	doi = {10.1109/VRW55335.2022.00144},
    url = {https://doi.org/10.1109/VRW55335.2022.00144},
	abstract = {We propose a concept for displaying notifications in the peripheral field of view of smart glasses aiming to achieve a balance between perception and distraction depending on the priority of the notification. We designed three different visualizations for notifications of low, medium, and high priority. To evaluate this concept, we conducted a study with 24 participants who reacted to the notifications while performing a primary task. Reaction times for the low-priority notification were significantly higher. The medium- and high-priority notifications did not show a clear difference.},
	booktitle = {2022 {IEEE} {Conference} on {Virtual} {Reality} and {3D} {User} {Interfaces} {Abstracts} and {Workshops} ({VRW})},
	author = {Faulhaber, Anja K. and Hoppe, Moritz and Schmidt, Ludger},
	month = mar,
	year = {2022},
	keywords = {Augmented reality, Augmented reality glasses, Conferences, distraction, Human-centered computing—Human computer interaction (HCI)—Empirical studies in HCI, Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed / augmented reality, interruption, notification, peripheral vision, Smart glasses, Task analysis, Three-dimensional displays, User interfaces, Visualization},
	pages = {586--587},
}

@article{gabbard_effects_2018,
	title = {Effects of {AR} {Display} {Context} {Switching} and {Focal} {Distance} {Switching} on {Human} {Performance}},
	volume = {25},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2018.2832633},
    url = {https://doi.org/10.1109/TVCG.2018.2832633},
	abstract = {In augmented reality (AR) environments, information is often distributed between real world and virtual contexts, and often appears at different distances from the user. Therefore, to integrate the information, users must repeatedly switch context and refocus the eyes. To focus at different distances, the user's eyes must accommodate, which when done repeatedly can cause eyestrain and degrade task performance. An experiment was conducted that examined switching context and focal distance between a real and an AR environment, using a text-based visual search task and a monocular optical see-through AR display. Both context switching and focal distance switching resulted in significantly reduced performance. In addition, repeatedly performing the task caused visual fatigue to steadily increase. Performance was particularly poor for virtual text presented at optical infinity, and for target letters that participants tried to read before their eyes had completely accommodated to a new focal distance. The results show that context switching and focal distance switching are important AR user interface design issues.},
	number = {6},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Gabbard, Joseph L. and Mehra, Divya Gupta and Swan, J. Edward},
	year = {2018},
	keywords = {Visualization, Task analysis, Fatigue, Head-up displays, Multimedia information systems—artificial, augmented, and virtual realities, Optical switches, User interfaces—ergonomics, evaluation/methodology, screen design, style guides},
	pages = {2228--2241},
}

@misc{nyelveszleny_english_2022,
	title = {English sentence-bank: 5-word sentences (511)},
	shorttitle = {English sentence-bank},
	url = {http://bsnyelvtanfolyam.blog.hu/2014/07/29/english_sentence-bank_5-word_sentences},
	urldate = {2022-06-03},
	journal = {Brain Storming nyelvtanulási segédletei},
	author = {NyelvÉszlény, BS},
	month = jan,
	year = {2022},
}

@inproceedings{smith_visual_2015,
	address = {New York, NY, USA},
	series = {{AutomotiveUI} '15},
	title = {Visual search tasks: the effects of head-up displays on driving and task performance},
	isbn = {978-1-4503-3736-6},
	shorttitle = {Visual search tasks},
	url = {https://doi.org/10.1145/2799250.2799291},
	doi = {10.1145/2799250.2799291},
	abstract = {This study investigated the differences between head-up display (HUD) and head-down display (HDD) systems in vehicles with the ultimate goal of increasing driver performance and safety. Our initial focus was on comparing drivers' visual task performance (and associated driving behavior) while using a HUD and HDD. In a medium-fidelity driving simulator, 16 experienced drivers performed two types of tasks, a structured (text) and a semi-structured (grid) visual search task while driving. They first completed a baseline drive using a driving simulator with no secondary tasks followed by four drives under various conditions: HUD-Text, HUD-Grid, HDD-Text, and HDD-Grid. The study returned mixed results. HUDs generally contributed to more secondary task errors, but overall, users still preferred to use HUDs over HDDs. The response time to complete tasks was unevenly affected by display type. While there was no difference between response times in the grid tasks (HDD vs. HUD), the HUD was associated with significantly faster task performance as compared to the text tasks. These results suggest that HUDs may offer advantages to drivers in some task scenarios but more research is needed to understand under what conditions they do not add value.},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Smith, Missie and Streeter, Jillian and Burnett, Gary and Gabbard, Joseph L.},
	month = sep,
	year = {2015},
	keywords = {augmented reality, head-down display, head-up display, vehicle display system, visual display image},
	pages = {80--87},
}

@inproceedings{syiem_impact_2021,
	address = {Yokohama Japan},
	title = {Impact of {Task} on {Attentional} {Tunneling} in {Handheld} {Augmented} {Reality}},
	isbn = {978-1-4503-8096-6},
	url = {https://doi.org/10.1145/3411764.3445580},
	doi = {10.1145/3411764.3445580},
	abstract = {Attentional tunneling describes a phenomenon in Augmented Reality (AR) where users excessively focus on virtual content while neglecting their physical surroundings. This leads to the concern that users could neglect hazardous situations when using AR applications. However, studies have often confounded the role of the virtual content with the role of the associated task in inducing attentional tunneling. In this paper, we disentangle the impact of the associated task and of the virtual content on the attentional tunneling efect by measuring reaction times to events in two user studies. We found that presenting virtual content did not signifcantly increase user reaction times to events, but adding a task to the content did. This work contributes towards our understanding of the attentional tunneling efect on handheld AR devices, and highlights the need to consider both task and context when evaluating AR application usage.},
	language = {en},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Syiem, Brandon Victor and Kelly, Ryan M. and Goncalves, Jorge and Velloso, Eduardo and Dingler, Tilman},
	month = may,
	year = {2021},
	pages = {1--14},
}

@inproceedings{tasse_getting_2016,
	address = {San Jose California USA},
	title = {Getting {Users}' {Attention} in {Web} {Apps} in {Likable}, {Minimally} {Annoying} {Ways}},
	isbn = {978-1-4503-3362-7},
	url = {https://doi.org/10.1145/2858036.2858174},
	doi = {10.1145/2858036.2858174},
	abstract = {Web applications often need to present the user new information in the context of their current activity. Designers rely on a range of UI elements and visual techniques to present the new content to users, such as popups, message icons, and marquees. Web designers need to select which technique to use depending on the centrality of the information and how quickly they need a reaction. However, designers often rely on intuition and anecdotes rather than empirical evidence to drive their decisionmaking as to which presentation technique to use. This work represents an attempt to quantify these presentation style decisions. We present a large (n=1505) user study that compares 15 visual attention-grabbing techniques with respect to reaction time, noticeability, annoyance, likability, and recall. We suggest glowing shadows and message icons with badges, as well as more possibilities for future work.},
	language = {en},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Tasse, Dan and Ankolekar, Anupriya and Hailpern, Joshua},
	month = may,
	year = {2016},
	pages = {3324--3334},
}

@phdthesis{wilson_gradual_2006,
	type = {Thesis},
	title = {Gradual awareness notification for the desktop environment},
	copyright = {M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.},
	url = {http://hdl.handle.net/1721.1/36905},
	abstract = {This thesis develops and puts forth the principles of gradual awareness notification. It distinguishes the concepts of hard and soft notification, and defines situations where gradual awareness techniques can be of the most benefit. Furthermore, it applies gradual awareness principles to the desktop environment to produce slow-growth notification, a visual notification system relying on slowly growing windows. It describes the design principles behind gradual awareness notification, and presents a prototype implementation of slow-growth notification called the Slow-Growth Library, or SGL. Finally, it presents user study results which indicate that slow-growth notification can achieve significant benefits over traditional popup notification systems without needing to be informed of the user's current task. The study demonstrates that slowgrowth notifications were up to 39\% less disruptive than popups, and up to 33\% subjectively less annoying.},
	language = {eng},
	school = {Massachusetts Institute of Technology},
	author = {Wilson, Thomas Blake},
	year = {2006},
}

@inproceedings{caine_local_2016,
	address = {Santa Clara, California, USA},
	title = {Local {Standards} for {Sample} {Size} at {CHI}},
	isbn = {978-1-4503-3362-7},
	url = {https://doi.org/10.1145/2858036.2858498},
	doi = {10.1145/2858036.2858498},
	abstract = {We describe the primary ways researchers can determine the size of a sample of research participants, present the benefits and drawbacks of each of those methods, and focus on improving one method that could be useful to the CHI community: local standards. To determine local standards for sample size within the CHI community, we conducted an analysis of all manuscripts published at CHI2014. We find that sample size for manuscripts published at CHI ranges from 1 – 916,000 and the most common sample size is 12. We also find that sample size differs based on factors such as study setting and type of methodology employed. The outcome of this paper is an overview of the various ways sample size may be determined and an analysis of local standards for sample size within the CHI community. These contributions may be useful to researchers planning studies and reviewers evaluating the validity of results.},
	language = {en},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '16},
	publisher = {ACM Press},
	author = {Caine, Kelly},
	year = {2016},
	pages = {981--992},
}

@book{gibbons_nonparametric_2020,
	title = {Nonparametric {Statistical} {Inference}},
	isbn = {978-1-351-61617-1},
	abstract = {Praise for previous editions:  "... a classic with a long history." – Statistical Papers  "The fact that the first edition of this book was published in 1971 ... [is] testimony to the book’s success over a long period." – ISI Short Book Reviews  "... one of the best books available for a theory course on nonparametric statistics. ... very well written and organized ... recommended for teachers and graduate students." – Biometrics  "... There is no competitor for this book and its comprehensive development and application of nonparametric methods. Users of one of the earlier editions should certainly consider upgrading to this new edition." – Technometrics "... Useful to students and research workers ... a good textbook for a beginning graduate-level course in nonparametric statistics." – Journal of the American Statistical Association Since its first publication in 1971, Nonparametric Statistical Inference has been widely regarded as the source for learning about nonparametrics. The Sixth Edition carries on this tradition and incorporates computer solutions based on R.   Features   Covers the most commonly used nonparametric procedures   States the assumptions, develops the theory behind the procedures, and illustrates the techniques using realistic examples from the social, behavioral, and life sciences   Presents tests of hypotheses, confidence-interval estimation, sample size determination, power, and comparisons of competing procedures   Includes an Appendix of user-friendly tables needed for solutions to all data-oriented examples   Gives examples of computer applications based on R, MINITAB, STATXACT, and SAS   Lists over 100 new references   Nonparametric Statistical Inference, Sixth Edition, has been thoroughly revised and rewritten to make it more readable and reader-friendly. All of the R solutions are new and make this book much more useful for applications in modern times. It has been updated throughout and contains 100 new citations, including some of the most recent, to make it more current and useful for researchers.},
	language = {en},
	publisher = {CRC Press},
	author = {Gibbons, Jean Dickinson and Chakraborti, Subhabrata},
	month = dec,
	year = {2020},
	keywords = {Mathematics / General, Mathematics / Number Theory, Mathematics / Probability \& Statistics / General},
}

@article{goss_sampson_statistical_2019,
	title = {Statistical {Analyzis} in {JASP}: {A} {Guide} for {Students}},
	language = {en},
	author = {Goss-Sampson, Mark A},
	year = {2019},
	pages = {123},
}

@article{huang_how_2015,
	title = {How are icons processed by the brain? {Neuroimaging} measures of four types of visual stimuli used in information systems},
	volume = {66},
	issn = {2330-1643},
	shorttitle = {How are icons processed by the brain?},
	url = {https://doi.org/10.1002/asi.23210},
	doi = {10.1002/asi.23210},
	abstract = {We sought to understand how users interpret meanings of symbols commonly used in information systems, especially how icons are processed by the brain. We investigated Chinese and English speakers' processing of 4 types of visual stimuli: icons, pictures, Chinese characters, and English words. The goal was to examine, via functional magnetic resonance imaging (fMRI) data, the hypothesis that people cognitively process icons as logographic words and to provide neurological evidence related to human−computer interaction (HCI), which has been rare in traditional information system studies. According to the neuroimaging data of 19 participants, we conclude that icons are not cognitively processed as logographical words like Chinese characters, although they both stimulate the semantic system in the brain that is needed for language processing. Instead, more similar to images and pictures, icons are not as efficient as words in conveying meanings, and brains (people) make more effort to process icons than words. We use this study to demonstrate that it is practicable to test information system constructs such as elements of graphical user interfaces (GUIs) with neuroscience data and that, with such data, we can better understand individual or group differences related to system usage and user−computer interactions.},
	language = {en},
	number = {4},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Huang, Sheng-Cheng and Bias, Randolph G. and Schnyer, David},
	year = {2015},
	keywords = {graphical user interfaces, human computer interaction, human factors},
	pages = {702--720},
}

@misc{kay_effect_2021,
	title = {Effect {Sizes} with {ART}},
	url = {https://cran.r-project.org/web/packages/ARTool/vignettes/art-effect-size.html},
	abstract = {The aligned-rank transform (ART) allows for non-parametric analyses of variance. But how do we derive effect sizes from ART results?},
	urldate = {2022-07-19},
	author = {Kay, Matthew},
	year = {2021},
}

@article{kline_visibility_1990,
	title = {Visibility {Distance} of {Highway} {Signs} among {Young}, {Middle}-{Aged}, and {Older} {Observers}: {Icons} {Are} {Better} than {Text}},
	volume = {32},
	issn = {0018-7208},
	shorttitle = {Visibility {Distance} of {Highway} {Signs} among {Young}, {Middle}-{Aged}, and {Older} {Observers}},
	url = {https://doi.org/10.1177/001872089003200508},
	doi = {10.1177/001872089003200508},
	abstract = {The visibility distances for young, middle-aged, and elderly observers of text and icon versions of four different highway signs were compared under day and dusk lighting conditions. No age differences were observed. Icon signs, however, were visible at much greater distances than were text signs for all three age groups, a difference that was more pronounced under dusk conditions. There were no age differences in the comprehension of icon signs, but there was considerable variability from one icon sign to another in the degree to which they were comprehended. Acuity was found to be a better predictor of the visibility distance of text signs in both day and dusk conditions than it was of icon signs. To the degree that they are comprehended, icon signs appear to offer drivers of all ages almost twice as much time in which to respond to them.},
	language = {en},
	number = {5},
	journal = {Human Factors},
	author = {Kline, Theresa J. Babbitt and Ghali, Laura M. and Kline, Donald W. and Brown, Steven},
	month = oct,
	year = {1990},
	pages = {609--619},
}

@article{ram_lsvp_2021,
	title = {{LSVP}: {Towards} {Effective} {On}-the-go {Video} {Learning} {Using} {Optical} {Head}-{Mounted} {Displays}},
	volume = {5},
	shorttitle = {{LSVP}},
	url = {https://doi.org/10.1145/3448118},
	doi = {10.1145/3448118},
	abstract = {The ubiquity of mobile phones allows video content to be watched on the go. However, users' current on-the-go video learning experience on phones is encumbered by issues of toggling and managing attention between the video and surroundings, as informed by our initial qualitative study. To alleviate this, we explore how combining the emergent smart glasses (Optical Head-Mounted Display or OHMD) platform with a redesigned video presentation style can better distribute users' attention between learning and walking tasks. We evaluated three presentation techniques: highlighting, sequentiality, and data persistence to find that combining sequentiality and data persistence is highly effective, yielding a 56\% higher immediate recall score compared to a static video presentation. We also compared the OHMD against smartphones to delineate the advantages of either platform for on-the-go video learning in the context of everyday mobility tasks. We found that OHMDs improved users' 7-day delayed recall scores by 17\% while still allowing 5.6\% faster walking speed, especially during complex mobility tasks. Based on the findings, we introduce Layered Serial Visual Presentation (LSVP) style, which incorporates sequentiality, strict data persistence, and transparent background, among other properties, for future OHMD-based on-the-go video learning.},
	number = {1},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Ram, Ashwin and Zhao, Shengdong},
	month = mar,
	year = {2021},
	keywords = {dynamic information, Smart glasses},
	pages = {30:1--30:27},
}

@article{theios_theoretical_1989,
	title = {Theoretical analysis of the cognitive processing of lexical and pictorial stimuli: {Reading}, naming, and visual and conceptual comparisons},
	volume = {96},
	issn = {1939-1471},
	shorttitle = {Theoretical analysis of the cognitive processing of lexical and pictorial stimuli},
	doi = {10.1037/0033-295X.96.1.5},
    url = {https://doi.org/10.1037/0033-295X.96.1.5},
	abstract = {This article reviews the research literature on the differences between word reading and picture naming. A theory for the visual and cognitive processing of pictures and words is then introduced. The theory accounts for slower naming of pictures than reading of words. Reading aloud involves a fast, grapheme-to-phoneme transformation process, whereas picture naming involves two additional processes; (a) determining the meaning of the pictorial stimulus and (b) finding a name for the pictorial stimulus. We conducted a reading-naming experiment, and the time to achieve (a) and (b) was determined to be approximately 160 ms. On the basis of data from a second experiment, we demonstrated that there is no significant difference in time to visually compare two pictures or two words when size of the stimuli is equated. There is no difference in time to make the two types of cross-modality conceptual comparisons (picture first, then word, or word first, then picture). The symmetry of the visual and conceptual comparison results supports the hypothesis that the coding of the mind is neither intrinsically linguistic nor imagistic, but rather it is abstract. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	journal = {Psychological Review},
	author = {Theios, John and Amrhein, Paul C.},
	year = {1989},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Cognitive Processes, Lexical Decision, Meaning, Naming, Pictorial Stimuli, Theories, Transfer (Learning), Words (Phonetic Units)},
	pages = {5--24},
}

@article{tomczak_need_2014,
	title = {The need to report effect size estimates revisited. {An} overview of some recommended measures of effect size},
	volume = {1},
	abstract = {Recent years have witnessed a growing number of published reports that point out the need for reporting various effect size estimates in the context of null hypothesis testing (H0) as a response to a tendency for reporting tests of statistical significance only, with less attention on other important aspects of statistical analysis. In the face of considerable changes over the past several years, neglect to report effect size estimates may be noted in such fields as medical science, psychology, applied linguistics, or pedagogy. Nor have sport sciences managed to totally escape the grips of this suboptimal practice: here statistical analyses in even some of the current research reports do not go much further than computing p-values. The p-value, however, is not meant to provide information on the actual strength of the relationship between variables, and does not allow the researcher to determine the effect of one variable on another. Effect size measures serve this purpose well. While the number of reports containing statistical estimates of effect sizes calculated after applying parametric tests is steadily increasing, reporting effect sizes with non-parametric tests is still very rare. Hence, the main objectives of this contribution are to promote various effect size measures in sport sciences through, once again, bringing to the readers’ attention the benefits of reporting them, and to present examples of such estimates with a greater focus on those that can be calculated for non-parametric tests},
	language = {en},
	number = {21},
	journal = {Trends in sport sciences},
	author = {Tomczak, Maciej and Tomczak, Ewa},
	year = {2014},
	pages = {19--25},
}

@article{wiedenbeck_use_1999,
	title = {The use of icons and labels in an end user application program: {An} empirical study of learning and retention},
	volume = {18},
	issn = {0144-929X},
	shorttitle = {The use of icons and labels in an end user application program},
	url = {https://doi.org/10.1080/014492999119129},
	doi = {10.1080/014492999119129},
	abstract = {This research compared the learning of an application program whose interface was implemented using buttons with text labels, icons, or a fully redundant combination of icons and text labels. The objective was to: 1) evaluate the success of novice computer users in initially learning to use the application and in later use in a delayed session and 2) measure users' attitudes toward the application. Each session was divided into four blocks, and performance in the blocks was measured in terms of correctness of the tasks performed, time to perform tasks, and number of times the help facility was accessed. In addition, at the end of each session the participants' perceptions of the ease of use and usefulness of the software were measured. The results showed that in the first session performance was best on the label-only and icon-label interfaces. Performance on the icon-only interface was much poorer in session 1, particularly in terms of time and help references, but improved in session 2 to the point where it approached the performance on the other interfaces. Retention of skill between the initial and the delayed session was worse for the icon-only interface, but the effect was short-lived. Perceptions of ease of use were consistently better for the icon-label interface than for the other two interfaces. Perceptions of usefulness were higher for the icon-only and icon-label interfaces than for the label-only interface in the first session. Perceptions of usefulness became more positive for the icon-only group in the delayed session, but did not change for the other groups.},
	number = {2},
	journal = {Behaviour \& Information Technology},
	author = {Wiedenbeck, Susan},
	month = jan,
	year = {1999},
	pages = {68--82},
}

@article{bartlomiejczyk_text_2013,
	title = {Text and image in traffic signs},
	url = {https://journals.pan.pl/publication/103135/edition/89148/},
	abstract = {Polish Academy of Sciences},
	journal = {LINGUISTICA SILESIANA},
	author = {Bartłomiejczyk, Magdalena},
	year = {2013},
	note = {Publisher: Polska Akademia Nauk • Oddział w Katowicach},
	pages = {111--131},
}

@incollection{castro_effectiveness_2004,
	title = {The {Effectiveness} of {Transport} {Signs}},
	isbn = {978-0-429-20604-7},
	abstract = {Cándida Castro, Tim Horberry, and Francisco Tornay},
	booktitle = {The {Human} {Factors} of {Transport} {Signs}},
	publisher = {CRC Press},
	author = {Castro, Cándida and Horberry, Tim and Tornay, Francisco},
	year = {2004},
}

@article{roca_legibility_2018,
	title = {Legibility of {Text} and {Pictograms} in {Variable} {Message} {Signs}: {Can} {Single}-{Word} {Messages} {Outperform} {Pictograms}?},
	volume = {60},
	issn = {0018-7208},
	shorttitle = {Legibility of {Text} and {Pictograms} in {Variable} {Message} {Signs}},
	url = {https://doi.org/10.1177/0018720817751623},
	doi = {10.1177/0018720817751623},
	abstract = {Objective:The current research shows the advantage of single-word messages in the particular case of variable message signs (VMSs) with a high aspect ratio.Background:Early studies on traffic sign design proposed that pictorial information would advantage equivalent text messages in static signs.Method:We used a driving simulator to present individually 36 VMSs, showing six words (e.g., ?congestion?) and six danger signs (e.g., congestion traffic sign). In Experiment 1, 18 drivers read aloud the text or orally identified the pictograms as soon as they could correctly do it. In Experiment 2, a different sample of 18 drivers gave a motor response, according to the meaning of the message. We analyzed the legibility distance and accuracy, driving performance (speed variability), and glance behavior.Results:Our results show that single-word messages were associated with better performance (farther reading distances) and required less visual demands (fewer glances and less glancing times) than pictograms.Conclusion:As typical configurations of VMSs usually have a high aspect ratio, and thus allow large character heights, single-word messages can outperform the legibility of pictograms. However, the final advantage of text or pictorial messages would depend on several factors, such as the driver?s knowledge of the language and the pictogram set, the use of single or multiple words, the particular design and size of critical details in letters and pictograms, environmental factors, and driver age.Application:Potential applications include the design of VMSs and other devices aimed at displaying text and/or pictograms with a high aspect ratio.},
	language = {en},
	number = {3},
	journal = {Human Factors},
	author = {Roca, Javier and Insa, Beatriz and Tejero, Pilar},
	month = may,
	year = {2018},
	keywords = {high aspect ratio, legibility distance, pictogram, text message, traffic signs, variable message signs},
	pages = {384--396},
}

@article{shinar_comprehension_2013,
	title = {Comprehension of traffic signs with symbolic versus text displays},
	volume = {18},
	issn = {1369-8478},
	url = {https://doi.org/10.1016/j.trf.2012.12.012},
	doi = {10.1016/j.trf.2012.12.012},
	abstract = {Objective
To evaluate the benefits of text and symbolic displays in highway signs relative to their familiarity on their comprehension speed and accuracy.
Background
A recent study that evaluated the influence of ergonomic principles – familiarity, standardization, and symbol-concept compatibility – on traffic sign comprehension showed that comprehension is highly correlated with the compliance with these ergonomic design principles (Ben-Bassat \& Shinar, 2006). As an alternative to existing unfamiliar symbolic signs we tested the effect of adding text.
Method
Drivers were presented with 30 traffic signs varying in their level of familiarity in three display conditions: standard symbol-only, text-only, and symbol+text. Speed and accuracy of comprehension were recorded.
Results
Display condition and familiarity significantly affected both correctness of the answers and reaction time. Correctness improved when the symbol was shown with text, especially when the sign was less familiar.
Conclusions
Adding text improves the comprehension and reduces the time it takes to comprehend the sign, especially of unfamiliar signs.
Application
Adding text could be a simple solution to making (unfamiliar) signs more understandable to a greater segment of the driving population without compromising comprehension time, thereby increasing traffic safety.},
	language = {en},
	journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
	author = {Shinar, David and Vogelzang, Margreet},
	month = may,
	year = {2013},
	keywords = {Comprehension time, Sign comprehension, Traffic safety, Traffic signs},
	pages = {72--82},
}

@inproceedings{tauch_the_2016,
author = {Tauch, Channary and Kanjo, Eiman},
title = {The Roles of Emojis in Mobile Phone Notifications},
year = {2016},
isbn = {9781450344623},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2968219.2968549},
doi = {10.1145/2968219.2968549},
abstract = {The texts in mobile messages are not always easy to decipher since tone and body language is removed from the context. Emojis offer an attractive way to express emotions to avoid misunderstandings of message tone. In this paper we shed the light on the roles of Emojis in phone notification, we conducted an in-situ study to gather phone notification data. We outline the relationship between Emojis and various social network applications including WhatsApp, Facebook and Twitter. Early results allow us to draw several conclusions in relation to number, position, type and sentimental value of Emojis. It turns out that most popular Emojis in one social app is not as popular in the others. Emojis sentimental polarity in Twitter is high and overall number of Emojis is less than Facebook. The sentimental value of Emojis is more meaningful when there are multiple Emoji in one notification.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct},
pages = {1560–1565},
numpages = {6},
keywords = {phone notifications, sentimental analysis, affective computing, pervasive computing, emojis},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@misc{nus_hci_lab_heads_up_2022,
	title = {Heads-{Up} {Computing} – {NUS}-{HCI} {Lab}},
	url = {https://www.nus-hci.org/heads-up-computing/},
	language = {en-US},
	urldate = {2022-10-04},
	author = {NUS-HCI Lab},
	year = {2022},
}


@article{pashler_dual_task_1994,
	title = {Dual-task interference in simple tasks: data and theory},
	volume = {116},
	issn = {0033-2909},
	shorttitle = {Dual-task interference in simple tasks},
	doi = {10.1037/0033-2909.116.2.220},
    url = {https://doi.org/10.1037/0033-2909.116.2.220},
	abstract = {People often have trouble performing 2 relatively simple tasks concurrently. The causes of this interference and its implications for the nature of attentional limitations have been controversial for 40 years, but recent experimental findings are beginning to provide some answers. Studies of the psychological refractory period effect indicate a stubborn bottleneck encompassing the process of choosing actions and probably memory retrieval generally, together with certain other cognitive operations. Other limitations associated with task preparation, sensory-perceptual processes, and timing can generate additional and distinct forms of interference. These conclusions challenge widely accepted ideas about attentional resources and probe reaction time methodologies. They also suggest new ways of thinking about continuous dual-task performance, effects of extraneous stimulation (e.g., stop signals), and automaticity. Implications for higher mental processes are discussed.},
	language = {eng},
	number = {2},
	journal = {Psychological Bulletin},
	author = {Pashler, H.},
	month = sep,
	year = {1994},
	pmid = {7972591},
	keywords = {Attention, Automatism, Humans, Reaction Time, Task Performance and Analysis},
	pages = {220--244},
}

@misc{apple_notifications_2022,
	title = {Notifications - {System} experiences - {Components} - {Human} {Interface} {Guidelines} - {Design} - {Apple} {Developer}},
	url = {https://developer.apple.com/design/human-interface-guidelines/components/system-experiences/notifications/},
	urldate = {2022-11-21},
	author = {Apple},
	year = {2022},
}

@inproceedings{avrahami_im_2008,
	address = {San Diego, CA, USA},
	title = {{IM} waiting: timing and responsiveness in semi-synchronous communication},
	isbn = {978-1-60558-007-4},
	shorttitle = {{IM} waiting},
	url = {https://doi.org/10.1145/1460563.1460610},
	doi = {10.1145/1460563.1460610},
	abstract = {Responsiveness, or the time until a person responds to communication, can affect the dynamics of a conversation as well as participants’ perceptions of one another. In this paper, we present a careful examination of responsiveness to instant messaging communication, showing, for example, that work-fragmentation significantly correlates with faster responsiveness. We show also that the presentation of the incoming communication significantly affects responsiveness (even more so than indicators that the communication was ongoing), suggesting the potential for dynamically influencing responsiveness. This work contributes to a better understanding of computer-mediated communication and to the design of new tools for computer-mediated communication.},
	language = {en},
	booktitle = {Proceedings of the {ACM} 2008 conference on {Computer} supported cooperative work - {CSCW} '08},
	publisher = {ACM Press},
	author = {Avrahami, Daniel and Fussell, Susan R. and Hudson, Scott E.},
	year = {2008},
	pages = {285},
}

@article{shen_effects_2018,
	title = {Effects of {Users}’ {Familiarity} {With} the {Objects} {Depicted} in {Icons} on the {Cognitive} {Performance} of {Icon} {Identification}},
	volume = {9},
	issn = {2041-6695},
	url = {https://doi.org/10.1177/2041669518780807},
	doi = {10.1177/2041669518780807},
	abstract = {This study investigated the effects of users? familiarity with the objects depicted in icons on the cognitive performance of icon identification. First, without knowing the specific semantic information of icons, 20 participants were required to search for target icons among visually similar distractors for 3-hour-long training sessions across 1 week, during which their familiarity with different icons was manipulated by differential exposure frequencies. Half of the icons were presented 10 times more often than the other half. Subsequently, participants? abilities to recall corresponding semantic information when cued with associated target icons were tested after they had learned all the icons. The results showed that, in both the visual search task and the semantic information recall task, participants performed significantly better when the icons were more familiar. Importantly, the effects of icon complexity in the visual search task diminished as participants became familiar with the icons, and the beneficial effects of familiarity in the semantic information recall task were larger when the icons were complex. These findings have practical implications for icon design. When creating new icons for time critical user interfaces, icons should be kept as simple as possible and employ familiar, commonly used, graphics.},
	language = {en},
	number = {3},
	journal = {i-Perception},
	author = {Shen, Zhangfan and Xue, Chengqi and Wang, Haiyan},
	month = apr,
	year = {2018},
	note = {Publisher: SAGE Publications},
	pages = {2041669518780807},
}

@article{mcdougall_what_2016,
	title = {What makes icons appealing? {The} role of processing fluency in predicting icon appeal in different task contexts},
	volume = {55},
	issn = {0003-6870},
	shorttitle = {What makes icons appealing?},
	url = {https://doi.org/10.1016/j.apergo.2016.02.006},
	doi = {10.1016/j.apergo.2016.02.006},
	abstract = {Although icons appear on almost all interfaces, there is a paucity of research examining the determinants of icon appeal. The experiments reported here examined the icon characteristics determining appeal and the extent to which processing fluency – the subjective ease with which individuals process information – was used as a heuristic to guide appeal evaluations. Participants searched for, and identified, icons in displays. The initial appeal of icons was held constant while ease of processing was manipulated by systematically varying the complexity and familiarity of the icons presented and the type of task participants were asked to carry out. Processing fluency reliably influenced users' appeal ratings and appeared to be based on users' unconscious awareness of the ease with which they carried out experimental tasks.},
	language = {en},
	journal = {Applied Ergonomics},
	author = {McDougall, Siné and Reppa, Irene and Kulik, Jozef and Taylor, Alisdair},
	month = jul,
	year = {2016},
	keywords = {Aesthetics, Appeal, Icons, Processing fluency, User experience},
	pages = {156--172},
}



@article{nenna_augmented_2021,
	title = {Augmented {Reality} as a research tool: investigating cognitive-motor dual-task during outdoor navigation},
	volume = {152},
	issn = {1071-5819},
	shorttitle = {Augmented {Reality} as a research tool},
	url = {https://doi.org/10.1016/j.ijhcs.2021.102644},
	doi = {10.1016/j.ijhcs.2021.102644},
	abstract = {Augmented Reality (AR) combines real-world and computer-generated data, allowing for a dynamic presentation of visual contents while moving in the physical surroundings. Though promising for the investigation of visuospatial processing in natural scenarios, experimental research exploiting AR in this context is scarce. In this study, we aimed at testing the behavioral consequences of multitasking when walking in different directions to close landmarks while responding to AR holograms outdoors. Participants were engaged in i) a visual single-task for discriminating augmented peripheral targets, ii) a navigation single-task consisting of a sequence of short goal-directed walking periods to close augmented landmarks and iii) a dual-task combining the latter tasks. We evaluated the cost of dual-tasking on cognitive and motor performance in comparison to the single-tasks, along with a subjective assessment of mental load. Cognitive-Motor Interference (CMI) was highlighted by performance costs in both the cognitive and motor domains under dual-task. Interestingly, a discrepancy between subjective and objective measures of mental load under dual-task was observed. We conclude that the attentional load induced by multitasking can have important consequences when navigating the dynamic real world, and thus needs to be addressed in a variety of daily-living contexts. In this perspective, AR is a suitable research tool for simulating dynamic tasks outdoors, enhancing the ecological validity of cognitive investigations without sacrificing the experimental rigor of laboratory research. Additionally, it provides insights into the possible impact on attention and behavior when using wearable mobile technologies that overlap virtual data to the physical environment.},
	language = {en},
	journal = {International Journal of Human-Computer Studies},
	author = {Nenna, Federica and Zorzi, Marco and Gamberini, Luciano},
	month = aug,
	year = {2021},
	keywords = {Augmented Reality, Cognitive research, Cyber research, Dual task, Spatial cognition},
	pages = {102644},
}

@article{hua_enabling_2017,
  author={Hua, Hong},
  journal={Proceedings of the IEEE}, 
  title={Enabling Focus Cues in Head-Mounted Displays}, 
  year={2017},
  volume={105},
  number={5},
  pages={805-824},
  abstract={Developing head-mounted displays (HMDs) that offer uncompromised optical pathways to both digital and physical worlds without encumbrance and discomfort confronts many grand challenges, both from technological perspectives and human factors. Among the many challenges, minimizing visual discomfort is one of the key obstacles. One of the key contributing factors to visual discomfort is the lack of the ability to render proper focus cues in HMDs to stimulate natural eye accommodation responses, which leads to the wellknown problem of vergence-accommodation conflict. This paper provides a comprehensive summary of various technical approaches toward enabling focus cues in HMDs for both virtual reality (VR) and augmented reality (AR) applications.},
  keywords={},
  doi={10.1109/JPROC.2017.2648796},
  ISSN={1558-2256},
  url={https://doi.org/10.1109/JPROC.2017.2648796},
  month=may,
}


@article{marran_multiaccomodative_1997,
  author = {Lynn Marran and Clifton Schor},
  title ={Multiaccommodative Stimuli in VR Systems: Problems \& Solutions},
  journal = {Human Factors},
  volume = {39},
  number = {3},
  pages = {382-388},
  year = {1997},
  doi = {10.1518/001872097778827070},
  URL = {https://doi.org/10.1518/001872097778827070},
  eprint = {https://doi.org/10.1518/001872097778827070},
  abstract = { Virtual reality environments can introduce multiple and sometimes conflicting accommodative stimuli. For instance, with the high-powered lenses commonly used in head-mounted displays, small discrepancies in screen lens placement, caused by manufacturer error or user adjustment focus error, can change the focal depths of the image by a couple of diopters. This can introduce a binocular accommodative stimulus or, if the displacement between the two screens is unequal, an unequal (anisometropic) accommodative stimulus for the two eyes. Systems that allow simultaneous viewing of virtual and real images can also introduce a conflict in accommodative stimuli: When real and virtual images are at different focal planes, both cannot be in focus at the same time, though they may appear to be in similar locations in space. In this paper four unique designs are described that minimize the range of accommodative stimuli and maximize the visual system's ability to cope efficiently with the focus conflicts that remain: pinhole optics, monocular lens addition combined with aniso-accommodation, chromatic bifocal, and bifocal lens system. The advantages and disadvantages of each design are described and recommendation for design choice is given after consideration of the end use of the virtual reality system (e.g., low or high end, entertainment, technical, or medical use). The appropriate design modifications should allow greater user comfort and better performance. }
}


@misc{page_executing_2023,
	title = {Executing {UX} {Animations}: {Duration} and {Motion} {Characteristics}},
	shorttitle = {Executing {UX} {Animations}},
	url = {https://www.nngroup.com/articles/animation-duration/},
	abstract = {Define a trigger, transformations, duration, and easing of the animation, and be mindful of accessibility issues and annoying the user.},
	language = {en},
	urldate = {2023-05-19},
	journal = {Nielsen Norman Group},
	author = {Page, Laubheimer Leaders in Research-Based User},
	year = {2023},
}

@book{head_designing_2016,
	address = {Brooklyn, New York},
	edition = {1st edition},
	title = {Designing {Interface} {Animation}: {Improving} the {User} {Experience} {Through} {Animation}},
	isbn = {978-1-933820-32-3},
	shorttitle = {Designing {Interface} {Animation}},
	abstract = {Effective interface animation deftly combines form and function to improve feedback, aid in orientation, direct attention, show causality, and express your brand’s personality. Designing Interface Animation shows you how to create web animation that balances purpose and style while blending seamlessly into the user’s experience. This book is a crash course in motion design theory and practice for web designers, UX professionals, and front-end developers alike.},
	language = {English},
	publisher = {Rosenfeld Media},
	author = {Head, Val},
	month = jul,
	year = {2016},
}


@article{rau_speed_2018,
	title = {Speed reading on virtual reality and augmented reality},
	volume = {125},
	issn = {0360-1315},
	url = {https://doi.org/10.1016/j.compedu.2018.06.016},
	doi = {10.1016/j.compedu.2018.06.016},
	abstract = {Many virtual reality (VR) and augmented reality (AR) applications in education require speed reading. The current study aimed to explore whether the reading performance on VR and AR is different from that on traditional desktop display, and whether the difference is moderated by the reading speed. Sixty-three college students read Chinese passages at normal (650–750 characters per minute [cpm]) or fast speeds (1000–1400 cpm), and then answered multiple-choice questions. They spent approximately 10\% more time in making choice on VR and AR than they did on the desktop display. Teachers should be aware of this difference and allow 10\% more time when using VR and AR applications containing text components.},
	language = {en},
	journal = {Computers \& Education},
	author = {Rau, Pei-Luen Patrick and Zheng, Jian and Guo, Zhi and Li, Jiaqi},
	month = oct,
	year = {2018},
	keywords = {Augmented reality, Human-computer interface, Interactive learning environments, Reading performance, Virtual reality},
	pages = {240--245},
}

@inproceedings{rzayev_reading_2018,
	address = {Montreal QC, Canada},
	title = {Reading on {Smart} {Glasses}: {The} {Effect} of {Text} {Position}, {Presentation} {Type} and {Walking}},
	isbn = {978-1-4503-5620-6},
	shorttitle = {Reading on {Smart} {Glasses}},
	url = {https://doi.org/10.1145/3173574.3173619},
	doi = {10.1145/3173574.3173619},
	abstract = {Smart glasses are increasingly being used in professional contexts. Having key applications such as short messaging and newsreader, they enable continuous access to textual information. In particular, smart glasses allow reading while performing other activities as they do not occlude the user’s world view. For efﬁcient reading, it is necessary to understand how a text should be presented on them. We, therefore, conducted a study with 24 participants using a Microsoft HoloLens to investigate how to display text on smart glasses while walking and sitting. We compared text presentation in the top-right, center, and bottom-center positions with Rapid Serial Visual Presentation (RSVP) and line-by-line scrolling. We found that text displayed in the top-right of smart glasses increases subjective workload and reduces comprehension. RSVP yields higher comprehension while sitting. Conversely, reading with scrolling yields higher comprehension while walking. Insights from our study inform the design of reading interfaces for smart glasses.},
	language = {en},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '18},
	publisher = {ACM Press},
	author = {Rzayev, Rufat and Woźniak, Paweł W. and Dingler, Tilman and Henze, Niels},
	year = {2018},
	keywords = {RSVP, reading-on-the-go, text-style},
	pages = {1--9},
}

@misc{ampere_dusk_2023,
	title = {{Dusk}},
	url = {https://ampere.shop/products/dusk-electrochromic-smart-sunglasses},
	urldate = {2023-04-08},
	author = {Ampere},
	year = {2023},
}

@misc{ibm_calculation_2023,
	title = {The calculation of {Bonferroni}-adjusted p-values},
	url = {https://www.ibm.com/support/pages/calculation-bonferroni-adjusted-p-value},
	urldate = {2023-04-08},
	author = {IBM},
	year = {2023},
}

@article {Bland170,
	author = {Bland, J Martin and Altman, Douglas G},
	title = {Multiple significance tests: the Bonferroni method},
	volume = {310},
	number = {6973},
	pages = {170},
	year = {1995},
	doi = {10.1136/bmj.310.6973.170},
	publisher = {BMJ Publishing Group Ltd},
	issn = {0959-8138},
	URL = {https://doi.org/10.1136/bmj.310.6973.170},
	journal = {BMJ}
}


@inproceedings{lee_does_2019,
	address = {Glasgow, Scotland Uk},
	title = {Does \textit{{Who}} {Matter}?: {Studying} the {Impact} of {Relationship} {Characteristics} on {Receptivity} to {Mobile} {IM} {Messages}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {Does \textit{{Who}} {Matter}?},
	url = {https://doi.org/10.1145/3290605.3300756},
	doi = {10.1145/3290605.3300756},
	abstract = {This study examines the characteristics of mobile instantmessaging users’ relationships with their social contacts and the effects of both relationship and interruption context on four measures of receptivity: Attentiveness, Responsiveness, Interruptibility, and Opportuneness. Overall, interruption context overshadows relationship characteristics as predictors of all four of these facets of receptivity; this overshadowing was most acute for Interruptibility and Opportuneness, but existed for all factors. In addition, while Mobile Maintenance Expectation and Activity Engagement were negatively correlated with all receptivity measures, each such measure had its own set of predictors, highlighting the conceptual differences among the measures. Finally, delving more deeply into potential relationship effects, we found that a single, simple closeness question was as effective at predicting receptivity as the 12-item Unidimensional Relationship Closeness Scale.},
	language = {en},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '19},
	publisher = {ACM Press},
	author = {Lee, Hao-Ping and Chen, Kuan-Yin and Lin, Chih-Heng and Chen, Chia-Yu and Chung, Yu-Lin and Chang, Yung-Ju and Sun, Chien-Ru},
	year = {2019},
	pages = {1--12},
}


@article{visuri_understanding_2019,
	title = {Understanding smartphone notifications’ user interactions and content importance},
	volume = {128},
	issn = {10715819},
	url = {https://doi.org/10.1016/j.ijhcs.2019.03.001},
	doi = {10.1016/j.ijhcs.2019.03.001},
	abstract = {We present the results of our experiment aimed to comprehensively understand the combination of 1) how smartphone users interact with their notifications, 2) what notification content is considered important, 3) the complex relationship between the interaction choices and content importance, and lastly 4) establish an intelligent method to predict user's preference to seeing an incoming notification. We use a dataset of notifications received by 40 anonymous users in-the-wild, which consists of 1) qualitative user-labelled information about their preferences on notification's contents, 2) notification source, and 3) the context in which the notification was received. We assess the effectiveness of personalised prediction models generated using a combination of self-reported content importance and contextual information. We uncover four distinct user types, based on the number of daily notifications and interaction choices. We showcase how usage traits of these groups highlight the requirement for notification filtering approaches, e.g., when specific users habitually neglect to manually filter out unimportant notifications. Our machine learning-based predictor, based on both contextual sensing and notification contents can predict the user's preference for successfully acknowledging an incoming notification with 91.1\% mean accuracy, crucial for time-critical user engagement and interventions.},
	language = {en},
	journal = {International Journal of Human-Computer Studies},
	author = {Visuri, Aku and van Berkel, Niels and Okoshi, Tadashi and Goncalves, Jorge and Kostakos, Vassilis},
	month = aug,
	year = {2019},
	pages = {72--85},
}


@book{westermann_user_2017,
	address = {Singapore},
	series = {T-{Labs} {Series} in {Telecommunication} {Services}},
	title = {User {Acceptance} of {Mobile} {Notifications}},
	isbn = {978-981-10-3851-8},
	url = {https://doi.org/10.1007/978-981-10-3851-8},
	language = {en},
	publisher = {Springer Singapore},
	author = {Westermann, Tilo},
	year = {2017},
	doi = {10.1007/978-981-10-3851-8},
}


@phdthesis{fischer_understanding_2011,
	title = {Understanding {Receptivity} to {Interruptions} in {Mobile} {Human}-{Computer} {Interaction}},
	url = {http://eprints.nottingham.ac.uk/12499/},
	language = {en},
	school = {University of Nottingham},
	author = {Fischer, Joel E.},
	month = dec,
	year = {2011},
}


% update these
@article{zhao_headsup_2023,
    title = {{Heads-Up} {Computing}: {Moving} {Beyond} the {Device}-{Centered} {Paradigm}},
    language = {en},
    journal = {Communications of the ACM (To Appear)},
    author = {Zhao, Shengdong and Tan, Felicia and Fennedy, Katherine},
    % month = mar,
    year = {2023},
    url = {https://doi.org/10.48550/arXiv.2305.05292},
    archivePrefix={arXiv},
}


@article{janaka_glassmessaging_2023,
    title = {{GlassMessaging}: {Towards} {Ubiquitous} {Messaging} {Using} {OHMDs}},
    shorttitle = {{GlassMessaging}},
    % url = {https://doi.org/10.1145/3448118},
    % doi = {10.1145/3448118},
    journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (Under Review)},
    author = {Janaka, Nuwan and Gao, Jie and Zhu, Lin and Zhao, Shengdong and Lyu, Lan and Xu, Peisen and Nabokow, Maximilian and Wang, Silang and Ong, Yanch},
    year = {2023},
}



@inproceedings{zhang_adaptReview_2023,
    title = {{AdaptReview}: {Towards} {Effective} {Video} {Reviewing} using {Text} {Summaries} and {Concept} {Maps}},
    shorttitle = {{AdaptReview}},
    % isbn = {978-3-030-29384-0},
    % doi = {10.1007/978-3-030-29384-0_20},
    booktitle = {Human-{Computer} {Interaction} – {INTERACT} 2023 (To Appear)},
    publisher = {Springer International Publishing},
    author = {Zhang, Shan and Haigh, Chloe and Janaka, Nuwan and Chen, Yang and Zhao, Shengdong and Ooi, Wei Tsang},
    year = {2023},
}

